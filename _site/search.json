[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bem vindo!",
    "section": "",
    "text": "O que você encontra por aqui:\n\nCurso de R: aulas práticas de programação, análise de dados e visualização.\n\nRecursos e ferramentas: scripts, códigos de exemplo e materiais para facilitar seu aprendizado.\n\nBlog e tutoriais: conteúdos sobre estatística aplicada, experimentação agrícola e melhores práticas em pesquisa.\n\nAcompanhe e explore o site para aprender, praticar e aplicar R na sua pesquisa agrícola!\n  \n\n\n\n\nCurso de Estatística com  para Experimentação Agrícola\n\n\nComece agora mesmo a aprender a analisar dados em experimentação agrícola utilizando a linguagem R.\n\nAcesse o curso\nAndamento do curso\n\n\n\nExplore ferramentas que facilitam seu dia a dia.\n\n\n\n Gerar Regressão Linear\n\n\nEsta ferramenta permite gerar gráficos de regressão linear simples a partir de dados X e Y, exibindo a equação da reta e o coeficiente de determinação (R²). É ideal para verificar o ajuste de curvas, sendo especialmente útil em laboratórios durante a construção de curvas de soluções em análises.\n\nACESSAR"
  },
  {
    "objectID": "ferramentas.html",
    "href": "ferramentas.html",
    "title": "Central de Ferramentas",
    "section": "",
    "text": "Explore ferramentas práticas e interativas criadas para facilitar sua vida acadêmica e profissional.\nComece testando abaixo:\n\n\n Gerar Regressão Linear\n\n\nEsta ferramenta permite gerar gráficos de regressão linear simples a partir de dados X e Y, exibindo a equação da reta e o coeficiente de determinação (R²). É ideal para verificar o ajuste de curvas, sendo especialmente útil em laboratórios durante a construção de curvas de soluções em análises.\n\nACESSAR"
  },
  {
    "objectID": "apresentacao.html",
    "href": "apresentacao.html",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Este material serve como guia para o curso Estatística com R para Experimentação Agrícola.\nCada aula contém explicações teóricas resumidas e códigos práticos para serem executados no RStudio.\n\n\nObjetivo: Familiarizar o aluno com R, RStudio e a preparação correta dos dados.\n\n\n\nO que é R e RStudio\nInstalação passo a passo\nEstrutura do RStudio (console, script, environment, plots, packages)\n\n\n\n\n\nComandos básicos\nOperadores aritméticos e lógicos\nCriando e manipulando objetos\n\n\n\n\n\ninstall.packages(), library()\nPacotes úteis: tidyverse, readxl, agricolae, emmeans, broom, ggplot2\nComo procurar ajuda e documentação\n\n\n\n\n\nComo estruturar dados no Excel (linhas = observações, colunas = variáveis)\nImportação de arquivos (.csv, .xlsx, .txt)\nUso de read.csv(), readxl::read_excel(), read.table()\nVerificação e limpeza dos dados (head(), str(), summary())\n\n\n\n\n\n\nObjetivo: Aprender a organizar, transformar e explorar dados antes da análise.\n\n\n\ndplyr: select(), filter(), mutate(), summarise(), group_by()\ntidyr: pivot_longer(), pivot_wider()\n\n\n\n\n\nMédias, desvios-padrão, erro-padrão\nTabelas resumo com dplyr\nVisualizações iniciais: histogramas, boxplots, gráficos de barras\n\n\n\n\n\nEstrutura do ggplot2\nGráficos básicos aplicados a dados de experimentação agrícola\nPersonalização de gráficos\n\n\n\n\n\nDelineamentos básicos: DIC, DBC\nEstrutura dos dados em experimentação agrícola\nPreparação dos dados no Excel para cada delineamento\n\n\n\n\n\n\nObjetivo: Ensinar a rodar ANOVA, verificar pressupostos e interpretar resultados, utilizando diferentes pacotes.\n\n\n\nFunções base: aov()\nANOVA com ExpDes.pt (dic())\nANOVA com easyanova\n\n\n\n\n\nFunções base: aov()\nANOVA com ExpDes.pt (dbc())\nComparação da saída entre pacotes\n\n\n\n\n\nNormalidade dos resíduos: shapiro.test(), rstatix::shapiro_test()\nHomogeneidade: bartlett.test(), car::leveneTest(), rstatix::levene_test()\nInterpretação prática\n\n\n\n\n\nTukeyHSD() (base R)\nExpDes.pt (já integrado à ANOVA)\nemmeans + cld()\nrstatix::t_test() e rstatix::anova_test()\n\n\n\n\n\nDois fatores com aov()\nDois fatores com ExpDes.pt::fat2.dic() e fat2.dbc()\nInterpretação das interações\n\n\n\n\n\nEstrutura de dados\nExpDes.pt::psub2.dbc() (ou funções equivalentes)\nModelos mistos com lme4::lmer()\n\n\n\n\n\nbroom::tidy() para organizar tabelas\nExportação de resultados com rstatix (get_anova_table())\nApresentação de médias e letras com agricolae, emmeans e ExpDes.pt\n\n\n\n\n\nMesmos dados analisados em aov(), ExpDes.pt, easyanova e rstatix\nDiscussão: qual usar em cada situação\n\n\n\n\n\n\nObjetivo: Introduzir regressão e aplicações em experimentação agrícola.\n\n\n\nConceito, ajuste com lm()\nGráficos de regressão no ggplot2\n\n\n\n\n\nlm(y ~ poly(x, 2))\nAplicações em curvas de dose, tempo, crescimento\n\n\n\n\n\nCritérios AIC e BIC\nComparação de modelos\n\n\n\n\n\nnls()\nAjuste de curvas de resposta à dose\n\n\n\n\n\nglm(family = binomial)\nExemplos em fitossanidade e sobrevivência\n\n\n\n\n\n\n\n\n\nObjetivo: Consolidar o aprendizado com aplicações práticas.\n\n\n\nUso do RMarkdown\nExportar para Word e PDF\nOrganização dos resultados\n\n\n\n\nCada aluno analisa um banco de dados de experimentação agrícola.\nEntrega de relatório com:\n\nEstrutura dos dados\nANOVA + testes de médias ou regressão\nGráficos e tabelas\nInterpretação\n\n\n\n\n\n\n\nSemanas 1-2: R, RStudio, pacotes, organização/importação de dados\n\nSemanas 3-4: Manipulação de dados, gráficos, delineamentos\n\nSemanas 5-8: ANOVA com base R, ExpDes.pt, easyanova e rstatix\n\nSemanas 9-11: Regressão (linear, polinomial, não linear, logística)\n\nSemana 12: Relatórios e Projeto Final"
  },
  {
    "objectID": "apresentacao.html#módulo-1-introdução-ao-r-e-organização-de-dados-semanas-1-2",
    "href": "apresentacao.html#módulo-1-introdução-ao-r-e-organização-de-dados-semanas-1-2",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Objetivo: Familiarizar o aluno com R, RStudio e a preparação correta dos dados.\n\n\n\nO que é R e RStudio\nInstalação passo a passo\nEstrutura do RStudio (console, script, environment, plots, packages)\n\n\n\n\n\nComandos básicos\nOperadores aritméticos e lógicos\nCriando e manipulando objetos\n\n\n\n\n\ninstall.packages(), library()\nPacotes úteis: tidyverse, readxl, agricolae, emmeans, broom, ggplot2\nComo procurar ajuda e documentação\n\n\n\n\n\nComo estruturar dados no Excel (linhas = observações, colunas = variáveis)\nImportação de arquivos (.csv, .xlsx, .txt)\nUso de read.csv(), readxl::read_excel(), read.table()\nVerificação e limpeza dos dados (head(), str(), summary())"
  },
  {
    "objectID": "apresentacao.html#módulo-2-manipulação-e-exploração-de-dados-semanas-3-4",
    "href": "apresentacao.html#módulo-2-manipulação-e-exploração-de-dados-semanas-3-4",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Objetivo: Aprender a organizar, transformar e explorar dados antes da análise.\n\n\n\ndplyr: select(), filter(), mutate(), summarise(), group_by()\ntidyr: pivot_longer(), pivot_wider()\n\n\n\n\n\nMédias, desvios-padrão, erro-padrão\nTabelas resumo com dplyr\nVisualizações iniciais: histogramas, boxplots, gráficos de barras\n\n\n\n\n\nEstrutura do ggplot2\nGráficos básicos aplicados a dados de experimentação agrícola\nPersonalização de gráficos\n\n\n\n\n\nDelineamentos básicos: DIC, DBC\nEstrutura dos dados em experimentação agrícola\nPreparação dos dados no Excel para cada delineamento"
  },
  {
    "objectID": "apresentacao.html#módulo-3-análise-de-variância-anova-semanas-5-8",
    "href": "apresentacao.html#módulo-3-análise-de-variância-anova-semanas-5-8",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Objetivo: Ensinar a rodar ANOVA, verificar pressupostos e interpretar resultados, utilizando diferentes pacotes.\n\n\n\nFunções base: aov()\nANOVA com ExpDes.pt (dic())\nANOVA com easyanova\n\n\n\n\n\nFunções base: aov()\nANOVA com ExpDes.pt (dbc())\nComparação da saída entre pacotes\n\n\n\n\n\nNormalidade dos resíduos: shapiro.test(), rstatix::shapiro_test()\nHomogeneidade: bartlett.test(), car::leveneTest(), rstatix::levene_test()\nInterpretação prática\n\n\n\n\n\nTukeyHSD() (base R)\nExpDes.pt (já integrado à ANOVA)\nemmeans + cld()\nrstatix::t_test() e rstatix::anova_test()\n\n\n\n\n\nDois fatores com aov()\nDois fatores com ExpDes.pt::fat2.dic() e fat2.dbc()\nInterpretação das interações\n\n\n\n\n\nEstrutura de dados\nExpDes.pt::psub2.dbc() (ou funções equivalentes)\nModelos mistos com lme4::lmer()\n\n\n\n\n\nbroom::tidy() para organizar tabelas\nExportação de resultados com rstatix (get_anova_table())\nApresentação de médias e letras com agricolae, emmeans e ExpDes.pt\n\n\n\n\n\nMesmos dados analisados em aov(), ExpDes.pt, easyanova e rstatix\nDiscussão: qual usar em cada situação"
  },
  {
    "objectID": "apresentacao.html#módulo-4-regressão-e-modelos-semanas-9-11",
    "href": "apresentacao.html#módulo-4-regressão-e-modelos-semanas-9-11",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Objetivo: Introduzir regressão e aplicações em experimentação agrícola.\n\n\n\nConceito, ajuste com lm()\nGráficos de regressão no ggplot2\n\n\n\n\n\nlm(y ~ poly(x, 2))\nAplicações em curvas de dose, tempo, crescimento\n\n\n\n\n\nCritérios AIC e BIC\nComparação de modelos\n\n\n\n\n\nnls()\nAjuste de curvas de resposta à dose\n\n\n\n\n\nglm(family = binomial)\nExemplos em fitossanidade e sobrevivência"
  },
  {
    "objectID": "apresentacao.html#módulo-5-encerramento-e-projeto-final-semana-12",
    "href": "apresentacao.html#módulo-5-encerramento-e-projeto-final-semana-12",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Objetivo: Consolidar o aprendizado com aplicações práticas.\n\n\n\nUso do RMarkdown\nExportar para Word e PDF\nOrganização dos resultados\n\n\n\n\nCada aluno analisa um banco de dados de experimentação agrícola.\nEntrega de relatório com:\n\nEstrutura dos dados\nANOVA + testes de médias ou regressão\nGráficos e tabelas\nInterpretação"
  },
  {
    "objectID": "apresentacao.html#cronograma-resumido-atualizado",
    "href": "apresentacao.html#cronograma-resumido-atualizado",
    "title": "Curso de Estatística com R para Experimentação Agrícola",
    "section": "",
    "text": "Semanas 1-2: R, RStudio, pacotes, organização/importação de dados\n\nSemanas 3-4: Manipulação de dados, gráficos, delineamentos\n\nSemanas 5-8: ANOVA com base R, ExpDes.pt, easyanova e rstatix\n\nSemanas 9-11: Regressão (linear, polinomial, não linear, logística)\n\nSemana 12: Relatórios e Projeto Final"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Marlenildo Melo é Engenheiro Agrônomo e doutror em Agronomia/Fitotecnia com foco em Melhoramento Genético, Tecnologia de Sementes e Pós-Colheita. Possui sólida experiência em análise de dados e estatística aplicada à pesquisa agronômica, utilizando a linguagem R para tratamento, visualização e interpretação de dados.\n\n\nUniversidade Federal Rural do Semi-Árido (UFERSA) | Mossoró, RN\nMestrado e Doutorado em Agronomia/Fitotecnia | 2016 - 2022\nInstituto Federal de Educação, Ciência e Tecnologia do Ceará | Ceará, CE\nEngenharia Agronômica | 2012 - 2016\nUniversidade Federal do Ceará | Ceará, CE\nAdministração Pública | 2011 - 2015\n\n\n\nPesquisador e Analista de Dados Agronômicos | 2016 - presente\nAtuação em projetos de pesquisa envolvendo análise de dados, estatística aplicada à agronomia e uso avançado da linguagem R para visualização e interpretação de resultados.\n\n\n\nAcesse meus currículos ou entre em contato comigo através dos links abaixo:\n Linktree\n marlenildo@gmail.com\n (84) 98752-1095"
  },
  {
    "objectID": "about.html#educação",
    "href": "about.html#educação",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Universidade Federal Rural do Semi-Árido (UFERSA) | Mossoró, RN\nMestrado e Doutorado em Agronomia/Fitotecnia | 2016 - 2022\nInstituto Federal de Educação, Ciência e Tecnologia do Ceará | Ceará, CE\nEngenharia Agronômica | 2012 - 2016\nUniversidade Federal do Ceará | Ceará, CE\nAdministração Pública | 2011 - 2015"
  },
  {
    "objectID": "about.html#experiência-profissional",
    "href": "about.html#experiência-profissional",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Pesquisador e Analista de Dados Agronômicos | 2016 - presente\nAtuação em projetos de pesquisa envolvendo análise de dados, estatística aplicada à agronomia e uso avançado da linguagem R para visualização e interpretação de resultados."
  },
  {
    "objectID": "about.html#meus-links",
    "href": "about.html#meus-links",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Acesse meus currículos ou entre em contato comigo através dos links abaixo:\n Linktree\n marlenildo@gmail.com\n (84) 98752-1095"
  },
  {
    "objectID": "andamento.html",
    "href": "andamento.html",
    "title": "Andamento do Curso",
    "section": "",
    "text": "Acompanhe o andamento do  Curso de Estatística com R para Experimentação Agrícola."
  },
  {
    "objectID": "andamento.html#aulas-ministradas",
    "href": "andamento.html#aulas-ministradas",
    "title": "Andamento do Curso",
    "section": "Aulas ministradas",
    "text": "Aulas ministradas\nAcompanhe o andamento das aulas minitradas no curso.\nAs aulas foram estruturadas de forma progressiva, para que cada etapa sirva de base para a seguinte.\n\n\n\nAulas ministradas no Curso de Estatística com R para Experimentação Agrícola.\n\n\nAula\nDescrição\nData\nHorário de nício da aula\nHorário de fim da aula\nNúmero de horas\nAssunto\n\n\n\n\nAula 1\nPrimeiros passos no R e Rstudio.\n03/set/2025\n16:00\n17:10\n1.17\nInstalação e atualização do R; Instalação e atualização do RStudio; Apresentação da interface do RStudio; Criação e salvamento do primeiro script; Definição do diretório de trabalho (working directory) (setwd(); getwd()).\n\n\nAula 2\nConhecendo o RStudio e os tipos de variáveis no R\n04/set/2025\n10:00\n11:07\n1.12\nConhecendo os principais painéis do RStudio (Console , Editor/Script; Environment/History; Files/Plots/Packages/Help/Viewer); Comparar a diferença entre escrever direto no Console e salvar no Script; Reconhecendo os tipos de variáveis no Excel (numéricas, contínuas, discretas, categóricas, texto, data etc.).\n\n\nAula 3\nDiscussão sobre tipos de variáveis e desenho de experimentos.\n10/set/2025\n16:00\n17:20\n1.33\nReconhecendo os tipos de variáveis no exerimento no Excel; Como organizar os dados no Excel; Entendo sobre variáveis dependentes e independentes; Entendendo sobre fatores e níveis de fatores; Discussão sobre desenho de experimento (simples e fatorial) e analises estatísticas (paramétrica, não-paramétrica, análise univariada, bivariada e multivariada).\n\n\nAula 4\nInstalação e ativação de pacotes e importação de dados.\n12/set/2025\n15:30\n18:00\n2.50\nInstalação e ativação de pacotes; Importação de dados do excel (.xlsx); Visualização da estrutura e resumo dos dados (str(), glimpse(), summary(), View); Limpesa e organização dos dados; Organização dos nomes das variáveis usando clean_names() do pacote janitor; Reconhecimento de tipos de variáveis; Conversão de variáveis character em factor usando as.factor()."
  },
  {
    "objectID": "andamento.html#script-do-curso",
    "href": "andamento.html#script-do-curso",
    "title": "Andamento do Curso",
    "section": "Script do curso",
    "text": "Script do curso\nBaixe o script do curso e treine a progrmação em  utilizando o RStudio.\n\nCurso: Curso de Estatística com R para Experimentação Agrícola\nAutor: DSc. Marlenildo Ferreira Melo\nData: 03 de setembro de 2025\n\n Baixar script_cursoder.R\n Ver no GitHub\n\n\nMostrar/Ocultar script\n#' SCRIPT PARA ANÁLISE DE DADOS EXPERIMENTAIS EM R\n#' \n#' Curso: [Curso de Estatística com R para Experimentação Agrícola]\n#' Autor: [DSc. Marlenildo Ferreira Melo]\n#' Data: [03 de setembro de 2025]\n#' Versão do R: [R version 4.5.1 (2025-06-13 ucrt)]\n#' Versão do RStudio: [2025.05.1 Build 513]\n#' \n#' Objetivo: Análise de dados experimentais utilizando pacotes específicos em R\n#' Descrição: Este script cobre desde a instalação e carregamento de pacotes,\n#' importação e organização de dados, até a realização de análises estatísticas\n#' como estatísticas descritivas e análise de variância (ANOVA).\n#' Requisitos: R e RStudio instalados, pacotes necessários instalados\n\n\n#' ============================================================================\n# Aula 1. Introdução ao R e Rstudio----\n#' ===========================================================================\n#' Data: [03/set/2025]\n#'\n## 1.1 Primeiros passos----\n#' Instalação e atualização do R;\n#' Instalação e atualização do RStudio;\n#' Apresentação da interface do RStudio;\n#' Criação e salvamento do primeiro script;\n#'\n## 1.2. Diretório de trabalho----\n#' Definição do diretório de trabalho (working directory) \n#' Defina o diretório de trabalho para o local onde seus arquivos estão armazenados.\n#' Altere o caminho abaixo para o diretório desejado no seu computador.\n#' Exemplo de caminho no Windows: (\"C:/Users/SeuUsuario/Documentos/ProjetoR\")\n#' Use barras normais (/) ou duplas (\\\\) no Windows\n\nsetwd(\"C:/Users/marle/OneDrive/Documentos/Projetos R/site/logo_script\")\nsetwd(\"C:\\\\Users\\\\marle\\\\OneDrive\\\\Documentos\\\\Projetos R\\\\site\\\\logo_script\")\ngetwd() # Verifica o diretório de trabalho atual\n\n\n#' ============================================================================\n# Aula 2. Conhecendo o RStudio----\n#' ============================================================================\n#' Data: [04/set/2025]\n#'\n## 2.1 Conhecendo os paíneís do RStudio\n#' Console , Editor/Script; Environment/History; Files/Plots/Packages/Help/Viewer);\n#' Comparar a diferença entre escrever direto no Console e salvar no Script;\n#'\n## 2.2 Reconhecendo tipos de variáveis\n#' Reconhecendo os tipos de variáveis no Excel:\n#' numéricas (contínuas, discretas)\n#' categóricas (nominal e ordinal, fatores)\n#' texto livre\n#' data\n#' lógica (*boolean*) (VERDADEIRO/FALSO)\n\n\n#' ============================================================================\n# Aula 3. Instalando e carregando pacotes no R----\n#' ============================================================================\n#' Data: [10/set/2025]\n\n## 3.1 Instalando pacotes----\n\n### 3.1.1 Instalação individual de pacotes----\ninstall.packages(\"tidyverse\")   # Para manipulação e visualização de dados\ninstall.packages(\"dplyr\")       # Para manipulação e visualização de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e análise de experimentos agrícolas\ninstall.packages(\"easyanova\")   # Para facilitar análises de variância\ninstall.packages(\"rstatix\")     # Para estatísticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estatísticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organização de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\n### 3.1.2 Instalando pacotes de uma vez só----\ninstall.packages(\n  \"tidyverse\",\n  \"readxl\",\n  \"ExpDes.pt\",\n  \"easyanova\",\n  \"rstatix\",\n  \"emmeans\",\n  \"janitor\",\n  \"kableExtra\"\n)\n\n## 3.2 Carregando pacotes----\n\n#' Pacotes para manipulação e leitura de dados\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipulação de dados\nlibrary(readxl)      # Para importar planilhas Excel\nlibrary(readr)       # Para importar arquivos de texto\n\n#' Pacotes para análise de experimentos\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n#' Pacotes para estatística e pós-testes\nlibrary(rstatix)     # Testes estatísticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # Médias ajustadas e comparações múltiplas\n\n#' Pacotes para organização e visualização de dados\nlibrary(janitor)     # Limpeza e organização de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n## 3.3 Importando dados ara o R----\n\n### 3.3.1 Importando dados de um arquivo Excel usando pacote readxl----\ndados_ruins_dic &lt;- read_excel(\"C:\\\\Users\\\\marle\\\\OneDrive\\\\Documentos\\\\Projetos R\\\\site\\\\files\\\\dados_ruins_dic.xlsx\", sheet = \"Planilha1\")\n\n### 3.3.2 Importando dados de um arquivo .txt (arquivo de texo bloco de notas) usando pacote readr----\ndados_ruins_dic &lt;- read_delim(\"C:\\\\Users\\\\marle\\\\OneDrive\\\\Documentos\\\\Projetos R\\\\site\\\\files\\\\dados_ruins_dic.txt\", \n                              delim = \"\\t\", escape_double = FALSE, \n                              trim_ws = TRUE)\n\n\n\ndados_ruins_dic # Visualização rápida no console\n\nView(dados_ruins_dic) # Visualização em uma aba separada\n#' ============================================================================\n# 5. Renomear colunas específicas----\n#' ============================================================================\n\n## 5.1 Usando pacote dplyr----\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    tratamento = Tratamento,\n    repeticao = `Repetição`,\n    altura_planta_cm = `Altura da planta (cm)`,\n    peso_fresco_g = `Peso fresco (g)`\n  )\n\ndados_organizados_dplyr\n\n## 5.2 Usando pacote janitor----\n#' formato \"snake_case\"\n\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt;\n  janitor::clean_names()\n\ndados_organizados_janitor\n\n\n#' ============================================================================\n# 6. Visualizando os dados----\n#' ============================================================================\n\n## 6.1 Visualização dos dados originais----\n\ndados_organizados_janitor # Visualização rápida no console\nView(dados_organizados_janitor) # Visualização em uma aba separada (Atalho F2)\nhead(dados_organizados_janitor) # Primeiras linhas dos dados\ntail(dados_organizados_janitor) # Últimas linhas dos dados\nnames(dados_organizados_janitor) # Nomes das colunas\n\n## 6.2 Visualização da estrutura dos dados e resumo estatístico----\n\nstr(dados_organizados_janitor) # Estrutura dos dados\nglimpse(dados_organizados_janitor) # Visão geral dos dados (dplyr)\nsummary(dados_organizados_janitor) # Resumo estatístico dos dados\n\n  \n#' ============================================================================\n# 7. Convertendo variáveis em fatores----\n#' ===========================================================================\n  \n## 7.1 Usando a função `as.factor()`----\n  \ndados_organizados_janitor$tratamento &lt;- as.factor(dados_organizados_janitor$tratamento)\ndados_organizados_janitor$repeticao &lt;- as.factor(dados_organizados_janitor$repeticao)\n  \n  \nstr(dados_organizados_janitor) # Estrutura dos dados\nglimpse(dados_organizados_janitor) # Visão geral dos dados (dplyr)\nsummary(dados_organizados_janitor) # Resumo estatístico dos dados\n  \n##' 7.2 Usando a função `convert_as_factor` do pacote rstatix----\n  \ndados_organizados_janitor &lt;- dados_organizados_janitor |&gt;\n  convert_as_factor(tratamento, repeticao)\n  \n  \nstr(dados_organizados_janitor) # Estrutura dos dados\nglimpse(dados_organizados_janitor) # Visão geral dos dados (dplyr)\nsummary(dados_organizados_janitor) # Resumo estatístico dos dados\n\n\n#' ============================================================================\n# 8. Conhecendo os tipos de variáveis no R----\n#' ============================================================================\n\n#' Exemplo de banco de dados com todos os tipos de variáveis\n#'   em experimentação agrícola (Delineamento em Blocos Casualizados)\ndados_tipos &lt;- read_excel(\"dados_tipos.xlsx\", sheet = \"Planilha1\")\n\n  \n# Conferindo estrutura e resumo do banco\nstr(dados_tipos)          # Estrutura das variáveis\nglimpse(dados_tipos)      # Visão geral das variáveis com dplyr\nsummary(dados_tipos)      # Resumo estatístico dos dados\n  \n  \n# Renomeando colunas para facilitar o manuseio  \ndados_tipos_organizado &lt;- dados_tipos |&gt;\n    janitor::clean_names()\n\n# Visualizando parte do banco\nhead(dados_tipos_organizado) |&gt; view()\n\n\n#' EXPLICAÇÃO DOS TIPOS DE VARIÁVEIS\n\n#' 1) bloco -&gt; Variável numérica inteira (discreta)\n#' Representa os blocos do experimento (repetições). É usada para controlar\n#' a variabilidade do campo. No R, aparece como \"numeric\" (ou \"integer\").\n\n#' 2) tipo_adubo -&gt; Variável de texto (character), pode ser transformada em fator\n#' Representa a descrição do tratamento aplicado.\n#' Exemplo: \"Testemunha\", \"Adubo verde\".\n\n#' 3) tratamento -&gt; Variável categórica nominal (factor)\n#' É o identificador do tratamento (T1, T2, ...).\n#' Não tem ordem lógica, apenas categorias distintas.\n\n#' 4) data_coleta -&gt; Variável do tipo Date\n#' Representa a data em que os dados foram coletados.\n\n#' 5) nota_vigor -&gt; Variável ordinal\n#' Escala de 1 a 5 indicando o vigor da planta.\n#' Existe uma ordem (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\n#' 6) numero_folhas -&gt; Variável numérica inteira (discreta)\n#' Conta o número de folhas da planta.\n#' Só assume valores inteiros (5, 6, 7...).\n\n#' 7) altura_cm -&gt; Variável numérica contínua\n#' Medida da altura em centímetros.\n#' Pode assumir qualquer valor real dentro de um intervalo.\n\n#' 8) sobreviveu -&gt; Variável lógica (boolean)\n#' Indica se a planta sobreviveu (TRUE) ou morreu (FALSE).\n\n#' 9) observacao -&gt; Variável categórica nominal\n#' Anotações pré-definidas sobre a planta: \"Normal\", \"Doença\", \"Atraso\".\n#' Não existe ordem entre as categorias.\n\n#' 10) comentario_livre -&gt; Variável de texto livre (character)\n#' Comentários mais detalhados feitos pelo avaliador.\n#' Exemplo: \"Necessita irrigação extra\", \"Presença de pragas\".\n\n#' ============================================================================\n# 9. Convertendo variáveis em fatores no banco 'dados_tipos' ----\n#' ============================================================================\n\n# Carregando pacote necessário\nlibrary(rstatix)\nlibrary(dplyr)\n\n## 9.1 Usando a função `as.factor()` ----\n\n# Convertendo variáveis categóricas para fator\ndados_tipos_organizado$tipo_de_adubo &lt;- as.factor(dados_tipos_organizado$tipo_de_adubo)\ndados_tipos_organizado$tratamento &lt;- as.factor(dados_tipos_organizado$tratamento)\ndados_tipos_organizado$observacao &lt;- as.factor(dados_tipos_organizado$observacao)\ndados_tipos_organizado$bloco &lt;- as.factor(dados_tipos_organizado$bloco) # opcional: bloco também como fator\n\n# Conferindo estrutura e resumo do banco\nstr(dados_tipos_organizado)          # Estrutura das variáveis\nglimpse(dados_tipos_organizado)      # Visão geral das variáveis com dplyr\nsummary(dados_tipos_organizado)      # Resumo estatístico dos dados\n\n#' Estrutura geral do banco\ndados_tipos_organizado |&gt; view() # com v minúsculo - Visualização em uma aba separada (Atalho F2)\ndados_tipos_organizado |&gt; View() # com v maiúsculo - Visualização em uma aba separada (Atalho F2)\ndados_tipos_organizado |&gt;  str() # Estrutura das variáveis\ndados_tipos_organizado |&gt; glimpse() # Visão geral dos dados (dplyr)\ndados_tipos_organizado |&gt; summary() # Resumo estatístico dos dados\n\n\n\n## 9.2 Usando a função `convert_as_factor()` do pacote rstatix ----\n\n# Conversão das variáveis categóricas para fatores de forma mais prática\ndados_tipos &lt;- dados_tipos %&gt;%\n  convert_as_factor(tipo_adubo, tratamento, observacao, bloco)\n\n# Conferindo novamente\nstr(dados_tipos)          # Estrutura das variáveis\nglimpse(dados_tipos)      # Visão geral com dplyr\nsummary(dados_tipos)      # Resumo estatístico\n\n\n#' ============================================================================\n# 10. Estatísticas descritivas----\n#' ===========================================================================\n\n## 10.1 Estatísticas descritivas gerais usando pacote dplyr----\n\n#' Média geral\ndados_organizados_janitor |&gt;\n  summarise(\n    n = n(),  # Contagem total de observações\n    media_altura = mean(altura_da_planta_cm, na.rm = TRUE),  # Média da altura\n    sd_altura = sd(altura_da_planta_cm, na.rm = TRUE),      # Desvio padrão da altura\n    media_peso = mean(peso_fresco_g, na.rm = TRUE),      # Média do peso fresco\n    sd_peso = sd(peso_fresco_g, na.rm = TRUE)           # Desvio padrão do peso fresco\n  )\n\n#' Média por tratamento\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  summarise(\n    n = n(),  # Contagem total de observações\n    media_altura = mean(altura_da_planta_cm, na.rm = TRUE),  # Média da altura\n    sd_altura = sd(altura_da_planta_cm, na.rm = TRUE),      # Desvio padrão da altura\n    media_peso = mean(peso_fresco_g, na.rm = TRUE),      # Média do peso fresco\n    sd_peso = sd(peso_fresco_g, na.rm = TRUE)           # Desvio padrão do peso fresco\n  )\n\n## 10.2 Estatísticas descritivas usando pacote rstatix----\n\n#' Estatísticas descritivas gerais *média e desvio-padrão*\ndados_organizados_janitor |&gt;\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g, type = \"mean_sd\")\n\n#' Estatísticas descritivas por tratamento *média e desvio-padrão*\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g, type = \"mean_sd\")\n\n#' Estatísticas descritivas por tratamento *média e erro-padrão*\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g, type = \"mean_se\")\n\n#' Estatísticas descritivas completas por tratamento\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g)\n\n\n\n\n#' ============================================================================\n# 11. Análise de variância (ANOVA)----\n#' ===========================================================================\n\n## 11.1 Usando a função `aov()`----\nmodelo &lt;- aov(altura_da_planta_cm  ~ tratamento, data = dados_organizados_janitor)\nsummary(modelo)\n\n## 11.2 Usando a função `anova_test` do pacote rstatix----\ndados_organizados_janitor |&gt; anova_test(altura_da_planta_cm ~ tratamento) \n\n\n## 11.3 Usando a função `dic()` do pacote ExpDes.pt----\n\ndic(\n  trat = dados_organizados_janitor$tratamento,\n  resp = dados_organizados_janitor$altura_da_planta_cm,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n## 11.4 Usando a função `ea1` do pacote easyanova----\neasyanova::ea1(dados_organizados_janitor[-2], design = 1, plot = 2, list = TRUE)\n\n## 11.5 Usando o pacote easyanova (ANOVA)----\n\n\n## 11.6 Usando o pacote ExpDes.pt (DIC)----\n\n#' ANOVA para DIC\n#' O pacote ExpDes.pt é específico para experimentos agrícolas\n#' e facilita a análise de delineamentos experimentais comuns.\n#' Ele é especialmente útil para análises de variância (ANOVA)\n#' em delineamentos inteiramente casualizados (DIC),\n#' delineamentos em blocos casualizados (DBC),\n#' parcelas subdivididas, entre outros.\n#' Ele também oferece funções para realizar testes complementares,\n#' como o teste de Tukey, e para gerar gráficos básicos.\n#' #' A função `dic()` do pacote ExpDes.pt é usada para realizar a análise de variância (ANOVA)\n#' em um delineamento inteiramente casualizado (DIC).\n#' Ela calcula a ANOVA para uma variável resposta em função de um fator de tratamento,\n#' considerando as repetições do experimento.\n#' #' A função também pode realizar testes complementares, como o teste de Tukey,\n#' para comparar as médias dos tratamentos.\n#' #' A sintaxe básica da função `dic()` é a seguinte:\n#' #' ```R\n#' dic(response, treatment, block = NULL, quali = NULL, mcomp = \"tukey\", sigT = 0.05, sigF = 0.05, group = TRUE, console = TRUE)\n#' \n#' \n\n\n\n\n\n#'  ============================================================================\n#'  Fim do Script\n#'  ============================================================================"
  },
  {
    "objectID": "andamento.html#faça-as-atividades-propostas",
    "href": "andamento.html#faça-as-atividades-propostas",
    "title": "Andamento do Curso",
    "section": "Faça as atividades propostas",
    "text": "Faça as atividades propostas\n\nDesafios e exercícios à frente!\n\nDesenvolva as atividades a seguir e fortaleça suas habilidades em R.\n\nAtividade 1\nNesta atividade você deverá buscar um banco de dados, exportar para o Excel e, dentro do Excel, identificar os tipos de variáveis.\n\nProcure e selecione um banco de dados (de sites abertos ou de outra fonte confiável).\n\nExporte o banco de dados para o Excel (formato .xlsx).\n\nAbra o banco no Excel.\n\nAnalise cada coluna e classifique o tipo de variável:\n\nNumérica (valores inteiros ou decimais)\n\nTexto / Caractere (nomes, palavras, descrições)\n\nLógica (valores Verdadeiro/Falso ou Sim/Não)\n\nCategórica / Fator (classes ou categorias, como tratamentos, cidades, espécies etc.)\n\n\nCrie uma tabela resumo no Excel com as seguintes colunas:\n\nNome da variável\n\nTipo identificado\n\nJustificativa (por que é desse tipo)\n\n\n\n👉 Essa atividade vai treinar a percepção dos diferentes tipos de variáveis e a organização de informações em planilhas."
  },
  {
    "objectID": "codigos.html",
    "href": "codigos.html",
    "title": "Primeiros passos",
    "section": "",
    "text": "Instale o R e o RStudio em seu computador.\n\n\nO R é o programa principal, ou seja, a linguagem de programação e o ambiente de cálculo.\nÉ nele que todos os comandos são processados e as análises estatísticas são realizadas.\nPor isso, o primeiro passo é instalar o R no computador.\nO download deve ser feito diretamente no site oficial do CRAN (Comprehensive R Archive Network):\n https://cran.r-project.org/\nAo abrir o link, basta escolher o sistema operacional do seu computador (Windows, macOS ou Linux) e seguir as instruções de instalação.\nCom isso, você já terá o R funcionando, embora a sua interface seja bastante simples e pouco intuitiva para quem está começando.\nÉ justamente nesse ponto que entra o RStudio.\nO RStudio não é um programa separado do R, mas sim uma IDE (Integrated Development Environment), ou seja, um ambiente de desenvolvimento que facilita o uso do R.\nEle oferece uma interface gráfica amigável, onde você pode escrever códigos, visualizar gráficos, organizar projetos e instalar pacotes com muito mais facilidade.\nNo entanto, é fundamental compreender que o RStudio não funciona sozinho.\nEle depende do R já instalado na máquina, pois é o R quem executa de fato os cálculos.\nPor isso, a ordem correta é: primeiro instalar o R e, em seguida, instalar o RStudio.\nO download do RStudio pode ser feito no site oficial da Posit (empresa responsável pelo software):\n👉 https://posit.co/download/rstudio-desktop/\nAo instalar os dois programas, você terá o R como motor de cálculo e o RStudio como painel de controle, trabalhando em conjunto.\nEssa combinação é a mais utilizada no mundo acadêmico e profissional para análises estatísticas e ciência de dados.\n\nConheça os principais painéis do RStudio:\n\nConsole (execução de comandos)\n\nSource (script)\n\nEnvironment/History (objetos)\n\nPlots/Packages/Help\n\n\nVerificando versão do R\n\n# Verificando versão do R\nversion\n\n               _                                \nplatform       x86_64-w64-mingw32               \narch           x86_64                           \nos             mingw32                          \ncrt            ucrt                             \nsystem         x86_64, mingw32                  \nstatus                                          \nmajor          4                                \nminor          4.2                              \nyear           2024                             \nmonth          10                               \nday            31                               \nsvn rev        87279                            \nlanguage       R                                \nversion.string R version 4.4.2 (2024-10-31 ucrt)\nnickname       Pile of Leaves                   \n\n\nCitando o R\n\n# Citação do R\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nUma entrada BibTeX para usuários(as) de LaTeX é\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nOperações simples\n\n# Operações simples\n\n## Soma\n2 + 2\n\n[1] 4\n\n## Subtração\n7 - 2\n\n[1] 5\n\n## Mutiplicação\n4 * 3\n\n[1] 12\n\n## Divisão\n10 / 3\n\n[1] 3.333333\n\n## Raiz quadrada\nsqrt(25)\n\n[1] 5\n\n\n\n\n\n\nNesta aula, aprendemos a criar e manipular objetos no R. Objetos são variáveis que armazenam valores ou resultados de cálculos, permitindo que possamos reutilizá-los em outras operações.\nNo exemplo apresentado, criamos dois objetos numéricos:\n\n# Criando objetos\nx &lt;- 5\ny &lt;- 10\n\nAqui, x recebe o valor 5 e y recebe o valor 10. Em seguida, criamos um terceiro objeto chamado soma, que armazena a soma de x e y:\n\nsoma &lt;- x + y\nsoma\n\n[1] 15\n\n\nAo digitar apenas soma, o R retorna o valor armazenado neste objeto, que neste caso é 15.\nEste exemplo ilustra a forma básica de criar objetos no R e realizar operações simples com eles, fundamental para qualquer análise de dados ou programação no software.\n\n\n\n\nNo R, os pacotes são conjuntos de funções, dados e recursos que estendem as capacidades básicas do software, permitindo realizar análises mais complexas de forma prática e eficiente.\nNo exemplo abaixo, veja como instalar alguns pacotes importantes um de cada vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\")   # Para manipulação e visualização de dados\ninstall.packages(\"dplyr\")   # Para manipulação e visualização de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e análise de experimentos agrícolas\ninstall.packages(\"easyanova\")   # Para facilitar análises de variância\ninstall.packages(\"rstatix\")     # Para estatísticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estatísticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organização de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\nOuse preferir pode instalar vários de uma única vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\", \"readxl\", \"ExpDes.pt\", \"easyanova\", \"rstatix\", \"emmeans\", \"janitor\", \"kableExtra\")\n\nNo exemplo abaixo, carregamos alguns pacotes importantes:\n\n# Carregando pacotes\n\n# ---------------------------\n# Pacotes para manipulação e leitura de dados\n# ---------------------------\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipulação de dados\nlibrary(readxl)      # Para importar planilhas Excel\n\n# ---------------------------\n# Pacotes para análise de experimentos\n# ---------------------------\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n# ---------------------------\n# Pacotes para estatística e pós-testes\n# ---------------------------\nlibrary(rstatix)     # Testes estatísticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # Médias ajustadas e comparações múltiplas\n\n# ---------------------------\n# Pacotes para organização e visualização de dados\n# ---------------------------\nlibrary(janitor)     # Limpeza e organização de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n\n\n\n\nUm dos passos mais importantes em qualquer análise é a organização adequada dos dados. Dados desorganizados ou com nomes de variáveis inconsistentes podem dificultar o trabalho, aumentar a chance de erros e até inviabilizar o uso de funções em softwares estatísticos como o R.\nVeja esse esse exmeplo de banco de dados (dados_ruins_dic) no Excel:\n\n\n\n\n\nRepetição\nTratamento\nAltura da planta (cm)\nMatéria seca (g)\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nImportância de bons títulos nas variáveis\nNo R, os nomes das colunas (ou títulos das variáveis) devem seguir algumas boas práticas para facilitar a análise:\n\nPadrão snake_case: usar letras minúsculas e sublinhados para separar palavras, como altura_planta_g.\nEvitar espaços: em vez de Altura da Planta, utilizar Altura_Planta.\n\nUsar unidades no nome da variável: em vez de Altura da Planta (cm), utilizar Altura_Planta_cm.\n\nUsar letras minúsculas (ou padrão definido): altura_planta_cm.\n\nEvitar acentos e caracteres especiais: em vez de Matéria seca (g), utilizar materia_seca_g.\n\nSer descritivo, mas não excessivamente longo: peso_frutos em vez de pf_colheita_experimental_2024.\n\nEsses cuidados tornam o banco de dados mais limpo, reprodutível e compatível com funções e pacotes do R.\nComo organizar os títulos\n\nPode fazer manulamente no Excel\n\nAntes de importar o arquivo para o R, pode-se renomear diretamente no Excel.\n\nExemplo: renomear a coluna de Massa seca total (g) para massa_seca_total_g.\n\nManualmente no R usando o pacote dplyr\n\nA função rename() do pacote dplyr permite renomear manualmente colunas específicas.\n\n# Renomear colunas específicas\nlibrary(dplyr)\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    repeticao = `Repetição`,\n    tratamento = Tratamento,\n    altura_planta_cm = `Altura da planta (cm)`,\n    materia_seca_g = `Matéria seca (g)`\n  )\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repetição\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Matéria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_dplyr)\n\n[1] \"repeticao\"        \"tratamento\"       \"altura_planta_cm\" \"materia_seca_g\"  \n\n\n\nAutomático usando o pacote janitor\nExistem pacotes que auxiliam na padronização dos nomes de maneira automática:\n\nPacote janitor: a função clean_names() desse pacote converte automaticamente os títulos para um formato padrão (snake_case).\n\n\nVeja o que acontece com esse banco de dados (dados_ruins_dic):\n\n# Corrigir nomes das colunas -&gt; formato \"snake_case\"\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt; \n  janitor::clean_names()\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_da_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repetição\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Matéria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_janitor)\n\n[1] \"repeticao\"           \"tratamento\"          \"altura_da_planta_cm\"\n[4] \"materia_seca_g\"     \n\n\n\n\n\n\nImportando dados\nImportar dados para o R é um passo fundamental para qualquer análise. No R, é possível importar dados de diferentes formatos, o que é essencial para iniciar qualquer análise. O R permite ler diferentes formatos de arquivos, como CSV e Excel.\n\n# Importando CSV\n# dados_csv &lt;- read.csv(\"meus_dados.csv\", sep = \";\", dec = \",\")\n# Lê arquivos CSV, permitindo especificar o separador de colunas (sep) e o separador decimal (dec)\n\n# Importando Excel\n# dados_excel &lt;- readxl::read_excel(\"meus_dados.xlsx\")\n# Lê planilhas do Excel diretamente para o R\n\n# Importando arquivo de texto (TXT)\n# dados_txt &lt;- read.table(\"meus_dados.txt\", header = TRUE, sep = \"\\t\", dec = \".\")\n# Lê arquivos de texto, onde 'header = TRUE' indica que a primeira linha contém os nomes das colunas,\n# 'sep = \"\\t\"' indica que as colunas são separadas por tabulação, e 'dec = \".\"' define o separador decimal\n\n\nread.csv() lê arquivos no formato CSV (Comma-Separated Values), permitindo especificar o separador de colunas (sep) e o separador decimal (dec). É indicado para planilhas exportadas como CSV ou dados gerados por outros programas.\nread_excel() (do pacote readxl) lê arquivos do Excel (.xls ou .xlsx) diretamente, mantendo nomes das colunas e tipos de dados corretamente, o que facilita a importação de planilhas complexas sem precisar convertê-las.\nread.table() lê arquivos de texto simples (TXT ou outros delimitados), oferecendo flexibilidade para especificar se há cabeçalho (header = TRUE), o separador de colunas (sep) e o separador decimal (dec). É ideal para arquivos de texto com diferentes formatos de separação.\n\nVisualizando os dados\nApós a importação, podemos visualizar os dados para verificar se foram carregados corretamente: Após a importação, é importante visualizar os dados para conferir se foram carregados corretamente. Para isso, podem ser usadas funções como:\n\nhead() (exibe as primeiras linhas),\nsummary() (mostra resumo estatístico das variáveis),\nstr() (mostra a estrutura do objeto) e\nglimpse() (exibe de forma compacta e legível a estrutura e os tipos das variáveis).\n\n\n# head(dados_csv)    # Mostra as primeiras linhas do conjunto de dados\n# summary(dados_csv) # Mostra um resumo estatístico das variáveis\n# str(dados_csv)     # Mostra a estrutura do objeto, incluindo tipos de variáveis e dimensões\n# glimpse(dados_csv)  # Mostra todas as variáveis, seus tipos e algumas observações de cada coluna\n\n\n\n\n\n\n\n\n\nVariáveis numéricas\n\nContínuas (numeric / dbl): podem assumir qualquer valor dentro de um intervalo, incluindo decimais.\nExemplo: Produtividade (t/ha), Área (m²)\nDiscretas (integer / int): assumem apenas valores inteiros.\nExemplo: Parcela (identificador das parcelas)\n\nVariáveis categóricas (fatores) (factor / fct)\n\nRepresentam categorias ou grupos que o R reconhece para análises estatísticas.\nExemplo: Tratamento, Variedade\n\nIdeais para análise de variância e comparações entre grupos\n\nVariáveis de texto (character / chr)\n\nContêm informações textuais ou descritivas, que não têm ordem ou significado numérico.\nExemplo: Local (Norte, Sul, Leste)\n\nNão são usadas diretamente em cálculos estatísticos, mas servem para identificar ou agrupar dados\n\nVariáveis lógicas (logical / logi)\n\nAssumem apenas dois valores: TRUE ou FALSE\nExemplo: Irrigado\n\nÚteis para condições, filtros e análises condicionais\n\nOutros tipos disponíveis em R\n\nComplexo (complex / sem abreviação comum): números complexos, como 1+2i\nRaw (raw / sem abreviação comum): representa dados brutos em bytes\n\nDate (Date / sem abreviação comum): datas no formato \"YYYY-MM-DD\"\n\nPOSIXct / POSIXlt (POSIXct / POSIXlt): datas e horas com tempo\nOrdered factor (ordered / ord): fatores com ordem natural definida\n\n\n\nNeste exemplo, iremos criar variáveis de diferentes tipos em R — numéricas contínuas, numéricas discretas e categóricas (fatores) — e, em seguida, identificar o tipo de cada variável usando a função class().\nIsso nos permite compreender como o R armazena cada tipo de dado e como ele será tratado em análises estatísticas.\n\n# Numérica contínua\nnum_cont &lt;- 3.5      # numeric / dbl\nclass(num_cont) # Checando classes\n\n[1] \"numeric\"\n\n# Numérica discreta\nnum_disc &lt;- 5L       # integer / int\nclass(num_disc)\n\n[1] \"integer\"\n\n# Fator (categórica)\ntrat &lt;- factor(c(\"T1\", \"T2\", \"T3\"))  # factor / fct\nclass(trat)\n\n[1] \"factor\"\n\n# Ordered factor\nord_trat &lt;- factor(c(\"Baixo\", \"Médio\", \"Alto\"), ordered = TRUE) # ordered / ord\nclass(ord_trat)\n\n[1] \"ordered\" \"factor\" \n\n# Character\nlocal &lt;- c(\"Norte\", \"Sul\")  # character / chr\nclass(local)\n\n[1] \"character\"\n\n# Lógica\nirr &lt;- c(TRUE, FALSE)       # logical / logi\nclass(irr)\n\n[1] \"logical\"\n\n# Complexo\ncplx &lt;- 1 + 2i              # complex\nclass(cplx)\n\n[1] \"complex\"\n\n# Raw\nr &lt;- charToRaw(\"A\")         # raw\nclass(r)\n\n[1] \"raw\"\n\n# Datas\nd &lt;- as.Date(\"2025-08-29\")  # Date\nclass(d)\n\n[1] \"Date\"\n\ndt &lt;- as.POSIXct(\"2025-08-29 12:00:00\") # POSIXct\nclass(dt)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\nCriando banco de dados fictício\nNeste exemplo, iremos criar um banco de dados fictício de um experimento agrícola com diferentes tipos de variáveis: numéricas (contínuas e discretas), categóricas, lógicas e de texto.\nEm seguida, iremos visualizar o banco de dados e identificar os tipos de variáveis, para entender como o R armazena cada tipo e como podemos manipulá-las em análises estatísticas.\n\n# Exemplo de banco de dados de experimento agrícola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Numérica discreta (identificação das parcelas)\n  Tratamento = factor(rep(c(\"T1\", \"T2\", \"T3\"), each = 3)), # Fator (categórica nominal)\n  Variedade = factor(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\")), # Fator (categórica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Numérica contínua (m²)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Numérica contínua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # Lógica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\n# Exemplo de banco de dados de experimento agrícola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Numérica discreta (identificação das parcelas)\n  Tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 3), # Fator (categórica nominal)\n  Variedade = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"), # Fator (categórica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Numérica contínua (m²)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Numérica contínua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # Lógica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\nFunções para Visualização e Estrutura de Dados no R\n\nhead(dados_agro)\nMostra as primeiras linhas do conjunto de dados.\n\nÚtil para ter uma visão rápida do conteúdo do banco, verificando se os dados foram importados corretamente.\n\nExemplo de saída:\n\n\n\nhead(dados_agro) \n\n  Parcela Tratamento Variedade Area Produtividade Irrigado Local\n1       1         T1         A   10          30.5     TRUE Norte\n2       2         T1         A   10          32.0     TRUE Norte\n3       3         T1         A   10          31.0     TRUE Norte\n4       4         T2         B   12          28.0    FALSE   Sul\n5       5         T2         B   12          29.5    FALSE   Sul\n6       6         T2         B   12          30.0    FALSE   Sul\n\n\n\n\nstr(dados_agro)\n\nMostra a estrutura do objeto, permitindo entender rapidamente como os dados estão organizados no R.\nCom essa função, é possível:\n\nVer o número de observações (linhas) e o número de variáveis (colunas) do banco de dados, por exemplo, 9 obs. of 7 variables.\n\nIdentificar o tipo de cada variável, como int (inteiro), num (numérico contínuo), Factor (categórica), logi (lógica/boolean) e chr (texto).\n\nConferir alguns valores iniciais de cada coluna, ajudando a verificar se os dados foram importados corretamente e se os tipos estão adequados para análise.\n\nEm resumo, str() é uma função essencial para inspecionar rapidamente a estrutura e os tipos das variáveis, antes de realizar qualquer análise estatística ou manipulação dos dados.\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : chr  \"T1\" \"T1\" \"T1\" \"T2\" ...\n $ Variedade    : chr  \"A\" \"A\" \"A\" \"B\" ...\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nObserve que Tratamento e Variedade aparecem como character, ou seja, texto.\nPara análises estatísticas, é recomendado transformar essas variáveis em fatores.\n\n\nsummary(dados_agro)\n\nMostra um resumo estatístico das variáveis:\n- Para variáveis numéricas: mínimo, máximo, média, quartis\n- Para fatores: contagem de cada nível\n- Para lógicas: contagem de TRUE e FALSE\n- Útil para identificar tendências, valores extremos e distribuição dos dados.\n\nsummary(dados_agro)\n\n    Parcela   Tratamento         Variedade              Area    Produtividade  \n Min.   :1   Length:9           Length:9           Min.   :10   Min.   :28.00  \n 1st Qu.:3   Class :character   Class :character   1st Qu.:10   1st Qu.:30.00  \n Median :5   Mode  :character   Mode  :character   Median :11   Median :31.00  \n Mean   :5                                         Mean   :11   Mean   :31.22  \n 3rd Qu.:7                                         3rd Qu.:12   3rd Qu.:32.50  \n Max.   :9                                         Max.   :12   Max.   :34.50  \n  Irrigado          Local          \n Mode :logical   Length:9          \n FALSE:3         Class :character  \n TRUE :6         Mode  :character  \n                                   \n                                   \n                                   \n\n\nVeja novamente que Tratamento e Variedade aparecem como character.\nE não são reconhecidas como fatores.\nE não é possível perceber quais são os níveis de cada variável categórica.\n\nConvertendo variaveis categóricas em fatores\n\nPode-se convertê-las em fatores usando a função as.factor():\n\n\ndados_agro$Tratamento &lt;- as.factor(dados_agro$Tratamento)\ndados_agro$Variedade &lt;- as.factor(dados_agro$Variedade)\n\nAgora veja como fica a estrutura dos dados:\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : Factor w/ 3 levels \"T1\",\"T2\",\"T3\": 1 1 1 2 2 2 3 3 3\n $ Variedade    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 1 1 2 2 2 3 3 3\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nAgora sim, Tratamento e variedade aparecem como Factor com 3 níveis cada.\nveja como fica o resumo estatístico dos dados:\n\nsummary(dados_agro)\n\n    Parcela  Tratamento Variedade      Area    Produtividade    Irrigado      \n Min.   :1   T1:3       A:3       Min.   :10   Min.   :28.00   Mode :logical  \n 1st Qu.:3   T2:3       B:3       1st Qu.:10   1st Qu.:30.00   FALSE:3        \n Median :5   T3:3       C:3       Median :11   Median :31.00   TRUE :6        \n Mean   :5                        Mean   :11   Mean   :31.22                  \n 3rd Qu.:7                        3rd Qu.:12   3rd Qu.:32.50                  \n Max.   :9                        Max.   :12   Max.   :34.50                  \n    Local          \n Length:9          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nAgora é possível ver a contagem de cada nível das variáveis categóricas. Ou seja, são 3 níveis em cada variável (T1, T2, T3 para Tratamento e A, B, C para Variedade).\n\nPode-se convertê-las em fatores usando a função factor():\n\nTambém dá para criar o fator diretamente com a função factor(), que é mais flexível porque permite:\n\nDefinir os níveis (levels)\nDefinir as etiquetas (labels)\n\nOu seja, permite controlar a ordem e o rótulo dos níveis (mais recomendado para ANOVA e modelos, pois evita ordem alfabética indesejada).\n\nPode-se ainda convertê-las em fatores usando a função convert_as_factor() do pacote {rstatix}:\n\nA função convert_as_factor() pode converter uma ou várias colunas ao mesmo tempo.\n\n\nglimpse(dados_agro) (do pacote dplyr)\n\nMostra a estrutura dos dados de forma compacta e legível, similar ao str(), mas em formato horizontal:\n\nExibe todas as variáveis, seus tipos e algumas observações iniciais\n\nMais fácil de ler quando o banco de dados tem muitas colunas\n\nExemplo de saída (resumida):\n\nglimpse(dados_agro)\n\nRows: 9\nColumns: 7\n$ Parcela       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ Tratamento    &lt;fct&gt; Controle, Controle, Controle, Adubo, Adubo, Adubo, Bioes…\n$ Variedade     &lt;fct&gt; IPA 11, IPA 11, IPA 11, Campo Lindo, Campo Lindo, Campo …\n$ Area          &lt;dbl&gt; 10, 10, 10, 12, 12, 12, 11, 11, 11\n$ Produtividade &lt;dbl&gt; 30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5\n$ Irrigado      &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE\n$ Local         &lt;chr&gt; \"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\",…\n\n\n\n\n\n\n\n# Exemplo fictício\ndados &lt;- data.frame(\n  tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 4),\n  repeticao = rep(1:4, 3),\n  produtividade = c(30, 32, 28, 31, 35, 36, 34, 37, 25, 27, 26, 28)\n)\n\n# Selecionar colunas e filtrar\ndados |&gt; dplyr::select(tratamento, produtividade) |&gt; filter(produtividade &gt; 30)\n\n  tratamento produtividade\n1         T1            32\n2         T1            31\n3         T2            35\n4         T2            36\n5         T2            34\n6         T2            37\n\n# Resumo estatístico\ndados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    media = mean(produtividade),\n    sd = sd(produtividade)\n  )\n\n# A tibble: 3 × 3\n  tratamento media    sd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 T1          30.2  1.71\n2 T2          35.5  1.29\n3 T3          26.5  1.29\n\n\n\n\n\n\n\n# Histograma\nggplot(dados, aes(x = produtividade)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n# Boxplot\nggplot(dados, aes(x = tratamento, y = produtividade)) +\n  geom_boxplot(fill = \"orange\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Primeiro transformar variáveis em fatores\ndados$tratamento &lt;- factor(dados$tratamento)\ndados$repeticao &lt;- factor(dados$repeticao)\n\n# ANOVA usando aov()\nmodelo &lt;- aov(produtividade ~ tratamento, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamento   2 163.50   81.75   39.24 3.59e-05 ***\nResiduals    9  18.75    2.08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd     F        p p&lt;.05   ges\n1 tratamento   2   9 39.24 3.59e-05     * 0.897\n\n# ANOVA usando ExpDes.pt\ndic(\n  trat = dados$tratamento,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM    Fc      Pr&gt;Fc\nTratamento  2 163.50 81.750 39.24 3.5934e-05\nResiduo     9  18.75  2.083                 \nTotal      11 182.25                        \n------------------------------------------------------------------------\nCV = 4.69 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.5375769 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.8663487 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\neasyanova::ea1(dados[-2], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type I SS mean square F value    p&gt;F\ntreatments  2    163.50     81.7500   39.24 &lt;0.001\nResiduals   9     18.75      2.0833       -      -\n\n$Means\n  treatment  mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2 35.50 1.2910 0.7217  34  37     a   a      a a           a\n2        T1 30.25 1.7078 0.7217  28  32     b   b      b b           b\n3        T3 26.50 1.2910 0.7217  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 T2 - T1     5.25   0.0016 0.0006    0.0006 0.0006\n2 T2 - T3     9.00   0.0000 0.0000    0.0000 0.0000\n3 T1 - T3     3.75   0.0128 0.0051    0.0051 0.0051\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                             values\np.value Shapiro-Wilk test    0.5376\np.value Bartlett test        0.8663\ncoefficient of variation (%) 4.6900\nfirst value most discrepant  3.0000\nsecond value most discrepant 2.0000\nthird value most discrepant  8.0000\n\n$`Residual analysis`$residuals\n    1     2     3     4     5     6     7     8     9    10    11    12 \n-0.25  1.75 -2.25  0.75 -0.50  0.50 -1.50  1.50 -1.50  0.50 -0.50  1.50 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n-0.1914854  1.3403980 -1.7233688  0.5744563 -0.3829708  0.3829708 -1.1489125 \n         8          9         10         11         12 \n 1.1489125 -1.1489125  0.3829708 -0.3829708  1.1489125 \n\n\nTestes de Pressupostos\nAntes da análise de variância (ANOVA), foi realizada a verificação dos pressupostos de normalidade dos resíduos e homogeneidade das variâncias, que são condições necessárias para a validade do teste F.\nNormalidade dos resíduos\n\nO teste de Shapiro-Wilk foi aplicado sobre os resíduos do modelo, verificando se a distribuição se aproxima da normal.\nAlém disso, a normalidade foi testada dentro de cada grupo experimental utilizando a função shapiro_test() do pacote rstatix, o que permite avaliar possíveis desvios em tratamentos específicos.\nQuando o valor de p &gt; 0,05, não se rejeita a hipótese nula de normalidade, indicando que os resíduos podem ser considerados normalmente distribuídos.\n\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.94298, p-value = 0.5376\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 × 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n\nHomogeneidade das variâncias\n\nPara verificar se os tratamentos apresentam variâncias homogêneas, foram aplicados três testes:\n\nTeste de Bartlett: sensível a desvios de normalidade, mas adequado quando os dados são normais.\nTeste de Levene: mais robusto quando a normalidade não é estritamente atendida.\n\n\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n\n\nEm todos os testes, valores de p &gt; 0,05 indicam que não há evidências para rejeitar a hipótese de homogeneidade das variâncias, atendendo ao pressuposto da ANOVA.\n\nDessa forma, a análise de variância pode ser conduzida com confiança, uma vez que os pressupostos de normalidade e homogeneidade foram verificados.\nComparações de Médias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento, data = dados)\n\n$tratamento\n       diff        lwr        upr     p adj\nT2-T1  5.25   2.400421  8.0995788 0.0015767\nT3-T1 -3.75  -6.599579 -0.9004212 0.0127984\nT3-T2 -9.00 -11.849579 -6.1504212 0.0000269\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 × 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# Médias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean    SE df lower.CL upper.CL .group\n T3           26.5 0.722  9     24.4     28.6  a    \n T1           30.2 0.722  9     28.1     32.4   b   \n T2           35.5 0.722  9     33.4     37.6    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nAnova\nNo DBC (delineamento em blocos casualizados) a diferença principal é que você precisa considerar o efeito de blocos no modelo. Seguindo o mesmo estilo da sua aula de DIC, aqui está a versão para DBC:\n\n# ANOVA usando aov()\n# Aqui usamos Error(bloco) ou bloco como efeito\nmodelo &lt;- aov(produtividade ~ tratamento + repeticao, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \ntratamento   2 163.50   81.75 127.957 1.2e-05 ***\nrepeticao    3  14.92    4.97   7.783  0.0172 *  \nResiduals    6   3.83    0.64                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento + repeticao)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd       F       p p&lt;.05   ges\n1 tratamento   2   6 127.957 1.2e-05     * 0.977\n2  repeticao   3   6   7.783 1.7e-02     * 0.796\n\n# ANOVA usando ExpDes.pt\ndbc(\n  trat = dados$tratamento,\n  bloco = dados$repeticao,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ     QM      Fc    Pr&gt;Fc\nTratamento  2 163.500 81.750 127.957 0.000012\nBloco       3  14.917  4.972   7.783 0.017195\nResiduo     6   3.833  0.639                 \nTotal      11 182.250                        \n------------------------------------------------------------------------\nCV = 2.6 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.4793843 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.1530654 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\n# design = 2 corresponde a DBC\neasyanova::ea1(dados, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type III SS mean square  F value    p&gt;F\ntreatments  2    163.5000     81.7500 127.9565 &lt;0.001\nblocks      3     14.9167      4.9722   7.7826 0.0172\nresiduals   6      3.8333      0.6389        -      -\n\n$`Adjusted means`\n  treatment adjusted.mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2         35.50 1.2910 0.3997  34  37     a   a      a a           a\n2        T1         30.25 1.7078 0.3997  28  32     b   b      b b           b\n3        T3         26.50 1.2910 0.3997  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)  p(t)\n1 T2 - T1     5.25   0.0002  1e-04     1e-04 1e-04\n2 T2 - T3     9.00   0.0000  0e+00     0e+00 0e+00\n3 T1 - T3     3.75   0.0014  6e-04     6e-04 6e-04\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                              values\np.value Shapiro-Wilk test     0.4794\np.value Bartlett test         0.8663\ncoefficient of variation (%)  2.6000\nfirst value most discrepant  11.0000\nsecond value most discrepant  3.0000\nthird value most discrepant   2.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n 0.50000000  0.83333333 -0.83333333 -0.50000000  0.25000000 -0.41666667 \n          7           8           9          10          11          12 \n-0.08333333  0.25000000 -0.75000000 -0.41666667  0.91666667  0.25000000 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n 0.8469896  1.4116493 -1.4116493 -0.8469896  0.4234948 -0.7058246 -0.1411649 \n         8          9         10         11         12 \n 0.4234948 -1.2704843 -0.7058246  1.5528142  0.4234948 \n\n\nObservações importantes:\n\nNo aov(), o termo + bloco garante que a variação entre blocos seja considerada.\nNo ExpDes.pt, usamos dbc() no lugar de dic().\nNo easyanova, o argumento design = 2 é usado para DBC.\n\nTestes de Pressupostos\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.93854, p-value = 0.4794\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 × 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n## Teste de ONeill e Mathews\noneilldbc(trat = dados$tratamento, resp = dados$produtividade, bloco = dados$repeticao)\n\n[1] 0.1530654\n\n\nEm DBC também foi realizado Teste de O’Neill e Mathews, específico para experimentos em blocos casualizados (DBC), sendo recomendado como alternativa robusta para esse delineamento.\n\nEm todos os testes, valores de p &gt; 0,05 indicam que não há evidências para rejeitar a hipótese de homogeneidade das variâncias, atendendo ao pressuposto da ANOVA.\n\nComparações de Médias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento + repeticao, data = dados)\n\n$tratamento\n       diff        lwr       upr     p adj\nT2-T1  5.25   3.515829  6.984171 0.0002167\nT3-T1 -3.75  -5.484171 -2.015829 0.0013765\nT3-T2 -9.00 -10.734171 -7.265829 0.0000092\n\n$repeticao\n          diff        lwr         upr     p adj\n2-1  1.6666667 -0.5925501  3.92588339 0.1472526\n3-1 -0.6666667 -2.9258834  1.59255006 0.7441939\n4-1  2.0000000 -0.2592167  4.25921672 0.0796674\n3-2 -2.3333333 -4.5925501 -0.07411661 0.0438895\n4-2  0.3333333 -1.9258834  2.59255006 0.9535148\n4-3  2.6666667  0.4074499  4.92588339 0.0248704\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 × 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# Médias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean  SE df lower.CL upper.CL .group\n T3           26.5 0.4  6     25.2     27.8  a    \n T1           30.2 0.4  6     28.9     31.6   b   \n T2           35.5 0.4  6     34.2     36.8    c  \n\nResults are averaged over the levels of: repeticao \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\n# Exemplo com dois fatores\ndados2 &lt;- expand.grid(\n  adubacao = c(\"A1\", \"A2\"),\n  cultivar = c(\"C1\", \"C2\", \"C3\"),\n  rep = 1:4\n)\n\nset.seed(123)\n\ndados2$produtividade &lt;- rnorm(24, mean = 30, sd = 3)\ndados2$adubacao &lt;- factor(dados2$adubacao)\ndados2$cultivar &lt;- factor(dados2$cultivar)\ndados2$rep &lt;- factor(dados2$rep)\n\n# ANOVA usando aov()\nmodelo2 &lt;- aov(produtividade ~ adubacao * cultivar, data = dados2)\nsummary(modelo2)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nadubacao           1   2.09   2.089   0.217  0.647\ncultivar           2   1.07   0.536   0.056  0.946\nadubacao:cultivar  2  13.72   6.861   0.712  0.504\nResiduals         18 173.43   9.635               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1          adubacao   1  18 0.217 0.647       0.012\n2          cultivar   2  18 0.056 0.946       0.006\n3 adubacao:cultivar   2  18 0.712 0.504       0.073\n\n# ExpDes.pt\nfat2.dic(\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nF1       1   2.089  3 0.21680 0.64708\nF2       2   1.073  2 0.05566 0.94602\nF1*F2    2  13.723  4 0.71212 0.50391\nResiduo 18 173.435  5                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.36 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6606527 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\neasyanova::ea2(dados2[-3], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2168 0.6471\nfactor_2           2      1.0726      0.5363  0.0557  0.946\nfactor_1:factor_2  2     13.7229      6.8614  0.7121 0.5039\nresiduals         18    173.4346      9.6353       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.8961     a   a      a a           a\n2       A2        29.679 3.2191 0.8961     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6471 0.6471    0.6471 0.6471\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.0975     a   a      a a           a\n2       C3       30.0767 3.6356 1.0975     a   a      a a           a\n3       C1       29.6795 1.9564 1.0975     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9982 0.9549    0.9549 0.9549\n2 C2 - C1   0.4862   0.9475 0.9475    0.7709 0.7577\n3 C3 - C1   0.3972   0.9646 0.8009    0.8009 0.8009\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3414 0.3414    0.3414 0.3414\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5146 0.5146    0.5146 0.5146\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6272 0.6272    0.6272 0.6272\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9980 0.9523    0.9523 0.9523\n2 A1.C1 - A1.C2   1.3158   0.8221 0.8221    0.5783 0.5563\n3 A1.C3 - A1.C2   1.1828   0.8533 0.5966    0.5966 0.5966\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8112 0.5430    0.5430 0.5430\n2 A2.C2 - A2.C1   2.2883   0.5605 0.5605    0.3371 0.3109\n3 A2.C3 - A2.C1   0.9275   0.9068 0.6776    0.6776 0.6776\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6607\np.value Bartlett test (factor_1)    0.5289\np.value Bartlett test (factor_2)    0.1309\np.value Bartlett test (treatments)  0.5464\ncoefficient of variation (%)       10.3600\nfirst value most discrepant         6.0000\nsecond value most discrepant       18.0000\nthird value most discrepant         3.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n-2.43335287  0.70247809  5.23998198 -0.68381331 -0.23104847  5.61066714 \n          7           8           9          10          11          12 \n 0.63082268 -2.40217314 -1.49670152 -2.23232439  3.05333372  1.54491366 \n         13          14          15          16          17          18 \n 0.45038842  1.72505871 -1.10366637  4.46540093  0.87463976 -5.43437929 \n         19          20          21          22          23          24 \n 1.35214177 -0.02536366 -2.63961408 -1.54926323 -3.69692502 -1.72120151 \n\n$`Residual analysis`$`standardized residuals`\n           1            2            3            4            5            6 \n-0.886137644  0.255816692  1.908208766 -0.249019664 -0.084139356  2.043198673 \n           7            8            9           10           11           12 \n 0.229722427 -0.874783133 -0.545043662 -0.812930463  1.111911873  0.562600750 \n          13           14           15           16           17           18 \n 0.164014901  0.628202953 -0.401914711  1.626134829  0.318511642 -1.979001121 \n          19           20           21           22           23           24 \n 0.492400316 -0.009236513 -0.961250393 -0.564184702 -1.346284159 -0.626798303 \n\n\n\n\n\n\n\n# ANOVA usando aov()\n# Aqui, bloco é adicionado como efeito de erro\nmodelo_dbc &lt;- aov(produtividade ~ rep + adubacao * cultivar, data = dados2)\nsummary(modelo_dbc)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nrep                3  22.94   7.647   0.762  0.533\nadubacao           1   2.09   2.089   0.208  0.655\ncultivar           2   1.07   0.536   0.053  0.948\nadubacao:cultivar  2  13.72   6.861   0.684  0.520\nResiduals         15 150.49  10.033               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ rep + adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1               rep   3  15 0.762 0.533       0.132\n2          adubacao   1  15 0.208 0.655       0.014\n3          cultivar   2  15 0.053 0.948       0.007\n4 adubacao:cultivar   2  15 0.684 0.520       0.084\n\n# ExpDes.pt\n# fat2.dbc é a função para fatorial em blocos no pacote ExpDes.pt\nfat2.dbc(\n  bloco = dados2$rep,\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nBloco    3  22.942  6 0.76223 0.53264\nF1       1   2.089  4 0.20821 0.65471\nF2       2   1.073  2 0.05345 0.94813\nF1*F2    2  13.723  5 0.68390 0.51971\nResiduo 15 150.493  3                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.57 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6960048 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\n# Em DBC, design = 2 (fatorial em blocos)\neasyanova::ea2(dados2, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2082 0.6547\nfactor_2           2      1.0726      0.5363  0.0535 0.9481\nblocks             3     22.9420      7.6473  0.7622 0.5326\nfactor_1:factor_2  2     13.7229      6.8614  0.6839 0.5197\nresiduals         15    150.4926     10.0328       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.9144     a   a      a a           a\n2       A2        29.679 3.2191 0.9144     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6547 0.6547    0.6547 0.6547\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.1199     a   a      a a           a\n2       C3       30.0767 3.6356 1.1199     a   a      a a           a\n3       C1       29.6795 1.9564 1.1199     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9983 0.9559    0.9559 0.9559\n2 C2 - C1   0.4862   0.9495 0.9495    0.7754 0.7631\n3 C3 - C1   0.3972   0.9660 0.8054    0.8054 0.8054\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3534 0.3534    0.3534 0.3534\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5246 0.5246    0.5246 0.5246\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6353 0.6353    0.6353 0.6353\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9981 0.9534    0.9534 0.9534\n2 A1.C1 - A1.C2   1.3158   0.8288 0.8288    0.5862 0.5656\n3 A1.C3 - A1.C2   1.1828   0.8589 0.6051    0.6051 0.6051\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8182 0.5526    0.5526 0.5526\n2 A2.C2 - A2.C1   2.2883   0.5751 0.5751    0.3481 0.3231\n3 A2.C3 - A2.C1   0.9275   0.9104 0.6846    0.6846 0.6846\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6960\np.value Bartlett test (factor_1)    0.5441\np.value Bartlett test (factor_2)    0.6041\np.value Bartlett test (treatments)  0.8490\ncoefficient of variation (%)       10.5700\nfirst value most discrepant        18.0000\nsecond value most discrepant       16.0000\nthird value most discrepant         6.0000\n\n$`Residual analysis`$residuals\n         1          2          3          4          5          6          7 \n-3.8008383 -0.6650073  3.8724965 -2.0512987 -1.5985339  4.2431817  0.7811775 \n         8          9         10         11         12         13         14 \n-2.2518183 -1.3463467 -2.0819696  3.2036886  1.6952685  0.2874814  1.5621517 \n        15         16         17         18         19         20         21 \n-1.2665734  4.3024939  0.7117327 -5.5972863  2.7321794  1.3546740 -1.2595765 \n        22         23         24 \n-0.1692256 -2.3168874 -0.3411639 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n-1.48588700 -0.25997574  1.51390084 -0.80192786 -0.62492549  1.65881525 \n          7           8           9          10          11          12 \n 0.30539092 -0.88031831 -0.52633627 -0.81391821  1.25243928  0.66274259 \n         13          14          15          16          17          18 \n 0.11238701  0.61070235 -0.49514996  1.68200256  0.27824241 -2.18818437 \n         19          20          21          22          23          24 \n 1.06810906  0.52959170 -0.49241461 -0.06615649 -0.90575620 -0.13337347 \n\n\n\n\n\n\n\n\n\n\ndose &lt;- c(0, 50, 100, 150, 200)\nprod &lt;- c(20, 28, 35, 40, 38)\ndados_reg &lt;- data.frame(dose, prod)\n\nmodelo_reg &lt;- lm(prod ~ dose, data = dados_reg)\na &lt;- summary(modelo_reg)\n\n# Coeficientes\ncoeficientes &lt;- coef(modelo_reg)\nintercepto &lt;- round(coeficientes[1], 2) # sem sinal extra\nslope &lt;- formatC(coeficientes[2], format = \"f\", digits = 2, flag = \"+\") # sempre com sinal\n\n# Estatísticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n\n\n\n# Equação no formato correto\nequacao &lt;- paste0(\"y = \", intercepto, slope, \"x\")\n\nlegenda &lt;- paste0(\n  equacao,\n  \"  R² = \", r2,\n  \"\\nF = \", f_value,\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n\n\ndados_reg |&gt;\n  ggplot(aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  annotate(\"text\",\n           x = 100, y = 10,\n           label = legenda,\n           hjust = 0, size = 5) +\n  labs(x = \"Frequência de irrigação\", y = \"CRA (%)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ajustar modelo de regressão quadrática\nmodelo_quad &lt;- lm(prod ~ dose + I(dose^2), data = dados_reg)\na &lt;- summary(modelo_quad)\na\n\n\nCall:\nlm(formula = prod ~ dose + I(dose^2), data = dados_reg)\n\nResiduals:\n      1       2       3       4       5 \n 0.5429 -0.9714 -0.3429  1.4286 -0.6571 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 19.4571429  1.3021176  14.943  0.00445 **\ndose         0.2217143  0.0308492   7.187  0.01882 * \nI(dose^2)   -0.0006286  0.0001479  -4.250  0.05116 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.384 on 2 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9715 \nF-statistic: 69.21 on 2 and 2 DF,  p-value: 0.01424\n\n# Coeficientes da regressão quadrática (com mais casas decimais)\ncoef_quad &lt;- coef(modelo_quad)\nintercepto &lt;- formatC(coef_quad[1], format = \"f\", digits = 4)\nlinear     &lt;- formatC(coef_quad[2], format = \"f\", digits = 4, flag = \"+\")\nquadratico &lt;- formatC(coef_quad[3], format = \"f\", digits = 4, flag = \"+\") \n# usei 6 casas para o termo quadrático porque geralmente é bem pequeno\n\n# Estatísticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n# Equação para legenda\nequacao &lt;- paste0(\"y = \", intercepto, \" \", linear, \"x \", quadratico, \"x²\")\nlegenda &lt;- paste0(\n  equacao,\n  \"  R² = \", r2,\n  \"\\nF = \", round(f_value, 2),\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n# Gráfico\nlibrary(ggplot2)\n\nregressao_quad &lt;- ggplot(dados_reg, aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  stat_smooth(\n    method = \"lm\",\n    formula = y ~ x + I(x^2),\n    se = FALSE,\n    color = \"black\"\n  ) +\n  annotate(\"text\", x = 50, y = 10, label = legenda, hjust = 0, size = 5) +\n  labs(x = \"Dose\", y = \"Produção\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n# Exibir gráfico\nregressao_quad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste próprio arquivo é um exemplo.\n\nPode ser exportado em HTML, Word ou PDF.\n\n\n\n\n\n\nAnalise um conjunto de dados agrícolas (real ou fornecido):\n- Estruture os dados no Excel/CSV.\n- Importe para o R.\n- Realize ANOVA (com aov(), ExpDes.pt, easyanova e rstatix).\n- Teste pressupostos.\n- Se necessário, ajuste modelos de regressão.\n- Gere gráficos com ggplot2.\n- Organize os resultados em relatório RMarkdown."
  },
  {
    "objectID": "codigos.html#módulo-1-introdução-ao-r-e-organização-de-dados",
    "href": "codigos.html#módulo-1-introdução-ao-r-e-organização-de-dados",
    "title": "Primeiros passos",
    "section": "",
    "text": "Instale o R e o RStudio em seu computador.\n\n\nO R é o programa principal, ou seja, a linguagem de programação e o ambiente de cálculo.\nÉ nele que todos os comandos são processados e as análises estatísticas são realizadas.\nPor isso, o primeiro passo é instalar o R no computador.\nO download deve ser feito diretamente no site oficial do CRAN (Comprehensive R Archive Network):\n https://cran.r-project.org/\nAo abrir o link, basta escolher o sistema operacional do seu computador (Windows, macOS ou Linux) e seguir as instruções de instalação.\nCom isso, você já terá o R funcionando, embora a sua interface seja bastante simples e pouco intuitiva para quem está começando.\nÉ justamente nesse ponto que entra o RStudio.\nO RStudio não é um programa separado do R, mas sim uma IDE (Integrated Development Environment), ou seja, um ambiente de desenvolvimento que facilita o uso do R.\nEle oferece uma interface gráfica amigável, onde você pode escrever códigos, visualizar gráficos, organizar projetos e instalar pacotes com muito mais facilidade.\nNo entanto, é fundamental compreender que o RStudio não funciona sozinho.\nEle depende do R já instalado na máquina, pois é o R quem executa de fato os cálculos.\nPor isso, a ordem correta é: primeiro instalar o R e, em seguida, instalar o RStudio.\nO download do RStudio pode ser feito no site oficial da Posit (empresa responsável pelo software):\n👉 https://posit.co/download/rstudio-desktop/\nAo instalar os dois programas, você terá o R como motor de cálculo e o RStudio como painel de controle, trabalhando em conjunto.\nEssa combinação é a mais utilizada no mundo acadêmico e profissional para análises estatísticas e ciência de dados.\n\nConheça os principais painéis do RStudio:\n\nConsole (execução de comandos)\n\nSource (script)\n\nEnvironment/History (objetos)\n\nPlots/Packages/Help\n\n\nVerificando versão do R\n\n# Verificando versão do R\nversion\n\n               _                                \nplatform       x86_64-w64-mingw32               \narch           x86_64                           \nos             mingw32                          \ncrt            ucrt                             \nsystem         x86_64, mingw32                  \nstatus                                          \nmajor          4                                \nminor          4.2                              \nyear           2024                             \nmonth          10                               \nday            31                               \nsvn rev        87279                            \nlanguage       R                                \nversion.string R version 4.4.2 (2024-10-31 ucrt)\nnickname       Pile of Leaves                   \n\n\nCitando o R\n\n# Citação do R\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nUma entrada BibTeX para usuários(as) de LaTeX é\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nOperações simples\n\n# Operações simples\n\n## Soma\n2 + 2\n\n[1] 4\n\n## Subtração\n7 - 2\n\n[1] 5\n\n## Mutiplicação\n4 * 3\n\n[1] 12\n\n## Divisão\n10 / 3\n\n[1] 3.333333\n\n## Raiz quadrada\nsqrt(25)\n\n[1] 5\n\n\n\n\n\n\nNesta aula, aprendemos a criar e manipular objetos no R. Objetos são variáveis que armazenam valores ou resultados de cálculos, permitindo que possamos reutilizá-los em outras operações.\nNo exemplo apresentado, criamos dois objetos numéricos:\n\n# Criando objetos\nx &lt;- 5\ny &lt;- 10\n\nAqui, x recebe o valor 5 e y recebe o valor 10. Em seguida, criamos um terceiro objeto chamado soma, que armazena a soma de x e y:\n\nsoma &lt;- x + y\nsoma\n\n[1] 15\n\n\nAo digitar apenas soma, o R retorna o valor armazenado neste objeto, que neste caso é 15.\nEste exemplo ilustra a forma básica de criar objetos no R e realizar operações simples com eles, fundamental para qualquer análise de dados ou programação no software.\n\n\n\n\nNo R, os pacotes são conjuntos de funções, dados e recursos que estendem as capacidades básicas do software, permitindo realizar análises mais complexas de forma prática e eficiente.\nNo exemplo abaixo, veja como instalar alguns pacotes importantes um de cada vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\")   # Para manipulação e visualização de dados\ninstall.packages(\"dplyr\")   # Para manipulação e visualização de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e análise de experimentos agrícolas\ninstall.packages(\"easyanova\")   # Para facilitar análises de variância\ninstall.packages(\"rstatix\")     # Para estatísticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estatísticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organização de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\nOuse preferir pode instalar vários de uma única vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\", \"readxl\", \"ExpDes.pt\", \"easyanova\", \"rstatix\", \"emmeans\", \"janitor\", \"kableExtra\")\n\nNo exemplo abaixo, carregamos alguns pacotes importantes:\n\n# Carregando pacotes\n\n# ---------------------------\n# Pacotes para manipulação e leitura de dados\n# ---------------------------\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipulação de dados\nlibrary(readxl)      # Para importar planilhas Excel\n\n# ---------------------------\n# Pacotes para análise de experimentos\n# ---------------------------\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n# ---------------------------\n# Pacotes para estatística e pós-testes\n# ---------------------------\nlibrary(rstatix)     # Testes estatísticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # Médias ajustadas e comparações múltiplas\n\n# ---------------------------\n# Pacotes para organização e visualização de dados\n# ---------------------------\nlibrary(janitor)     # Limpeza e organização de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n\n\n\n\nUm dos passos mais importantes em qualquer análise é a organização adequada dos dados. Dados desorganizados ou com nomes de variáveis inconsistentes podem dificultar o trabalho, aumentar a chance de erros e até inviabilizar o uso de funções em softwares estatísticos como o R.\nVeja esse esse exmeplo de banco de dados (dados_ruins_dic) no Excel:\n\n\n\n\n\nRepetição\nTratamento\nAltura da planta (cm)\nMatéria seca (g)\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nImportância de bons títulos nas variáveis\nNo R, os nomes das colunas (ou títulos das variáveis) devem seguir algumas boas práticas para facilitar a análise:\n\nPadrão snake_case: usar letras minúsculas e sublinhados para separar palavras, como altura_planta_g.\nEvitar espaços: em vez de Altura da Planta, utilizar Altura_Planta.\n\nUsar unidades no nome da variável: em vez de Altura da Planta (cm), utilizar Altura_Planta_cm.\n\nUsar letras minúsculas (ou padrão definido): altura_planta_cm.\n\nEvitar acentos e caracteres especiais: em vez de Matéria seca (g), utilizar materia_seca_g.\n\nSer descritivo, mas não excessivamente longo: peso_frutos em vez de pf_colheita_experimental_2024.\n\nEsses cuidados tornam o banco de dados mais limpo, reprodutível e compatível com funções e pacotes do R.\nComo organizar os títulos\n\nPode fazer manulamente no Excel\n\nAntes de importar o arquivo para o R, pode-se renomear diretamente no Excel.\n\nExemplo: renomear a coluna de Massa seca total (g) para massa_seca_total_g.\n\nManualmente no R usando o pacote dplyr\n\nA função rename() do pacote dplyr permite renomear manualmente colunas específicas.\n\n# Renomear colunas específicas\nlibrary(dplyr)\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    repeticao = `Repetição`,\n    tratamento = Tratamento,\n    altura_planta_cm = `Altura da planta (cm)`,\n    materia_seca_g = `Matéria seca (g)`\n  )\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repetição\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Matéria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_dplyr)\n\n[1] \"repeticao\"        \"tratamento\"       \"altura_planta_cm\" \"materia_seca_g\"  \n\n\n\nAutomático usando o pacote janitor\nExistem pacotes que auxiliam na padronização dos nomes de maneira automática:\n\nPacote janitor: a função clean_names() desse pacote converte automaticamente os títulos para um formato padrão (snake_case).\n\n\nVeja o que acontece com esse banco de dados (dados_ruins_dic):\n\n# Corrigir nomes das colunas -&gt; formato \"snake_case\"\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt; \n  janitor::clean_names()\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_da_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repetição\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Matéria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_janitor)\n\n[1] \"repeticao\"           \"tratamento\"          \"altura_da_planta_cm\"\n[4] \"materia_seca_g\"     \n\n\n\n\n\n\nImportando dados\nImportar dados para o R é um passo fundamental para qualquer análise. No R, é possível importar dados de diferentes formatos, o que é essencial para iniciar qualquer análise. O R permite ler diferentes formatos de arquivos, como CSV e Excel.\n\n# Importando CSV\n# dados_csv &lt;- read.csv(\"meus_dados.csv\", sep = \";\", dec = \",\")\n# Lê arquivos CSV, permitindo especificar o separador de colunas (sep) e o separador decimal (dec)\n\n# Importando Excel\n# dados_excel &lt;- readxl::read_excel(\"meus_dados.xlsx\")\n# Lê planilhas do Excel diretamente para o R\n\n# Importando arquivo de texto (TXT)\n# dados_txt &lt;- read.table(\"meus_dados.txt\", header = TRUE, sep = \"\\t\", dec = \".\")\n# Lê arquivos de texto, onde 'header = TRUE' indica que a primeira linha contém os nomes das colunas,\n# 'sep = \"\\t\"' indica que as colunas são separadas por tabulação, e 'dec = \".\"' define o separador decimal\n\n\nread.csv() lê arquivos no formato CSV (Comma-Separated Values), permitindo especificar o separador de colunas (sep) e o separador decimal (dec). É indicado para planilhas exportadas como CSV ou dados gerados por outros programas.\nread_excel() (do pacote readxl) lê arquivos do Excel (.xls ou .xlsx) diretamente, mantendo nomes das colunas e tipos de dados corretamente, o que facilita a importação de planilhas complexas sem precisar convertê-las.\nread.table() lê arquivos de texto simples (TXT ou outros delimitados), oferecendo flexibilidade para especificar se há cabeçalho (header = TRUE), o separador de colunas (sep) e o separador decimal (dec). É ideal para arquivos de texto com diferentes formatos de separação.\n\nVisualizando os dados\nApós a importação, podemos visualizar os dados para verificar se foram carregados corretamente: Após a importação, é importante visualizar os dados para conferir se foram carregados corretamente. Para isso, podem ser usadas funções como:\n\nhead() (exibe as primeiras linhas),\nsummary() (mostra resumo estatístico das variáveis),\nstr() (mostra a estrutura do objeto) e\nglimpse() (exibe de forma compacta e legível a estrutura e os tipos das variáveis).\n\n\n# head(dados_csv)    # Mostra as primeiras linhas do conjunto de dados\n# summary(dados_csv) # Mostra um resumo estatístico das variáveis\n# str(dados_csv)     # Mostra a estrutura do objeto, incluindo tipos de variáveis e dimensões\n# glimpse(dados_csv)  # Mostra todas as variáveis, seus tipos e algumas observações de cada coluna"
  },
  {
    "objectID": "codigos.html#módulo-2-manipulação-e-exploração-de-dados",
    "href": "codigos.html#módulo-2-manipulação-e-exploração-de-dados",
    "title": "Primeiros passos",
    "section": "",
    "text": "Variáveis numéricas\n\nContínuas (numeric / dbl): podem assumir qualquer valor dentro de um intervalo, incluindo decimais.\nExemplo: Produtividade (t/ha), Área (m²)\nDiscretas (integer / int): assumem apenas valores inteiros.\nExemplo: Parcela (identificador das parcelas)\n\nVariáveis categóricas (fatores) (factor / fct)\n\nRepresentam categorias ou grupos que o R reconhece para análises estatísticas.\nExemplo: Tratamento, Variedade\n\nIdeais para análise de variância e comparações entre grupos\n\nVariáveis de texto (character / chr)\n\nContêm informações textuais ou descritivas, que não têm ordem ou significado numérico.\nExemplo: Local (Norte, Sul, Leste)\n\nNão são usadas diretamente em cálculos estatísticos, mas servem para identificar ou agrupar dados\n\nVariáveis lógicas (logical / logi)\n\nAssumem apenas dois valores: TRUE ou FALSE\nExemplo: Irrigado\n\nÚteis para condições, filtros e análises condicionais\n\nOutros tipos disponíveis em R\n\nComplexo (complex / sem abreviação comum): números complexos, como 1+2i\nRaw (raw / sem abreviação comum): representa dados brutos em bytes\n\nDate (Date / sem abreviação comum): datas no formato \"YYYY-MM-DD\"\n\nPOSIXct / POSIXlt (POSIXct / POSIXlt): datas e horas com tempo\nOrdered factor (ordered / ord): fatores com ordem natural definida\n\n\n\nNeste exemplo, iremos criar variáveis de diferentes tipos em R — numéricas contínuas, numéricas discretas e categóricas (fatores) — e, em seguida, identificar o tipo de cada variável usando a função class().\nIsso nos permite compreender como o R armazena cada tipo de dado e como ele será tratado em análises estatísticas.\n\n# Numérica contínua\nnum_cont &lt;- 3.5      # numeric / dbl\nclass(num_cont) # Checando classes\n\n[1] \"numeric\"\n\n# Numérica discreta\nnum_disc &lt;- 5L       # integer / int\nclass(num_disc)\n\n[1] \"integer\"\n\n# Fator (categórica)\ntrat &lt;- factor(c(\"T1\", \"T2\", \"T3\"))  # factor / fct\nclass(trat)\n\n[1] \"factor\"\n\n# Ordered factor\nord_trat &lt;- factor(c(\"Baixo\", \"Médio\", \"Alto\"), ordered = TRUE) # ordered / ord\nclass(ord_trat)\n\n[1] \"ordered\" \"factor\" \n\n# Character\nlocal &lt;- c(\"Norte\", \"Sul\")  # character / chr\nclass(local)\n\n[1] \"character\"\n\n# Lógica\nirr &lt;- c(TRUE, FALSE)       # logical / logi\nclass(irr)\n\n[1] \"logical\"\n\n# Complexo\ncplx &lt;- 1 + 2i              # complex\nclass(cplx)\n\n[1] \"complex\"\n\n# Raw\nr &lt;- charToRaw(\"A\")         # raw\nclass(r)\n\n[1] \"raw\"\n\n# Datas\nd &lt;- as.Date(\"2025-08-29\")  # Date\nclass(d)\n\n[1] \"Date\"\n\ndt &lt;- as.POSIXct(\"2025-08-29 12:00:00\") # POSIXct\nclass(dt)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\nCriando banco de dados fictício\nNeste exemplo, iremos criar um banco de dados fictício de um experimento agrícola com diferentes tipos de variáveis: numéricas (contínuas e discretas), categóricas, lógicas e de texto.\nEm seguida, iremos visualizar o banco de dados e identificar os tipos de variáveis, para entender como o R armazena cada tipo e como podemos manipulá-las em análises estatísticas.\n\n# Exemplo de banco de dados de experimento agrícola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Numérica discreta (identificação das parcelas)\n  Tratamento = factor(rep(c(\"T1\", \"T2\", \"T3\"), each = 3)), # Fator (categórica nominal)\n  Variedade = factor(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\")), # Fator (categórica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Numérica contínua (m²)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Numérica contínua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # Lógica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\n# Exemplo de banco de dados de experimento agrícola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Numérica discreta (identificação das parcelas)\n  Tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 3), # Fator (categórica nominal)\n  Variedade = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"), # Fator (categórica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Numérica contínua (m²)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Numérica contínua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # Lógica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\nFunções para Visualização e Estrutura de Dados no R\n\nhead(dados_agro)\nMostra as primeiras linhas do conjunto de dados.\n\nÚtil para ter uma visão rápida do conteúdo do banco, verificando se os dados foram importados corretamente.\n\nExemplo de saída:\n\n\n\nhead(dados_agro) \n\n  Parcela Tratamento Variedade Area Produtividade Irrigado Local\n1       1         T1         A   10          30.5     TRUE Norte\n2       2         T1         A   10          32.0     TRUE Norte\n3       3         T1         A   10          31.0     TRUE Norte\n4       4         T2         B   12          28.0    FALSE   Sul\n5       5         T2         B   12          29.5    FALSE   Sul\n6       6         T2         B   12          30.0    FALSE   Sul\n\n\n\n\nstr(dados_agro)\n\nMostra a estrutura do objeto, permitindo entender rapidamente como os dados estão organizados no R.\nCom essa função, é possível:\n\nVer o número de observações (linhas) e o número de variáveis (colunas) do banco de dados, por exemplo, 9 obs. of 7 variables.\n\nIdentificar o tipo de cada variável, como int (inteiro), num (numérico contínuo), Factor (categórica), logi (lógica/boolean) e chr (texto).\n\nConferir alguns valores iniciais de cada coluna, ajudando a verificar se os dados foram importados corretamente e se os tipos estão adequados para análise.\n\nEm resumo, str() é uma função essencial para inspecionar rapidamente a estrutura e os tipos das variáveis, antes de realizar qualquer análise estatística ou manipulação dos dados.\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : chr  \"T1\" \"T1\" \"T1\" \"T2\" ...\n $ Variedade    : chr  \"A\" \"A\" \"A\" \"B\" ...\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nObserve que Tratamento e Variedade aparecem como character, ou seja, texto.\nPara análises estatísticas, é recomendado transformar essas variáveis em fatores.\n\n\nsummary(dados_agro)\n\nMostra um resumo estatístico das variáveis:\n- Para variáveis numéricas: mínimo, máximo, média, quartis\n- Para fatores: contagem de cada nível\n- Para lógicas: contagem de TRUE e FALSE\n- Útil para identificar tendências, valores extremos e distribuição dos dados.\n\nsummary(dados_agro)\n\n    Parcela   Tratamento         Variedade              Area    Produtividade  \n Min.   :1   Length:9           Length:9           Min.   :10   Min.   :28.00  \n 1st Qu.:3   Class :character   Class :character   1st Qu.:10   1st Qu.:30.00  \n Median :5   Mode  :character   Mode  :character   Median :11   Median :31.00  \n Mean   :5                                         Mean   :11   Mean   :31.22  \n 3rd Qu.:7                                         3rd Qu.:12   3rd Qu.:32.50  \n Max.   :9                                         Max.   :12   Max.   :34.50  \n  Irrigado          Local          \n Mode :logical   Length:9          \n FALSE:3         Class :character  \n TRUE :6         Mode  :character  \n                                   \n                                   \n                                   \n\n\nVeja novamente que Tratamento e Variedade aparecem como character.\nE não são reconhecidas como fatores.\nE não é possível perceber quais são os níveis de cada variável categórica.\n\nConvertendo variaveis categóricas em fatores\n\nPode-se convertê-las em fatores usando a função as.factor():\n\n\ndados_agro$Tratamento &lt;- as.factor(dados_agro$Tratamento)\ndados_agro$Variedade &lt;- as.factor(dados_agro$Variedade)\n\nAgora veja como fica a estrutura dos dados:\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : Factor w/ 3 levels \"T1\",\"T2\",\"T3\": 1 1 1 2 2 2 3 3 3\n $ Variedade    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 1 1 2 2 2 3 3 3\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nAgora sim, Tratamento e variedade aparecem como Factor com 3 níveis cada.\nveja como fica o resumo estatístico dos dados:\n\nsummary(dados_agro)\n\n    Parcela  Tratamento Variedade      Area    Produtividade    Irrigado      \n Min.   :1   T1:3       A:3       Min.   :10   Min.   :28.00   Mode :logical  \n 1st Qu.:3   T2:3       B:3       1st Qu.:10   1st Qu.:30.00   FALSE:3        \n Median :5   T3:3       C:3       Median :11   Median :31.00   TRUE :6        \n Mean   :5                        Mean   :11   Mean   :31.22                  \n 3rd Qu.:7                        3rd Qu.:12   3rd Qu.:32.50                  \n Max.   :9                        Max.   :12   Max.   :34.50                  \n    Local          \n Length:9          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nAgora é possível ver a contagem de cada nível das variáveis categóricas. Ou seja, são 3 níveis em cada variável (T1, T2, T3 para Tratamento e A, B, C para Variedade).\n\nPode-se convertê-las em fatores usando a função factor():\n\nTambém dá para criar o fator diretamente com a função factor(), que é mais flexível porque permite:\n\nDefinir os níveis (levels)\nDefinir as etiquetas (labels)\n\nOu seja, permite controlar a ordem e o rótulo dos níveis (mais recomendado para ANOVA e modelos, pois evita ordem alfabética indesejada).\n\nPode-se ainda convertê-las em fatores usando a função convert_as_factor() do pacote {rstatix}:\n\nA função convert_as_factor() pode converter uma ou várias colunas ao mesmo tempo.\n\n\nglimpse(dados_agro) (do pacote dplyr)\n\nMostra a estrutura dos dados de forma compacta e legível, similar ao str(), mas em formato horizontal:\n\nExibe todas as variáveis, seus tipos e algumas observações iniciais\n\nMais fácil de ler quando o banco de dados tem muitas colunas\n\nExemplo de saída (resumida):\n\nglimpse(dados_agro)\n\nRows: 9\nColumns: 7\n$ Parcela       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ Tratamento    &lt;fct&gt; Controle, Controle, Controle, Adubo, Adubo, Adubo, Bioes…\n$ Variedade     &lt;fct&gt; IPA 11, IPA 11, IPA 11, Campo Lindo, Campo Lindo, Campo …\n$ Area          &lt;dbl&gt; 10, 10, 10, 12, 12, 12, 11, 11, 11\n$ Produtividade &lt;dbl&gt; 30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5\n$ Irrigado      &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE\n$ Local         &lt;chr&gt; \"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\",…\n\n\n\n\n\n\n\n# Exemplo fictício\ndados &lt;- data.frame(\n  tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 4),\n  repeticao = rep(1:4, 3),\n  produtividade = c(30, 32, 28, 31, 35, 36, 34, 37, 25, 27, 26, 28)\n)\n\n# Selecionar colunas e filtrar\ndados |&gt; dplyr::select(tratamento, produtividade) |&gt; filter(produtividade &gt; 30)\n\n  tratamento produtividade\n1         T1            32\n2         T1            31\n3         T2            35\n4         T2            36\n5         T2            34\n6         T2            37\n\n# Resumo estatístico\ndados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    media = mean(produtividade),\n    sd = sd(produtividade)\n  )\n\n# A tibble: 3 × 3\n  tratamento media    sd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 T1          30.2  1.71\n2 T2          35.5  1.29\n3 T3          26.5  1.29\n\n\n\n\n\n\n\n# Histograma\nggplot(dados, aes(x = produtividade)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n# Boxplot\nggplot(dados, aes(x = tratamento, y = produtividade)) +\n  geom_boxplot(fill = \"orange\")"
  },
  {
    "objectID": "codigos.html#módulo-3-análise-de-variância-anova",
    "href": "codigos.html#módulo-3-análise-de-variância-anova",
    "title": "Primeiros passos",
    "section": "",
    "text": "# Primeiro transformar variáveis em fatores\ndados$tratamento &lt;- factor(dados$tratamento)\ndados$repeticao &lt;- factor(dados$repeticao)\n\n# ANOVA usando aov()\nmodelo &lt;- aov(produtividade ~ tratamento, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamento   2 163.50   81.75   39.24 3.59e-05 ***\nResiduals    9  18.75    2.08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd     F        p p&lt;.05   ges\n1 tratamento   2   9 39.24 3.59e-05     * 0.897\n\n# ANOVA usando ExpDes.pt\ndic(\n  trat = dados$tratamento,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM    Fc      Pr&gt;Fc\nTratamento  2 163.50 81.750 39.24 3.5934e-05\nResiduo     9  18.75  2.083                 \nTotal      11 182.25                        \n------------------------------------------------------------------------\nCV = 4.69 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.5375769 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.8663487 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\neasyanova::ea1(dados[-2], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type I SS mean square F value    p&gt;F\ntreatments  2    163.50     81.7500   39.24 &lt;0.001\nResiduals   9     18.75      2.0833       -      -\n\n$Means\n  treatment  mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2 35.50 1.2910 0.7217  34  37     a   a      a a           a\n2        T1 30.25 1.7078 0.7217  28  32     b   b      b b           b\n3        T3 26.50 1.2910 0.7217  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 T2 - T1     5.25   0.0016 0.0006    0.0006 0.0006\n2 T2 - T3     9.00   0.0000 0.0000    0.0000 0.0000\n3 T1 - T3     3.75   0.0128 0.0051    0.0051 0.0051\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                             values\np.value Shapiro-Wilk test    0.5376\np.value Bartlett test        0.8663\ncoefficient of variation (%) 4.6900\nfirst value most discrepant  3.0000\nsecond value most discrepant 2.0000\nthird value most discrepant  8.0000\n\n$`Residual analysis`$residuals\n    1     2     3     4     5     6     7     8     9    10    11    12 \n-0.25  1.75 -2.25  0.75 -0.50  0.50 -1.50  1.50 -1.50  0.50 -0.50  1.50 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n-0.1914854  1.3403980 -1.7233688  0.5744563 -0.3829708  0.3829708 -1.1489125 \n         8          9         10         11         12 \n 1.1489125 -1.1489125  0.3829708 -0.3829708  1.1489125 \n\n\nTestes de Pressupostos\nAntes da análise de variância (ANOVA), foi realizada a verificação dos pressupostos de normalidade dos resíduos e homogeneidade das variâncias, que são condições necessárias para a validade do teste F.\nNormalidade dos resíduos\n\nO teste de Shapiro-Wilk foi aplicado sobre os resíduos do modelo, verificando se a distribuição se aproxima da normal.\nAlém disso, a normalidade foi testada dentro de cada grupo experimental utilizando a função shapiro_test() do pacote rstatix, o que permite avaliar possíveis desvios em tratamentos específicos.\nQuando o valor de p &gt; 0,05, não se rejeita a hipótese nula de normalidade, indicando que os resíduos podem ser considerados normalmente distribuídos.\n\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.94298, p-value = 0.5376\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 × 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n\nHomogeneidade das variâncias\n\nPara verificar se os tratamentos apresentam variâncias homogêneas, foram aplicados três testes:\n\nTeste de Bartlett: sensível a desvios de normalidade, mas adequado quando os dados são normais.\nTeste de Levene: mais robusto quando a normalidade não é estritamente atendida.\n\n\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n\n\nEm todos os testes, valores de p &gt; 0,05 indicam que não há evidências para rejeitar a hipótese de homogeneidade das variâncias, atendendo ao pressuposto da ANOVA.\n\nDessa forma, a análise de variância pode ser conduzida com confiança, uma vez que os pressupostos de normalidade e homogeneidade foram verificados.\nComparações de Médias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento, data = dados)\n\n$tratamento\n       diff        lwr        upr     p adj\nT2-T1  5.25   2.400421  8.0995788 0.0015767\nT3-T1 -3.75  -6.599579 -0.9004212 0.0127984\nT3-T2 -9.00 -11.849579 -6.1504212 0.0000269\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 × 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# Médias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean    SE df lower.CL upper.CL .group\n T3           26.5 0.722  9     24.4     28.6  a    \n T1           30.2 0.722  9     28.1     32.4   b   \n T2           35.5 0.722  9     33.4     37.6    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nAnova\nNo DBC (delineamento em blocos casualizados) a diferença principal é que você precisa considerar o efeito de blocos no modelo. Seguindo o mesmo estilo da sua aula de DIC, aqui está a versão para DBC:\n\n# ANOVA usando aov()\n# Aqui usamos Error(bloco) ou bloco como efeito\nmodelo &lt;- aov(produtividade ~ tratamento + repeticao, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \ntratamento   2 163.50   81.75 127.957 1.2e-05 ***\nrepeticao    3  14.92    4.97   7.783  0.0172 *  \nResiduals    6   3.83    0.64                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento + repeticao)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd       F       p p&lt;.05   ges\n1 tratamento   2   6 127.957 1.2e-05     * 0.977\n2  repeticao   3   6   7.783 1.7e-02     * 0.796\n\n# ANOVA usando ExpDes.pt\ndbc(\n  trat = dados$tratamento,\n  bloco = dados$repeticao,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ     QM      Fc    Pr&gt;Fc\nTratamento  2 163.500 81.750 127.957 0.000012\nBloco       3  14.917  4.972   7.783 0.017195\nResiduo     6   3.833  0.639                 \nTotal      11 182.250                        \n------------------------------------------------------------------------\nCV = 2.6 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.4793843 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.1530654 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\n# design = 2 corresponde a DBC\neasyanova::ea1(dados, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type III SS mean square  F value    p&gt;F\ntreatments  2    163.5000     81.7500 127.9565 &lt;0.001\nblocks      3     14.9167      4.9722   7.7826 0.0172\nresiduals   6      3.8333      0.6389        -      -\n\n$`Adjusted means`\n  treatment adjusted.mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2         35.50 1.2910 0.3997  34  37     a   a      a a           a\n2        T1         30.25 1.7078 0.3997  28  32     b   b      b b           b\n3        T3         26.50 1.2910 0.3997  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)  p(t)\n1 T2 - T1     5.25   0.0002  1e-04     1e-04 1e-04\n2 T2 - T3     9.00   0.0000  0e+00     0e+00 0e+00\n3 T1 - T3     3.75   0.0014  6e-04     6e-04 6e-04\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                              values\np.value Shapiro-Wilk test     0.4794\np.value Bartlett test         0.8663\ncoefficient of variation (%)  2.6000\nfirst value most discrepant  11.0000\nsecond value most discrepant  3.0000\nthird value most discrepant   2.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n 0.50000000  0.83333333 -0.83333333 -0.50000000  0.25000000 -0.41666667 \n          7           8           9          10          11          12 \n-0.08333333  0.25000000 -0.75000000 -0.41666667  0.91666667  0.25000000 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n 0.8469896  1.4116493 -1.4116493 -0.8469896  0.4234948 -0.7058246 -0.1411649 \n         8          9         10         11         12 \n 0.4234948 -1.2704843 -0.7058246  1.5528142  0.4234948 \n\n\nObservações importantes:\n\nNo aov(), o termo + bloco garante que a variação entre blocos seja considerada.\nNo ExpDes.pt, usamos dbc() no lugar de dic().\nNo easyanova, o argumento design = 2 é usado para DBC.\n\nTestes de Pressupostos\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.93854, p-value = 0.4794\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 × 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n## Teste de ONeill e Mathews\noneilldbc(trat = dados$tratamento, resp = dados$produtividade, bloco = dados$repeticao)\n\n[1] 0.1530654\n\n\nEm DBC também foi realizado Teste de O’Neill e Mathews, específico para experimentos em blocos casualizados (DBC), sendo recomendado como alternativa robusta para esse delineamento.\n\nEm todos os testes, valores de p &gt; 0,05 indicam que não há evidências para rejeitar a hipótese de homogeneidade das variâncias, atendendo ao pressuposto da ANOVA.\n\nComparações de Médias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento + repeticao, data = dados)\n\n$tratamento\n       diff        lwr       upr     p adj\nT2-T1  5.25   3.515829  6.984171 0.0002167\nT3-T1 -3.75  -5.484171 -2.015829 0.0013765\nT3-T2 -9.00 -10.734171 -7.265829 0.0000092\n\n$repeticao\n          diff        lwr         upr     p adj\n2-1  1.6666667 -0.5925501  3.92588339 0.1472526\n3-1 -0.6666667 -2.9258834  1.59255006 0.7441939\n4-1  2.0000000 -0.2592167  4.25921672 0.0796674\n3-2 -2.3333333 -4.5925501 -0.07411661 0.0438895\n4-2  0.3333333 -1.9258834  2.59255006 0.9535148\n4-3  2.6666667  0.4074499  4.92588339 0.0248704\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 × 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# Médias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean  SE df lower.CL upper.CL .group\n T3           26.5 0.4  6     25.2     27.8  a    \n T1           30.2 0.4  6     28.9     31.6   b   \n T2           35.5 0.4  6     34.2     36.8    c  \n\nResults are averaged over the levels of: repeticao \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\n# Exemplo com dois fatores\ndados2 &lt;- expand.grid(\n  adubacao = c(\"A1\", \"A2\"),\n  cultivar = c(\"C1\", \"C2\", \"C3\"),\n  rep = 1:4\n)\n\nset.seed(123)\n\ndados2$produtividade &lt;- rnorm(24, mean = 30, sd = 3)\ndados2$adubacao &lt;- factor(dados2$adubacao)\ndados2$cultivar &lt;- factor(dados2$cultivar)\ndados2$rep &lt;- factor(dados2$rep)\n\n# ANOVA usando aov()\nmodelo2 &lt;- aov(produtividade ~ adubacao * cultivar, data = dados2)\nsummary(modelo2)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nadubacao           1   2.09   2.089   0.217  0.647\ncultivar           2   1.07   0.536   0.056  0.946\nadubacao:cultivar  2  13.72   6.861   0.712  0.504\nResiduals         18 173.43   9.635               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1          adubacao   1  18 0.217 0.647       0.012\n2          cultivar   2  18 0.056 0.946       0.006\n3 adubacao:cultivar   2  18 0.712 0.504       0.073\n\n# ExpDes.pt\nfat2.dic(\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nF1       1   2.089  3 0.21680 0.64708\nF2       2   1.073  2 0.05566 0.94602\nF1*F2    2  13.723  4 0.71212 0.50391\nResiduo 18 173.435  5                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.36 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6606527 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\neasyanova::ea2(dados2[-3], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2168 0.6471\nfactor_2           2      1.0726      0.5363  0.0557  0.946\nfactor_1:factor_2  2     13.7229      6.8614  0.7121 0.5039\nresiduals         18    173.4346      9.6353       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.8961     a   a      a a           a\n2       A2        29.679 3.2191 0.8961     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6471 0.6471    0.6471 0.6471\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.0975     a   a      a a           a\n2       C3       30.0767 3.6356 1.0975     a   a      a a           a\n3       C1       29.6795 1.9564 1.0975     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9982 0.9549    0.9549 0.9549\n2 C2 - C1   0.4862   0.9475 0.9475    0.7709 0.7577\n3 C3 - C1   0.3972   0.9646 0.8009    0.8009 0.8009\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3414 0.3414    0.3414 0.3414\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5146 0.5146    0.5146 0.5146\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6272 0.6272    0.6272 0.6272\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9980 0.9523    0.9523 0.9523\n2 A1.C1 - A1.C2   1.3158   0.8221 0.8221    0.5783 0.5563\n3 A1.C3 - A1.C2   1.1828   0.8533 0.5966    0.5966 0.5966\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8112 0.5430    0.5430 0.5430\n2 A2.C2 - A2.C1   2.2883   0.5605 0.5605    0.3371 0.3109\n3 A2.C3 - A2.C1   0.9275   0.9068 0.6776    0.6776 0.6776\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6607\np.value Bartlett test (factor_1)    0.5289\np.value Bartlett test (factor_2)    0.1309\np.value Bartlett test (treatments)  0.5464\ncoefficient of variation (%)       10.3600\nfirst value most discrepant         6.0000\nsecond value most discrepant       18.0000\nthird value most discrepant         3.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n-2.43335287  0.70247809  5.23998198 -0.68381331 -0.23104847  5.61066714 \n          7           8           9          10          11          12 \n 0.63082268 -2.40217314 -1.49670152 -2.23232439  3.05333372  1.54491366 \n         13          14          15          16          17          18 \n 0.45038842  1.72505871 -1.10366637  4.46540093  0.87463976 -5.43437929 \n         19          20          21          22          23          24 \n 1.35214177 -0.02536366 -2.63961408 -1.54926323 -3.69692502 -1.72120151 \n\n$`Residual analysis`$`standardized residuals`\n           1            2            3            4            5            6 \n-0.886137644  0.255816692  1.908208766 -0.249019664 -0.084139356  2.043198673 \n           7            8            9           10           11           12 \n 0.229722427 -0.874783133 -0.545043662 -0.812930463  1.111911873  0.562600750 \n          13           14           15           16           17           18 \n 0.164014901  0.628202953 -0.401914711  1.626134829  0.318511642 -1.979001121 \n          19           20           21           22           23           24 \n 0.492400316 -0.009236513 -0.961250393 -0.564184702 -1.346284159 -0.626798303 \n\n\n\n\n\n\n\n# ANOVA usando aov()\n# Aqui, bloco é adicionado como efeito de erro\nmodelo_dbc &lt;- aov(produtividade ~ rep + adubacao * cultivar, data = dados2)\nsummary(modelo_dbc)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nrep                3  22.94   7.647   0.762  0.533\nadubacao           1   2.09   2.089   0.208  0.655\ncultivar           2   1.07   0.536   0.053  0.948\nadubacao:cultivar  2  13.72   6.861   0.684  0.520\nResiduals         15 150.49  10.033               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ rep + adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1               rep   3  15 0.762 0.533       0.132\n2          adubacao   1  15 0.208 0.655       0.014\n3          cultivar   2  15 0.053 0.948       0.007\n4 adubacao:cultivar   2  15 0.684 0.520       0.084\n\n# ExpDes.pt\n# fat2.dbc é a função para fatorial em blocos no pacote ExpDes.pt\nfat2.dbc(\n  bloco = dados2$rep,\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nBloco    3  22.942  6 0.76223 0.53264\nF1       1   2.089  4 0.20821 0.65471\nF2       2   1.073  2 0.05345 0.94813\nF1*F2    2  13.723  5 0.68390 0.51971\nResiduo 15 150.493  3                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.57 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6960048 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\n# Em DBC, design = 2 (fatorial em blocos)\neasyanova::ea2(dados2, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2082 0.6547\nfactor_2           2      1.0726      0.5363  0.0535 0.9481\nblocks             3     22.9420      7.6473  0.7622 0.5326\nfactor_1:factor_2  2     13.7229      6.8614  0.6839 0.5197\nresiduals         15    150.4926     10.0328       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.9144     a   a      a a           a\n2       A2        29.679 3.2191 0.9144     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6547 0.6547    0.6547 0.6547\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.1199     a   a      a a           a\n2       C3       30.0767 3.6356 1.1199     a   a      a a           a\n3       C1       29.6795 1.9564 1.1199     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9983 0.9559    0.9559 0.9559\n2 C2 - C1   0.4862   0.9495 0.9495    0.7754 0.7631\n3 C3 - C1   0.3972   0.9660 0.8054    0.8054 0.8054\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3534 0.3534    0.3534 0.3534\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5246 0.5246    0.5246 0.5246\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6353 0.6353    0.6353 0.6353\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9981 0.9534    0.9534 0.9534\n2 A1.C1 - A1.C2   1.3158   0.8288 0.8288    0.5862 0.5656\n3 A1.C3 - A1.C2   1.1828   0.8589 0.6051    0.6051 0.6051\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8182 0.5526    0.5526 0.5526\n2 A2.C2 - A2.C1   2.2883   0.5751 0.5751    0.3481 0.3231\n3 A2.C3 - A2.C1   0.9275   0.9104 0.6846    0.6846 0.6846\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6960\np.value Bartlett test (factor_1)    0.5441\np.value Bartlett test (factor_2)    0.6041\np.value Bartlett test (treatments)  0.8490\ncoefficient of variation (%)       10.5700\nfirst value most discrepant        18.0000\nsecond value most discrepant       16.0000\nthird value most discrepant         6.0000\n\n$`Residual analysis`$residuals\n         1          2          3          4          5          6          7 \n-3.8008383 -0.6650073  3.8724965 -2.0512987 -1.5985339  4.2431817  0.7811775 \n         8          9         10         11         12         13         14 \n-2.2518183 -1.3463467 -2.0819696  3.2036886  1.6952685  0.2874814  1.5621517 \n        15         16         17         18         19         20         21 \n-1.2665734  4.3024939  0.7117327 -5.5972863  2.7321794  1.3546740 -1.2595765 \n        22         23         24 \n-0.1692256 -2.3168874 -0.3411639 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n-1.48588700 -0.25997574  1.51390084 -0.80192786 -0.62492549  1.65881525 \n          7           8           9          10          11          12 \n 0.30539092 -0.88031831 -0.52633627 -0.81391821  1.25243928  0.66274259 \n         13          14          15          16          17          18 \n 0.11238701  0.61070235 -0.49514996  1.68200256  0.27824241 -2.18818437 \n         19          20          21          22          23          24 \n 1.06810906  0.52959170 -0.49241461 -0.06615649 -0.90575620 -0.13337347"
  },
  {
    "objectID": "codigos.html#módulo-4-regressão",
    "href": "codigos.html#módulo-4-regressão",
    "title": "Primeiros passos",
    "section": "",
    "text": "dose &lt;- c(0, 50, 100, 150, 200)\nprod &lt;- c(20, 28, 35, 40, 38)\ndados_reg &lt;- data.frame(dose, prod)\n\nmodelo_reg &lt;- lm(prod ~ dose, data = dados_reg)\na &lt;- summary(modelo_reg)\n\n# Coeficientes\ncoeficientes &lt;- coef(modelo_reg)\nintercepto &lt;- round(coeficientes[1], 2) # sem sinal extra\nslope &lt;- formatC(coeficientes[2], format = \"f\", digits = 2, flag = \"+\") # sempre com sinal\n\n# Estatísticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n\n\n\n# Equação no formato correto\nequacao &lt;- paste0(\"y = \", intercepto, slope, \"x\")\n\nlegenda &lt;- paste0(\n  equacao,\n  \"  R² = \", r2,\n  \"\\nF = \", f_value,\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n\n\ndados_reg |&gt;\n  ggplot(aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  annotate(\"text\",\n           x = 100, y = 10,\n           label = legenda,\n           hjust = 0, size = 5) +\n  labs(x = \"Frequência de irrigação\", y = \"CRA (%)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ajustar modelo de regressão quadrática\nmodelo_quad &lt;- lm(prod ~ dose + I(dose^2), data = dados_reg)\na &lt;- summary(modelo_quad)\na\n\n\nCall:\nlm(formula = prod ~ dose + I(dose^2), data = dados_reg)\n\nResiduals:\n      1       2       3       4       5 \n 0.5429 -0.9714 -0.3429  1.4286 -0.6571 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 19.4571429  1.3021176  14.943  0.00445 **\ndose         0.2217143  0.0308492   7.187  0.01882 * \nI(dose^2)   -0.0006286  0.0001479  -4.250  0.05116 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.384 on 2 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9715 \nF-statistic: 69.21 on 2 and 2 DF,  p-value: 0.01424\n\n# Coeficientes da regressão quadrática (com mais casas decimais)\ncoef_quad &lt;- coef(modelo_quad)\nintercepto &lt;- formatC(coef_quad[1], format = \"f\", digits = 4)\nlinear     &lt;- formatC(coef_quad[2], format = \"f\", digits = 4, flag = \"+\")\nquadratico &lt;- formatC(coef_quad[3], format = \"f\", digits = 4, flag = \"+\") \n# usei 6 casas para o termo quadrático porque geralmente é bem pequeno\n\n# Estatísticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n# Equação para legenda\nequacao &lt;- paste0(\"y = \", intercepto, \" \", linear, \"x \", quadratico, \"x²\")\nlegenda &lt;- paste0(\n  equacao,\n  \"  R² = \", r2,\n  \"\\nF = \", round(f_value, 2),\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n# Gráfico\nlibrary(ggplot2)\n\nregressao_quad &lt;- ggplot(dados_reg, aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  stat_smooth(\n    method = \"lm\",\n    formula = y ~ x + I(x^2),\n    se = FALSE,\n    color = \"black\"\n  ) +\n  annotate(\"text\", x = 50, y = 10, label = legenda, hjust = 0, size = 5) +\n  labs(x = \"Dose\", y = \"Produção\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n# Exibir gráfico\nregressao_quad"
  },
  {
    "objectID": "codigos.html#módulo-5-relatórios-e-projeto-final",
    "href": "codigos.html#módulo-5-relatórios-e-projeto-final",
    "title": "Primeiros passos",
    "section": "",
    "text": "Este próprio arquivo é um exemplo.\n\nPode ser exportado em HTML, Word ou PDF."
  },
  {
    "objectID": "codigos.html#projeto-final",
    "href": "codigos.html#projeto-final",
    "title": "Primeiros passos",
    "section": "",
    "text": "Analise um conjunto de dados agrícolas (real ou fornecido):\n- Estruture os dados no Excel/CSV.\n- Importe para o R.\n- Realize ANOVA (com aov(), ExpDes.pt, easyanova e rstatix).\n- Teste pressupostos.\n- Se necessário, ajuste modelos de regressão.\n- Gere gráficos com ggplot2.\n- Organize os resultados em relatório RMarkdown."
  },
  {
    "objectID": "graficos.html",
    "href": "graficos.html",
    "title": "Construindo gráficos no R",
    "section": "",
    "text": "Construindo gráficos usando o pacote ggplot2\n\nlibrary(ggplot2) #Criar gráficos de vários tipos\nlibrary(dplyr) #Utilizar operadores pipes\nlibrary(rstatix) #Pacote para realizar estatística descritiva"
  },
  {
    "objectID": "graficos.html#gráfico-de-boxplot",
    "href": "graficos.html#gráfico-de-boxplot",
    "title": "Construindo gráficos no R",
    "section": "Gráfico de boxplot",
    "text": "Gráfico de boxplot\n\nVariável dependente: MAP\n\nVariáveis independentes: FMICO, LIRRIG, DAS\n\n\nModelo 1- Simples com duas variáveis\nMassa aérea da parte aérea da planta (MAP) em função de níveis de irrigação aplicados às plantas (LIRIG).\n\ndados |&gt; \n  ggplot(aes(x= LIRRIG, y=MAP))+ #Escolhe que variáveis aparecem no eixo X, Y e grupo\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nModelo 2 - Agrupado com três variáveis\n\nMassa aérea da parte aérea da planta (MAP) em função de níveis de irrigação aplicados às plantas (LIRIG) separado por dias após a semeadura (DAS).\n\ndados |&gt; \n  ggplot(aes(x=LIRRIG, y=MAP))+ #Escolhe que variáveis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gráfico de boxplot\n  facet_grid(~DAS) # Agrupa gráfico por MICO\n\n\n\n\n\n\n\n\nPodemos trocar e fazer o gráfico em função de DAS e separado por LIRRIG.\n\ndados |&gt; \n  ggplot(aes(x=DAS, y=MAP))+ #Escolhe que variáveis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gráfico de boxplot\n  facet_grid(~LIRRIG) # Agrupa gráfico por LRRIG\n\n\n\n\n\n\n\n\n\n\n\nModelo 3 agrupado com quatro variáveis\n\nMassa aérea da parte aérea da planta (MAP) em função de níveis de irrigação aplicados às plantas (LIRIG) separado por dias após a semeadura (DAS) e agrupado por FMICO\n\ndados |&gt; \n  ggplot(aes(x=LIRRIG, y=MAP, fill=FMICO))+ #Escolhe que variáveis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gráfico de boxplot\n  facet_grid(~DAS)+ # Agrupa gráfico por DAS \n  theme_bw() #Estilo de gráfico\n\n\n\n\n\n\n\n\n\nAlterando títulos dos eixos\n\n\nModelo 5\n\n\ndados |&gt; \n  ggplot(aes(x=LIRRIG, y=MAP, fill=FMICO))+ #Escolhe que variáveis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gráfico de boxplot\n  facet_grid(~DAS)+ # Agrupa gráfico por DAS \n  theme_bw()+ #Estilo de gráfico\n  xlab(\"Dias\")+ #Altera o título do eixo X\n  ylab(\"Nome da variável no eixo y\") #Altera o título do eixo Y"
  },
  {
    "objectID": "graficos.html#gráfico-de-linhas-e-barras-de-erros",
    "href": "graficos.html#gráfico-de-linhas-e-barras-de-erros",
    "title": "Construindo gráficos no R",
    "section": "Gráfico de linhas e barras de erros",
    "text": "Gráfico de linhas e barras de erros\nPara fazer gráfico de linhas, a variável no eixo X precisa ser uma variável numérica, como DAS\n\nModelo 1\n\n\n#chama arquivo de dados\ndados |&gt; \n  \n  # Realizar o agrupamento dos dados por FMICO, LIRRIG e DAS\n  group_by(FMICO, LIRRIG,DAS) |&gt; \n  \n  # Calcular as estatísticas resumidas (média e erro padrão) para a coluna MAP dentro de cada grupo\n  get_summary_stats(MAP, type=\"mean_se\") |&gt; \n  \n  # Criar o gráfico de linhas\n  ggplot(aes(x = DAS, #Variável no eixo X\n             y = mean, #Variável no eixo Y (essa deve ser a varável analisada (dependente))\n             fill = LIRRIG)) + #Variável na legenda (as linhas terão as cores agrupadas conforme essa variável)\n  \n  # Adicionar as linhas de dados\n  geom_line(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  # Adicionar pontos nas linhas (opcional)\n  geom_point(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  #Adiciona barras de erros nos pontos\n  geom_errorbar(aes(ymax = mean + se, #Barra de erro para baixo (média - erro)\n                   ymin = mean - se, #Barra de erro para cima (média + erro) \n                   width=2, #define a largura da barra de erro \n                   color=LIRRIG #define as cores das linhas de acordo com LIRRIG\n                   ))+\n  \n  #Agrupa os gráficos por FMICO\n  facet_grid(~FMICO)+\n  \n  #Define o estilo do gráfico\n  theme_bw()+\n  \n  #Altera título do eixo X\n  xlab(\"Nome da variável no eixo X (DAS)\")+\n\n  #Altera título do eixo Y\n  ylab(\"Nome da variável no eixo Y (MAP)\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\n\n\n\nModelo 2\n\nAdicionando letras nas linhas:\n\n\n#chama arquivo de dados\ndados |&gt; \n  \n  # Realizar o agrupamento dos dados por FMICO, LIRRIG e DAS\n  group_by(FMICO, LIRRIG,DAS) |&gt; \n  \n  # Calcular as estatísticas resumidas (média e erro padrão) para a coluna MAP dentro de cada grupo\n  get_summary_stats(MAP, type=\"mean_se\") |&gt; \n  \n# Criar o gráfico de linhas\n  ggplot(aes(x = DAS, #Variável no eixo X\n             y = mean, #Variável no eixo Y (essa deve ser a varável analisada (dependente))\n             fill = LIRRIG)) + #Variável na legenda (as linhas terão as cores agrupadas conforme essa variável)\n  \n  # Adicionar as linhas de dados\n  geom_line(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  # Adicionar pontos nas linhas (opcional)\n  geom_point(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  #Adiciona barras de erros nos pontos\n  geom_errorbar(aes(ymax = mean + se, #Barra de erro para baixo (média - erro)\n                   ymin = mean - se, #Barra de erro para cima (média + erro) \n                   width=2, #define a largura da barra de erro \n                   color=LIRRIG #define as cores das linhas de acordo com LIRRIG\n                   ))+\n  \n  #Agrupa os gráficos por FMICO\n  facet_grid(~FMICO)+\n  \n  #Define o estilo do gráfico\n  theme_bw()+\n  \n  #Altera título do eixo X\n  xlab(\"Nome da variável no eixo X (DAS)\")+\n\n  #Altera título do eixo Y\n  ylab(\"Nome da variável no eixo Y (MAP)\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n  # Adiocionar letras acima das barras\n  geom_text(aes(label = c(\n    \"a\"#1\n    \n    )),position = position_dodge(1), vjust = -1)\n\nmapping: label = ~c(\"a\") \ngeom_text: parse = FALSE, check_overlap = FALSE, size.unit = mm, na.rm = FALSE\nstat_identity: na.rm = FALSE\nposition_dodge"
  },
  {
    "objectID": "graficos.html#gráfico-de-pontos-e-barras-de-erros",
    "href": "graficos.html#gráfico-de-pontos-e-barras-de-erros",
    "title": "Construindo gráficos no R",
    "section": "Gráfico de pontos e barras de erros",
    "text": "Gráfico de pontos e barras de erros\n\nModelo1\n\n\ndados |&gt;\n  group_by(FMICO, LIRRIG, DAS) |&gt;\n  get_summary_stats(MAP, type = \"mean_se\") |&gt;\n  convert_as_factor(DAS) |&gt;\n  \n  ggplot(aes(\n    x = FMICO,\n    y = mean,\n    fill = LIRRIG\n  )) +\n  geom_point(aes(color = LIRRIG), position = position_dodge(width = 0.2)) +\n  geom_errorbar(\n    aes(\n      x = FMICO,\n      ymax = mean + se,\n      ymin = mean - se,\n      width = 0.1,\n      color = LIRRIG\n    ),\n    position = position_dodge(width = 0.2)\n  ) +\n  facet_grid(~DAS) +\n  theme_bw() +\n  xlab(\"Nome da variável no eixo X (DAS)\") +\n  ylab(\"Nome da variável no eixo Y (MAP)\")\n\n\n\n\n\n\n\n\n\n\n\nModelo2\n\nAdicionando significância entre tratamentos.\n\n\nteste=\ndados |&gt; \n  group_by(DAS, FMICO) |&gt;\n  pairwise_t_test(MAP ~ LIRRIG, p.adjust.method = \"bonferroni\") |&gt; \n  dplyr::select(-`p`, -`p.signif`) |&gt; \n  add_xy_position(x = \"DAS\") |&gt;  \n  filter(`p.adj`&lt;0.05 ) \n\n\nlibrary(ggpubr)\n\ndados |&gt;\n  group_by(FMICO, LIRRIG, DAS) |&gt;\n  get_summary_stats(MAP, type = \"mean_se\") |&gt;\n  convert_as_factor(DAS) |&gt;\n  \n  ggplot(aes(\n    x = FMICO,\n    y = mean,\n    fill = LIRRIG\n  )) +\n  geom_point(aes(color = LIRRIG), position = position_dodge(width = 0.2)) +\n  geom_errorbar(\n    aes(\n      x = FMICO,\n      ymax = mean + se,\n      ymin = mean - se,\n      width = 0.1,\n      color = LIRRIG\n    ),\n    position = position_dodge(width = 0.2)\n  ) +\n  facet_grid(~DAS) +\n  theme_bw() +\n  xlab(\"Nome da variável no eixo X (DAS)\") +\n  ylab(\"Nome da variável no eixo Y (MAP)\")\n\n\n\n\n\n\n\n  # stat_pvalue_manual(teste, tip.length = 0, hide.ns = TRUE)"
  },
  {
    "objectID": "graficos.html#gráfico-de-barras-e-erros",
    "href": "graficos.html#gráfico-de-barras-e-erros",
    "title": "Construindo gráficos no R",
    "section": "Gráfico de barras e erros",
    "text": "Gráfico de barras e erros\n\nModelo 1\n\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estatísticas resumidas (média e erro padrão) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, type = \"mean_se\") |&gt; \n  \n  # Criar o gráfico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gráfico\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nModelo 2\n\nAlterando título dos eixos X e Y e alterando cores das barras:\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estatísticas resumidas (média e erro padrão) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, #Selcionar a variável\n                    type = \"mean_se\") |&gt; #definir o tipo de estatística (média±erro-padrão)\n  \n  # Criar o gráfico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  \n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", #define que a altura das barras seja a média\n           position = \"dodge\", #define que as barras fiquem lado a lado\n           color = \"black\") + #Adiciona cotorno preto às barras\n  \n  # Escolha as cores das barras manualmente (pode usar nome da cor ou código hexadecimal)\n    scale_fill_manual(values = c(\"red\", \"#555555\", \"#ffffff\")) +  \n  \n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gráfico\n  theme_bw()+\n  \n  #Altera título do eixo X\n  xlab(\"Nome da variável FMICO\")+\n  \n  #Altera título do eixo Y\n  ylab(\"Nome da variável CLOA\")\n\n\n\n\n\n\n\n\n\n\n\nModelo 3\n\nAdicionado letras nas barras:\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estatísticas resumidas (média e erro padrão) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, #Selcionar a variável\n                    type = \"mean_se\") |&gt; #definir o tipo de estatística (média±erro-padrão)\n  \n  # Criar o gráfico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  \n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", #define que a altura das barras seja a média\n           position = \"dodge\", #define que as barras fiquem lado a lado\n           color = \"black\") + #Adiciona cotorno preto às barras\n  \n  # Escolha as cores das barras manualmente (pode usar nome da cor ou código hexadecimal)\n    scale_fill_manual(values = c(\"red\", \"#555555\", \"#ffffff\")) +  \n  \n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gráfico\n  theme_bw()+\n  \n  #Altera título do eixo X\n  xlab(\"Nome da variável FMICO\")+\n  \n  #Altera título do eixo Y\n  ylab(\"Nome da variável CLOA\")+\n  \n  ylim(0,50)+ #AUmentando a escala de Y para caber as letras no gráfico\n\n  # Adiocionar letras acima das barras\n  geom_text(aes(label = c(\n    \"a\",#1\n    \"b\",#2\n    \"c\",#3\n    \"d\",#4\n    \"e\",#5\n    \"f\",#6\n    \"g\",#7\n    \"h\",#8\n    \"i\" #9\n    \n    )),position = position_dodge(1), vjust = -1)\n\n\n\n\n\n\n\n\n\n\n\nModelo 4\n\nReduzindo a escala do gráfica\n\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estatísticas resumidas (média e erro padrão) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, #Selcionar a variável\n                    type = \"mean_se\") |&gt; #definir o tipo de estatística (média±erro-padrão)\n  \n  # Criar o gráfico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  \n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", #define que a altura das barras seja a média\n           position = \"dodge\", #define que as barras fiquem lado a lado\n           color = \"black\") + #Adiciona cotorno preto às barras\n  \n  # Escolha as cores das barras manualmente (pode usar nome da cor ou código hexadecimal)\n    scale_fill_manual(values = c(\"red\", \"#555555\", \"#ffffff\")) +  \n  \n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gráfico\n  theme_bw()+\n  \n  #Altera título do eixo X\n  xlab(\"Nome da variável FMICO\")+\n  \n  #Altera título do eixo Y\n  ylab(\"Nome da variável CLOA\")+\n  \n  #Aumentando a escala de Y para caber as letras no gráfico\n  #Usando coord_cartesian para definir o range e não subir as barras\n  coord_cartesian(ylim = c(20, 50))+ \n\n  # Adiocionar letras acima das barras\n  geom_text(aes(label = c(\n    \"a\",#1\n    \"b\",#2\n    \"c\",#3\n    \"d\",#4\n    \"e\",#5\n    \"f\",#6\n    \"g\",#7\n    \"h\",#8\n    \"i\" #9\n    \n    )),position = position_dodge(1), vjust = -1)"
  },
  {
    "objectID": "andamento.html#bancos-de-dados",
    "href": "andamento.html#bancos-de-dados",
    "title": "Andamento do Curso",
    "section": "Bancos de dados",
    "text": "Bancos de dados\nBaixe os bancos de dados utilizados no curso.\n\nBanco de dados 1\nBanco de dados contendo diferentes tipos de variáveis para aprender a identificá-las e analisá-las no R (categórica/fator, numérica, contínua, discreta, etc.).\n Baixar dados1_tipos_de_variaveis.xlsx\n\n\n Visualizar/Ocultar dados\n\n\n\n\nBanco de dados 1: Reconhecendo tipos de variáveis (numéricas, categóricas, fatores, etc.) no Excel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBloco\nTipo de adubo\nTratamento\nData de coleta\nNota de vigor de planta\nNúmero de folhas\nAltura de planta (cm)\nA planta sobreviveu?\nObservação\nComentário livre\n\n\n\n\n1\nTestemunha\nT1\n2025-03-01\n3\n11\n140.6\nFALSE\nAtraso\nPresença de pragas\n\n\n1\nAdubo químico 50 kg N\nT2\n2025-03-08\n3\n6\n124.7\nTRUE\nDoença\nFolhas amareladas\n\n\n1\nAdubo químico 100 kg N\nT3\n2025-03-15\n2\n5\n162.6\nFALSE\nAtraso\nPresença de pragas\n\n\n1\nAdubo orgânico\nT4\n2025-03-22\n2\n10\n152.3\nFALSE\nNormal\nPresença de pragas\n\n\n1\nAdubo verde\nT5\n2025-03-29\n3\n7\n132.9\nTRUE\nDoença\nPresença de pragas\n\n\n2\nTestemunha\nT1\n2025-04-05\n5\n8\n168.8\nFALSE\nDoença\nBom desenvolvimento\n\n\n2\nAdubo químico 50 kg N\nT2\n2025-04-12\n4\n10\n156.4\nFALSE\nAtraso\nFolhas amareladas\n\n\n2\nAdubo químico 100 kg N\nT3\n2025-04-19\n1\n5\n145.6\nTRUE\nDoença\nFolhas amareladas\n\n\n2\nAdubo orgânico\nT4\n2025-04-26\n2\n7\n163.4\nTRUE\nNormal\nPresença de pragas\n\n\n2\nAdubo verde\nT5\n2025-05-03\n3\n11\n163.2\nFALSE\nAtraso\nNecessita irrigação extra\n\n\n3\nTestemunha\nT1\n2025-05-10\n5\n9\n162.3\nTRUE\nAtraso\nPresença de pragas\n\n\n3\nAdubo químico 50 kg N\nT2\n2025-05-17\n3\n8\n160.3\nTRUE\nAtraso\nPresença de pragas\n\n\n3\nAdubo químico 100 kg N\nT3\n2025-05-24\n3\n11\n158.3\nTRUE\nDoença\nPresença de pragas\n\n\n3\nAdubo orgânico\nT4\n2025-05-31\n1\n12\n149.1\nFALSE\nDoença\nBom desenvolvimento\n\n\n3\nAdubo verde\nT5\n2025-06-07\n4\n6\n145.4\nFALSE\nAtraso\nFolhas amareladas\n\n\n4\nTestemunha\nT1\n2025-06-14\n1\n9\n144.3\nTRUE\nNormal\nPresença de pragas\n\n\n4\nAdubo químico 50 kg N\nT2\n2025-06-21\n1\n11\n139.6\nFALSE\nNormal\nBom desenvolvimento\n\n\n4\nAdubo químico 100 kg N\nT3\n2025-06-28\n5\n5\n146.9\nFALSE\nAtraso\nPresença de pragas\n\n\n4\nAdubo orgânico\nT4\n2025-07-05\n3\n5\n131.0\nTRUE\nDoença\nBom desenvolvimento\n\n\n4\nAdubo verde\nT5\n2025-07-12\n2\n6\n182.5\nTRUE\nDoença\nFolhas amareladas"
  }
]