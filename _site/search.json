[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bem vindo!",
    "section": "",
    "text": "O que voc√™ encontra por aqui:\n\nCurso de R: aulas pr√°ticas de programa√ß√£o, an√°lise de dados e visualiza√ß√£o.\n\nRecursos e ferramentas: scripts, c√≥digos de exemplo e materiais para facilitar seu aprendizado.\n\nBlog e tutoriais: conte√∫dos sobre estat√≠stica aplicada, experimenta√ß√£o agr√≠cola e melhores pr√°ticas em pesquisa.\n\nAcompanhe e explore o site para aprender, praticar e aplicar R na sua pesquisa agr√≠cola!\n  \n\n\n\n\n Cursos dispon√≠veis\n\n\nComece agora mesmo a aprender a analisar dados em experimenta√ß√£o agr√≠cola.\n\n Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola\nAn√°lise de dados experimentais utilizando a linguagem R.\n\n\n\n\n Ferramentas Interativas\n\n\nExplore ferramentas pr√°ticas e interativas criadas para facilitar sua vida acad√™mica e profissional.\nComece testando abaixo:\n\n Gerar Regress√£o Linear\nPermite gerar gr√°ficos de regress√£o linear simples exibindo a equa√ß√£o da reta e o coeficiente de determina√ß√£o (R¬≤)."
  },
  {
    "objectID": "ferramentas.html",
    "href": "ferramentas.html",
    "title": "Central de Ferramentas",
    "section": "",
    "text": "Explore ferramentas pr√°ticas e interativas criadas para facilitar sua vida acad√™mica e profissional.\nComece testando abaixo:\n\n\n Gerar Regress√£o Linear\n\n\nEsta ferramenta permite gerar gr√°ficos de regress√£o linear simples a partir de dados X e Y, exibindo a equa√ß√£o da reta e o coeficiente de determina√ß√£o (R¬≤). √â ideal para verificar o ajuste de curvas, sendo especialmente √∫til em laborat√≥rios durante a constru√ß√£o de curvas de solu√ß√µes em an√°lises.\n\nACESSAR"
  },
  {
    "objectID": "codigos.html",
    "href": "codigos.html",
    "title": "Primeiros passos",
    "section": "",
    "text": "Instale o R e o RStudio em seu computador.\n\n\nO R √© o programa principal, ou seja, a linguagem de programa√ß√£o e o ambiente de c√°lculo.\n√â nele que todos os comandos s√£o processados e as an√°lises estat√≠sticas s√£o realizadas.\nPor isso, o primeiro passo √© instalar o R no computador.\nO download deve ser feito diretamente no site oficial do CRAN (Comprehensive R Archive Network):\n https://cran.r-project.org/\nAo abrir o link, basta escolher o sistema operacional do seu computador (Windows, macOS ou Linux) e seguir as instru√ß√µes de instala√ß√£o.\nCom isso, voc√™ j√° ter√° o R funcionando, embora a sua interface seja bastante simples e pouco intuitiva para quem est√° come√ßando.\n√â justamente nesse ponto que entra o RStudio.\nO RStudio n√£o √© um programa separado do R, mas sim uma IDE (Integrated Development Environment), ou seja, um ambiente de desenvolvimento que facilita o uso do R.\nEle oferece uma interface gr√°fica amig√°vel, onde voc√™ pode escrever c√≥digos, visualizar gr√°ficos, organizar projetos e instalar pacotes com muito mais facilidade.\nNo entanto, √© fundamental compreender que o RStudio n√£o funciona sozinho.\nEle depende do R j√° instalado na m√°quina, pois √© o R quem executa de fato os c√°lculos.\nPor isso, a ordem correta √©: primeiro instalar o R e, em seguida, instalar o RStudio.\nO download do RStudio pode ser feito no site oficial da Posit (empresa respons√°vel pelo software):\nüëâ https://posit.co/download/rstudio-desktop/\nAo instalar os dois programas, voc√™ ter√° o R como motor de c√°lculo e o RStudio como painel de controle, trabalhando em conjunto.\nEssa combina√ß√£o √© a mais utilizada no mundo acad√™mico e profissional para an√°lises estat√≠sticas e ci√™ncia de dados.\n\nConhe√ßa os principais pain√©is do RStudio:\n\nConsole (execu√ß√£o de comandos)\n\nSource (script)\n\nEnvironment/History (objetos)\n\nPlots/Packages/Help\n\n\nVerificando vers√£o do R\n\n# Verificando vers√£o do R\nversion\n\n               _                                \nplatform       x86_64-w64-mingw32               \narch           x86_64                           \nos             mingw32                          \ncrt            ucrt                             \nsystem         x86_64, mingw32                  \nstatus                                          \nmajor          4                                \nminor          4.2                              \nyear           2024                             \nmonth          10                               \nday            31                               \nsvn rev        87279                            \nlanguage       R                                \nversion.string R version 4.4.2 (2024-10-31 ucrt)\nnickname       Pile of Leaves                   \n\n\nCitando o R\n\n# Cita√ß√£o do R\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nUma entrada BibTeX para usu√°rios(as) de LaTeX √©\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nOpera√ß√µes simples\n\n# Opera√ß√µes simples\n\n## Soma\n2 + 2\n\n[1] 4\n\n## Subtra√ß√£o\n7 - 2\n\n[1] 5\n\n## Mutiplica√ß√£o\n4 * 3\n\n[1] 12\n\n## Divis√£o\n10 / 3\n\n[1] 3.333333\n\n## Raiz quadrada\nsqrt(25)\n\n[1] 5\n\n\n\n\n\n\nNesta aula, aprendemos a criar e manipular objetos no R. Objetos s√£o vari√°veis que armazenam valores ou resultados de c√°lculos, permitindo que possamos reutiliz√°-los em outras opera√ß√µes.\nNo exemplo apresentado, criamos dois objetos num√©ricos:\n\n# Criando objetos\nx &lt;- 5\ny &lt;- 10\n\nAqui, x recebe o valor 5 e y recebe o valor 10. Em seguida, criamos um terceiro objeto chamado soma, que armazena a soma de x e y:\n\nsoma &lt;- x + y\nsoma\n\n[1] 15\n\n\nAo digitar apenas soma, o R retorna o valor armazenado neste objeto, que neste caso √© 15.\nEste exemplo ilustra a forma b√°sica de criar objetos no R e realizar opera√ß√µes simples com eles, fundamental para qualquer an√°lise de dados ou programa√ß√£o no software.\n\n\n\n\nNo R, os pacotes s√£o conjuntos de fun√ß√µes, dados e recursos que estendem as capacidades b√°sicas do software, permitindo realizar an√°lises mais complexas de forma pr√°tica e eficiente.\nNo exemplo abaixo, veja como instalar alguns pacotes importantes um de cada vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"dplyr\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e an√°lise de experimentos agr√≠colas\ninstall.packages(\"easyanova\")   # Para facilitar an√°lises de vari√¢ncia\ninstall.packages(\"rstatix\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organiza√ß√£o de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\nOuse preferir pode instalar v√°rios de uma √∫nica vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\", \"readxl\", \"ExpDes.pt\", \"easyanova\", \"rstatix\", \"emmeans\", \"janitor\", \"kableExtra\")\n\nNo exemplo abaixo, carregamos alguns pacotes importantes:\n\n# Carregando pacotes\n\n# ---------------------------\n# Pacotes para manipula√ß√£o e leitura de dados\n# ---------------------------\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipula√ß√£o de dados\nlibrary(readxl)      # Para importar planilhas Excel\n\n# ---------------------------\n# Pacotes para an√°lise de experimentos\n# ---------------------------\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n# ---------------------------\n# Pacotes para estat√≠stica e p√≥s-testes\n# ---------------------------\nlibrary(rstatix)     # Testes estat√≠sticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # M√©dias ajustadas e compara√ß√µes m√∫ltiplas\n\n# ---------------------------\n# Pacotes para organiza√ß√£o e visualiza√ß√£o de dados\n# ---------------------------\nlibrary(janitor)     # Limpeza e organiza√ß√£o de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n\n\n\n\nUm dos passos mais importantes em qualquer an√°lise √© a organiza√ß√£o adequada dos dados. Dados desorganizados ou com nomes de vari√°veis inconsistentes podem dificultar o trabalho, aumentar a chance de erros e at√© inviabilizar o uso de fun√ß√µes em softwares estat√≠sticos como o R.\nVeja esse esse exmeplo de banco de dados (dados_ruins_dic) no Excel:\n\n\n\n\n\nRepeti√ß√£o\nTratamento\nAltura da planta (cm)\nMat√©ria seca (g)\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nImport√¢ncia de bons t√≠tulos nas vari√°veis\nNo R, os nomes das colunas (ou t√≠tulos das vari√°veis) devem seguir algumas boas pr√°ticas para facilitar a an√°lise:\n\nPadr√£o snake_case: usar letras min√∫sculas e sublinhados para separar palavras, como altura_planta_g.\nEvitar espa√ßos: em vez de Altura da Planta, utilizar Altura_Planta.\n\nUsar unidades no nome da vari√°vel: em vez de Altura da Planta (cm), utilizar Altura_Planta_cm.\n\nUsar letras min√∫sculas (ou padr√£o definido): altura_planta_cm.\n\nEvitar acentos e caracteres especiais: em vez de Mat√©ria seca (g), utilizar materia_seca_g.\n\nSer descritivo, mas n√£o excessivamente longo: peso_frutos em vez de pf_colheita_experimental_2024.\n\nEsses cuidados tornam o banco de dados mais limpo, reprodut√≠vel e compat√≠vel com fun√ß√µes e pacotes do R.\nComo organizar os t√≠tulos\n\nPode fazer manulamente no Excel\n\nAntes de importar o arquivo para o R, pode-se renomear diretamente no Excel.\n\nExemplo: renomear a coluna de Massa seca total (g) para massa_seca_total_g.\n\nManualmente no R usando o pacote dplyr\n\nA fun√ß√£o rename() do pacote dplyr permite renomear manualmente colunas espec√≠ficas.\n\n# Renomear colunas espec√≠ficas\nlibrary(dplyr)\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    repeticao = `Repeti√ß√£o`,\n    tratamento = Tratamento,\n    altura_planta_cm = `Altura da planta (cm)`,\n    materia_seca_g = `Mat√©ria seca (g)`\n  )\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_dplyr)\n\n[1] \"repeticao\"        \"tratamento\"       \"altura_planta_cm\" \"materia_seca_g\"  \n\n\n\nAutom√°tico usando o pacote janitor\nExistem pacotes que auxiliam na padroniza√ß√£o dos nomes de maneira autom√°tica:\n\nPacote janitor: a fun√ß√£o clean_names() desse pacote converte automaticamente os t√≠tulos para um formato padr√£o (snake_case).\n\n\nVeja o que acontece com esse banco de dados (dados_ruins_dic):\n\n# Corrigir nomes das colunas -&gt; formato \"snake_case\"\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt; \n  janitor::clean_names()\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_da_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_janitor)\n\n[1] \"repeticao\"           \"tratamento\"          \"altura_da_planta_cm\"\n[4] \"materia_seca_g\"     \n\n\n\n\n\n\nImportando dados\nImportar dados para o R √© um passo fundamental para qualquer an√°lise. No R, √© poss√≠vel importar dados de diferentes formatos, o que √© essencial para iniciar qualquer an√°lise. O R permite ler diferentes formatos de arquivos, como CSV e Excel.\n\n# Importando CSV\n# dados_csv &lt;- read.csv(\"meus_dados.csv\", sep = \";\", dec = \",\")\n# L√™ arquivos CSV, permitindo especificar o separador de colunas (sep) e o separador decimal (dec)\n\n# Importando Excel\n# dados_excel &lt;- readxl::read_excel(\"meus_dados.xlsx\")\n# L√™ planilhas do Excel diretamente para o R\n\n# Importando arquivo de texto (TXT)\n# dados_txt &lt;- read.table(\"meus_dados.txt\", header = TRUE, sep = \"\\t\", dec = \".\")\n# L√™ arquivos de texto, onde 'header = TRUE' indica que a primeira linha cont√©m os nomes das colunas,\n# 'sep = \"\\t\"' indica que as colunas s√£o separadas por tabula√ß√£o, e 'dec = \".\"' define o separador decimal\n\n\nread.csv() l√™ arquivos no formato CSV (Comma-Separated Values), permitindo especificar o separador de colunas (sep) e o separador decimal (dec). √â indicado para planilhas exportadas como CSV ou dados gerados por outros programas.\nread_excel() (do pacote readxl) l√™ arquivos do Excel (.xls ou .xlsx) diretamente, mantendo nomes das colunas e tipos de dados corretamente, o que facilita a importa√ß√£o de planilhas complexas sem precisar convert√™-las.\nread.table() l√™ arquivos de texto simples (TXT ou outros delimitados), oferecendo flexibilidade para especificar se h√° cabe√ßalho (header = TRUE), o separador de colunas (sep) e o separador decimal (dec). √â ideal para arquivos de texto com diferentes formatos de separa√ß√£o.\n\nVisualizando os dados\nAp√≥s a importa√ß√£o, podemos visualizar os dados para verificar se foram carregados corretamente: Ap√≥s a importa√ß√£o, √© importante visualizar os dados para conferir se foram carregados corretamente. Para isso, podem ser usadas fun√ß√µes como:\n\nhead() (exibe as primeiras linhas),\nsummary() (mostra resumo estat√≠stico das vari√°veis),\nstr() (mostra a estrutura do objeto) e\nglimpse() (exibe de forma compacta e leg√≠vel a estrutura e os tipos das vari√°veis).\n\n\n# head(dados_csv)    # Mostra as primeiras linhas do conjunto de dados\n# summary(dados_csv) # Mostra um resumo estat√≠stico das vari√°veis\n# str(dados_csv)     # Mostra a estrutura do objeto, incluindo tipos de vari√°veis e dimens√µes\n# glimpse(dados_csv)  # Mostra todas as vari√°veis, seus tipos e algumas observa√ß√µes de cada coluna\n\n\n\n\n\n\n\n\n\nVari√°veis num√©ricas\n\nCont√≠nuas (numeric / dbl): podem assumir qualquer valor dentro de um intervalo, incluindo decimais.\nExemplo: Produtividade (t/ha), √Årea (m¬≤)\nDiscretas (integer / int): assumem apenas valores inteiros.\nExemplo: Parcela (identificador das parcelas)\n\nVari√°veis categ√≥ricas (fatores) (factor / fct)\n\nRepresentam categorias ou grupos que o R reconhece para an√°lises estat√≠sticas.\nExemplo: Tratamento, Variedade\n\nIdeais para an√°lise de vari√¢ncia e compara√ß√µes entre grupos\n\nVari√°veis de texto (character / chr)\n\nCont√™m informa√ß√µes textuais ou descritivas, que n√£o t√™m ordem ou significado num√©rico.\nExemplo: Local (Norte, Sul, Leste)\n\nN√£o s√£o usadas diretamente em c√°lculos estat√≠sticos, mas servem para identificar ou agrupar dados\n\nVari√°veis l√≥gicas (logical / logi)\n\nAssumem apenas dois valores: TRUE ou FALSE\nExemplo: Irrigado\n\n√öteis para condi√ß√µes, filtros e an√°lises condicionais\n\nOutros tipos dispon√≠veis em R\n\nComplexo (complex / sem abrevia√ß√£o comum): n√∫meros complexos, como 1+2i\nRaw (raw / sem abrevia√ß√£o comum): representa dados brutos em bytes\n\nDate (Date / sem abrevia√ß√£o comum): datas no formato \"YYYY-MM-DD\"\n\nPOSIXct / POSIXlt (POSIXct / POSIXlt): datas e horas com tempo\nOrdered factor (ordered / ord): fatores com ordem natural definida\n\n\n\nNeste exemplo, iremos criar vari√°veis de diferentes tipos em R ‚Äî num√©ricas cont√≠nuas, num√©ricas discretas e categ√≥ricas (fatores) ‚Äî e, em seguida, identificar o tipo de cada vari√°vel usando a fun√ß√£o class().\nIsso nos permite compreender como o R armazena cada tipo de dado e como ele ser√° tratado em an√°lises estat√≠sticas.\n\n# Num√©rica cont√≠nua\nnum_cont &lt;- 3.5      # numeric / dbl\nclass(num_cont) # Checando classes\n\n[1] \"numeric\"\n\n# Num√©rica discreta\nnum_disc &lt;- 5L       # integer / int\nclass(num_disc)\n\n[1] \"integer\"\n\n# Fator (categ√≥rica)\ntrat &lt;- factor(c(\"T1\", \"T2\", \"T3\"))  # factor / fct\nclass(trat)\n\n[1] \"factor\"\n\n# Ordered factor\nord_trat &lt;- factor(c(\"Baixo\", \"M√©dio\", \"Alto\"), ordered = TRUE) # ordered / ord\nclass(ord_trat)\n\n[1] \"ordered\" \"factor\" \n\n# Character\nlocal &lt;- c(\"Norte\", \"Sul\")  # character / chr\nclass(local)\n\n[1] \"character\"\n\n# L√≥gica\nirr &lt;- c(TRUE, FALSE)       # logical / logi\nclass(irr)\n\n[1] \"logical\"\n\n# Complexo\ncplx &lt;- 1 + 2i              # complex\nclass(cplx)\n\n[1] \"complex\"\n\n# Raw\nr &lt;- charToRaw(\"A\")         # raw\nclass(r)\n\n[1] \"raw\"\n\n# Datas\nd &lt;- as.Date(\"2025-08-29\")  # Date\nclass(d)\n\n[1] \"Date\"\n\ndt &lt;- as.POSIXct(\"2025-08-29 12:00:00\") # POSIXct\nclass(dt)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\nCriando banco de dados fict√≠cio\nNeste exemplo, iremos criar um banco de dados fict√≠cio de um experimento agr√≠cola com diferentes tipos de vari√°veis: num√©ricas (cont√≠nuas e discretas), categ√≥ricas, l√≥gicas e de texto.\nEm seguida, iremos visualizar o banco de dados e identificar os tipos de vari√°veis, para entender como o R armazena cada tipo e como podemos manipul√°-las em an√°lises estat√≠sticas.\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = factor(rep(c(\"T1\", \"T2\", \"T3\"), each = 3)), # Fator (categ√≥rica nominal)\n  Variedade = factor(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\")), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 3), # Fator (categ√≥rica nominal)\n  Variedade = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\nFun√ß√µes para Visualiza√ß√£o e Estrutura de Dados no R\n\nhead(dados_agro)\nMostra as primeiras linhas do conjunto de dados.\n\n√ötil para ter uma vis√£o r√°pida do conte√∫do do banco, verificando se os dados foram importados corretamente.\n\nExemplo de sa√≠da:\n\n\n\nhead(dados_agro) \n\n  Parcela Tratamento Variedade Area Produtividade Irrigado Local\n1       1         T1         A   10          30.5     TRUE Norte\n2       2         T1         A   10          32.0     TRUE Norte\n3       3         T1         A   10          31.0     TRUE Norte\n4       4         T2         B   12          28.0    FALSE   Sul\n5       5         T2         B   12          29.5    FALSE   Sul\n6       6         T2         B   12          30.0    FALSE   Sul\n\n\n\n\nstr(dados_agro)\n\nMostra a estrutura do objeto, permitindo entender rapidamente como os dados est√£o organizados no R.\nCom essa fun√ß√£o, √© poss√≠vel:\n\nVer o n√∫mero de observa√ß√µes (linhas) e o n√∫mero de vari√°veis (colunas) do banco de dados, por exemplo, 9 obs. of 7 variables.\n\nIdentificar o tipo de cada vari√°vel, como int (inteiro), num (num√©rico cont√≠nuo), Factor (categ√≥rica), logi (l√≥gica/boolean) e chr (texto).\n\nConferir alguns valores iniciais de cada coluna, ajudando a verificar se os dados foram importados corretamente e se os tipos est√£o adequados para an√°lise.\n\nEm resumo, str() √© uma fun√ß√£o essencial para inspecionar rapidamente a estrutura e os tipos das vari√°veis, antes de realizar qualquer an√°lise estat√≠stica ou manipula√ß√£o dos dados.\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : chr  \"T1\" \"T1\" \"T1\" \"T2\" ...\n $ Variedade    : chr  \"A\" \"A\" \"A\" \"B\" ...\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nObserve que Tratamento e Variedade aparecem como character, ou seja, texto.\nPara an√°lises estat√≠sticas, √© recomendado transformar essas vari√°veis em fatores.\n\n\nsummary(dados_agro)\n\nMostra um resumo estat√≠stico das vari√°veis:\n- Para vari√°veis num√©ricas: m√≠nimo, m√°ximo, m√©dia, quartis\n- Para fatores: contagem de cada n√≠vel\n- Para l√≥gicas: contagem de TRUE e FALSE\n- √ötil para identificar tend√™ncias, valores extremos e distribui√ß√£o dos dados.\n\nsummary(dados_agro)\n\n    Parcela   Tratamento         Variedade              Area    Produtividade  \n Min.   :1   Length:9           Length:9           Min.   :10   Min.   :28.00  \n 1st Qu.:3   Class :character   Class :character   1st Qu.:10   1st Qu.:30.00  \n Median :5   Mode  :character   Mode  :character   Median :11   Median :31.00  \n Mean   :5                                         Mean   :11   Mean   :31.22  \n 3rd Qu.:7                                         3rd Qu.:12   3rd Qu.:32.50  \n Max.   :9                                         Max.   :12   Max.   :34.50  \n  Irrigado          Local          \n Mode :logical   Length:9          \n FALSE:3         Class :character  \n TRUE :6         Mode  :character  \n                                   \n                                   \n                                   \n\n\nVeja novamente que Tratamento e Variedade aparecem como character.\nE n√£o s√£o reconhecidas como fatores.\nE n√£o √© poss√≠vel perceber quais s√£o os n√≠veis de cada vari√°vel categ√≥rica.\n\nConvertendo variaveis categ√≥ricas em fatores\n\nPode-se convert√™-las em fatores usando a fun√ß√£o as.factor():\n\n\ndados_agro$Tratamento &lt;- as.factor(dados_agro$Tratamento)\ndados_agro$Variedade &lt;- as.factor(dados_agro$Variedade)\n\nAgora veja como fica a estrutura dos dados:\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : Factor w/ 3 levels \"T1\",\"T2\",\"T3\": 1 1 1 2 2 2 3 3 3\n $ Variedade    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 1 1 2 2 2 3 3 3\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nAgora sim, Tratamento e variedade aparecem como Factor com 3 n√≠veis cada.\nveja como fica o resumo estat√≠stico dos dados:\n\nsummary(dados_agro)\n\n    Parcela  Tratamento Variedade      Area    Produtividade    Irrigado      \n Min.   :1   T1:3       A:3       Min.   :10   Min.   :28.00   Mode :logical  \n 1st Qu.:3   T2:3       B:3       1st Qu.:10   1st Qu.:30.00   FALSE:3        \n Median :5   T3:3       C:3       Median :11   Median :31.00   TRUE :6        \n Mean   :5                        Mean   :11   Mean   :31.22                  \n 3rd Qu.:7                        3rd Qu.:12   3rd Qu.:32.50                  \n Max.   :9                        Max.   :12   Max.   :34.50                  \n    Local          \n Length:9          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nAgora √© poss√≠vel ver a contagem de cada n√≠vel das vari√°veis categ√≥ricas. Ou seja, s√£o 3 n√≠veis em cada vari√°vel (T1, T2, T3 para Tratamento e A, B, C para Variedade).\n\nPode-se convert√™-las em fatores usando a fun√ß√£o factor():\n\nTamb√©m d√° para criar o fator diretamente com a fun√ß√£o factor(), que √© mais flex√≠vel porque permite:\n\nDefinir os n√≠veis (levels)\nDefinir as etiquetas (labels)\n\nOu seja, permite controlar a ordem e o r√≥tulo dos n√≠veis (mais recomendado para ANOVA e modelos, pois evita ordem alfab√©tica indesejada).\n\nPode-se ainda convert√™-las em fatores usando a fun√ß√£o convert_as_factor() do pacote {rstatix}:\n\nA fun√ß√£o convert_as_factor() pode converter uma ou v√°rias colunas ao mesmo tempo.\n\n\nglimpse(dados_agro) (do pacote dplyr)\n\nMostra a estrutura dos dados de forma compacta e leg√≠vel, similar ao str(), mas em formato horizontal:\n\nExibe todas as vari√°veis, seus tipos e algumas observa√ß√µes iniciais\n\nMais f√°cil de ler quando o banco de dados tem muitas colunas\n\nExemplo de sa√≠da (resumida):\n\nglimpse(dados_agro)\n\nRows: 9\nColumns: 7\n$ Parcela       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ Tratamento    &lt;fct&gt; Controle, Controle, Controle, Adubo, Adubo, Adubo, Bioes‚Ä¶\n$ Variedade     &lt;fct&gt; IPA 11, IPA 11, IPA 11, Campo Lindo, Campo Lindo, Campo ‚Ä¶\n$ Area          &lt;dbl&gt; 10, 10, 10, 12, 12, 12, 11, 11, 11\n$ Produtividade &lt;dbl&gt; 30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5\n$ Irrigado      &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE\n$ Local         &lt;chr&gt; \"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\",‚Ä¶\n\n\n\n\n\n\n\n# Exemplo fict√≠cio\ndados &lt;- data.frame(\n  tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 4),\n  repeticao = rep(1:4, 3),\n  produtividade = c(30, 32, 28, 31, 35, 36, 34, 37, 25, 27, 26, 28)\n)\n\n# Selecionar colunas e filtrar\ndados |&gt; dplyr::select(tratamento, produtividade) |&gt; filter(produtividade &gt; 30)\n\n  tratamento produtividade\n1         T1            32\n2         T1            31\n3         T2            35\n4         T2            36\n5         T2            34\n6         T2            37\n\n# Resumo estat√≠stico\ndados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    media = mean(produtividade),\n    sd = sd(produtividade)\n  )\n\n# A tibble: 3 √ó 3\n  tratamento media    sd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 T1          30.2  1.71\n2 T2          35.5  1.29\n3 T3          26.5  1.29\n\n\n\n\n\n\n\n# Histograma\nggplot(dados, aes(x = produtividade)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n# Boxplot\nggplot(dados, aes(x = tratamento, y = produtividade)) +\n  geom_boxplot(fill = \"orange\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Primeiro transformar vari√°veis em fatores\ndados$tratamento &lt;- factor(dados$tratamento)\ndados$repeticao &lt;- factor(dados$repeticao)\n\n# ANOVA usando aov()\nmodelo &lt;- aov(produtividade ~ tratamento, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamento   2 163.50   81.75   39.24 3.59e-05 ***\nResiduals    9  18.75    2.08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd     F        p p&lt;.05   ges\n1 tratamento   2   9 39.24 3.59e-05     * 0.897\n\n# ANOVA usando ExpDes.pt\ndic(\n  trat = dados$tratamento,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM    Fc      Pr&gt;Fc\nTratamento  2 163.50 81.750 39.24 3.5934e-05\nResiduo     9  18.75  2.083                 \nTotal      11 182.25                        \n------------------------------------------------------------------------\nCV = 4.69 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.5375769 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.8663487 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\neasyanova::ea1(dados[-2], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type I SS mean square F value    p&gt;F\ntreatments  2    163.50     81.7500   39.24 &lt;0.001\nResiduals   9     18.75      2.0833       -      -\n\n$Means\n  treatment  mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2 35.50 1.2910 0.7217  34  37     a   a      a a           a\n2        T1 30.25 1.7078 0.7217  28  32     b   b      b b           b\n3        T3 26.50 1.2910 0.7217  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 T2 - T1     5.25   0.0016 0.0006    0.0006 0.0006\n2 T2 - T3     9.00   0.0000 0.0000    0.0000 0.0000\n3 T1 - T3     3.75   0.0128 0.0051    0.0051 0.0051\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                             values\np.value Shapiro-Wilk test    0.5376\np.value Bartlett test        0.8663\ncoefficient of variation (%) 4.6900\nfirst value most discrepant  3.0000\nsecond value most discrepant 2.0000\nthird value most discrepant  8.0000\n\n$`Residual analysis`$residuals\n    1     2     3     4     5     6     7     8     9    10    11    12 \n-0.25  1.75 -2.25  0.75 -0.50  0.50 -1.50  1.50 -1.50  0.50 -0.50  1.50 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n-0.1914854  1.3403980 -1.7233688  0.5744563 -0.3829708  0.3829708 -1.1489125 \n         8          9         10         11         12 \n 1.1489125 -1.1489125  0.3829708 -0.3829708  1.1489125 \n\n\nTestes de Pressupostos\nAntes da an√°lise de vari√¢ncia (ANOVA), foi realizada a verifica√ß√£o dos pressupostos de normalidade dos res√≠duos e homogeneidade das vari√¢ncias, que s√£o condi√ß√µes necess√°rias para a validade do teste F.\nNormalidade dos res√≠duos\n\nO teste de Shapiro-Wilk foi aplicado sobre os res√≠duos do modelo, verificando se a distribui√ß√£o se aproxima da normal.\nAl√©m disso, a normalidade foi testada dentro de cada grupo experimental utilizando a fun√ß√£o shapiro_test() do pacote rstatix, o que permite avaliar poss√≠veis desvios em tratamentos espec√≠ficos.\nQuando o valor de p &gt; 0,05, n√£o se rejeita a hip√≥tese nula de normalidade, indicando que os res√≠duos podem ser considerados normalmente distribu√≠dos.\n\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.94298, p-value = 0.5376\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n\nHomogeneidade das vari√¢ncias\n\nPara verificar se os tratamentos apresentam vari√¢ncias homog√™neas, foram aplicados tr√™s testes:\n\nTeste de Bartlett: sens√≠vel a desvios de normalidade, mas adequado quando os dados s√£o normais.\nTeste de Levene: mais robusto quando a normalidade n√£o √© estritamente atendida.\n\n\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nDessa forma, a an√°lise de vari√¢ncia pode ser conduzida com confian√ßa, uma vez que os pressupostos de normalidade e homogeneidade foram verificados.\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento, data = dados)\n\n$tratamento\n       diff        lwr        upr     p adj\nT2-T1  5.25   2.400421  8.0995788 0.0015767\nT3-T1 -3.75  -6.599579 -0.9004212 0.0127984\nT3-T2 -9.00 -11.849579 -6.1504212 0.0000269\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean    SE df lower.CL upper.CL .group\n T3           26.5 0.722  9     24.4     28.6  a    \n T1           30.2 0.722  9     28.1     32.4   b   \n T2           35.5 0.722  9     33.4     37.6    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nAnova\nNo DBC (delineamento em blocos casualizados) a diferen√ßa principal √© que voc√™ precisa considerar o efeito de blocos no modelo. Seguindo o mesmo estilo da sua aula de DIC, aqui est√° a vers√£o para DBC:\n\n# ANOVA usando aov()\n# Aqui usamos Error(bloco) ou bloco como efeito\nmodelo &lt;- aov(produtividade ~ tratamento + repeticao, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \ntratamento   2 163.50   81.75 127.957 1.2e-05 ***\nrepeticao    3  14.92    4.97   7.783  0.0172 *  \nResiduals    6   3.83    0.64                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento + repeticao)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd       F       p p&lt;.05   ges\n1 tratamento   2   6 127.957 1.2e-05     * 0.977\n2  repeticao   3   6   7.783 1.7e-02     * 0.796\n\n# ANOVA usando ExpDes.pt\ndbc(\n  trat = dados$tratamento,\n  bloco = dados$repeticao,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ     QM      Fc    Pr&gt;Fc\nTratamento  2 163.500 81.750 127.957 0.000012\nBloco       3  14.917  4.972   7.783 0.017195\nResiduo     6   3.833  0.639                 \nTotal      11 182.250                        \n------------------------------------------------------------------------\nCV = 2.6 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.4793843 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.1530654 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\n# design = 2 corresponde a DBC\neasyanova::ea1(dados, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type III SS mean square  F value    p&gt;F\ntreatments  2    163.5000     81.7500 127.9565 &lt;0.001\nblocks      3     14.9167      4.9722   7.7826 0.0172\nresiduals   6      3.8333      0.6389        -      -\n\n$`Adjusted means`\n  treatment adjusted.mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2         35.50 1.2910 0.3997  34  37     a   a      a a           a\n2        T1         30.25 1.7078 0.3997  28  32     b   b      b b           b\n3        T3         26.50 1.2910 0.3997  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)  p(t)\n1 T2 - T1     5.25   0.0002  1e-04     1e-04 1e-04\n2 T2 - T3     9.00   0.0000  0e+00     0e+00 0e+00\n3 T1 - T3     3.75   0.0014  6e-04     6e-04 6e-04\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                              values\np.value Shapiro-Wilk test     0.4794\np.value Bartlett test         0.8663\ncoefficient of variation (%)  2.6000\nfirst value most discrepant  11.0000\nsecond value most discrepant  3.0000\nthird value most discrepant   2.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n 0.50000000  0.83333333 -0.83333333 -0.50000000  0.25000000 -0.41666667 \n          7           8           9          10          11          12 \n-0.08333333  0.25000000 -0.75000000 -0.41666667  0.91666667  0.25000000 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n 0.8469896  1.4116493 -1.4116493 -0.8469896  0.4234948 -0.7058246 -0.1411649 \n         8          9         10         11         12 \n 0.4234948 -1.2704843 -0.7058246  1.5528142  0.4234948 \n\n\nObserva√ß√µes importantes:\n\nNo aov(), o termo + bloco garante que a varia√ß√£o entre blocos seja considerada.\nNo ExpDes.pt, usamos dbc() no lugar de dic().\nNo easyanova, o argumento design = 2 √© usado para DBC.\n\nTestes de Pressupostos\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.93854, p-value = 0.4794\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n## Teste de ONeill e Mathews\noneilldbc(trat = dados$tratamento, resp = dados$produtividade, bloco = dados$repeticao)\n\n[1] 0.1530654\n\n\nEm DBC tamb√©m foi realizado Teste de O‚ÄôNeill e Mathews, espec√≠fico para experimentos em blocos casualizados (DBC), sendo recomendado como alternativa robusta para esse delineamento.\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento + repeticao, data = dados)\n\n$tratamento\n       diff        lwr       upr     p adj\nT2-T1  5.25   3.515829  6.984171 0.0002167\nT3-T1 -3.75  -5.484171 -2.015829 0.0013765\nT3-T2 -9.00 -10.734171 -7.265829 0.0000092\n\n$repeticao\n          diff        lwr         upr     p adj\n2-1  1.6666667 -0.5925501  3.92588339 0.1472526\n3-1 -0.6666667 -2.9258834  1.59255006 0.7441939\n4-1  2.0000000 -0.2592167  4.25921672 0.0796674\n3-2 -2.3333333 -4.5925501 -0.07411661 0.0438895\n4-2  0.3333333 -1.9258834  2.59255006 0.9535148\n4-3  2.6666667  0.4074499  4.92588339 0.0248704\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean  SE df lower.CL upper.CL .group\n T3           26.5 0.4  6     25.2     27.8  a    \n T1           30.2 0.4  6     28.9     31.6   b   \n T2           35.5 0.4  6     34.2     36.8    c  \n\nResults are averaged over the levels of: repeticao \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\n# Exemplo com dois fatores\ndados2 &lt;- expand.grid(\n  adubacao = c(\"A1\", \"A2\"),\n  cultivar = c(\"C1\", \"C2\", \"C3\"),\n  rep = 1:4\n)\n\nset.seed(123)\n\ndados2$produtividade &lt;- rnorm(24, mean = 30, sd = 3)\ndados2$adubacao &lt;- factor(dados2$adubacao)\ndados2$cultivar &lt;- factor(dados2$cultivar)\ndados2$rep &lt;- factor(dados2$rep)\n\n# ANOVA usando aov()\nmodelo2 &lt;- aov(produtividade ~ adubacao * cultivar, data = dados2)\nsummary(modelo2)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nadubacao           1   2.09   2.089   0.217  0.647\ncultivar           2   1.07   0.536   0.056  0.946\nadubacao:cultivar  2  13.72   6.861   0.712  0.504\nResiduals         18 173.43   9.635               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1          adubacao   1  18 0.217 0.647       0.012\n2          cultivar   2  18 0.056 0.946       0.006\n3 adubacao:cultivar   2  18 0.712 0.504       0.073\n\n# ExpDes.pt\nfat2.dic(\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nF1       1   2.089  3 0.21680 0.64708\nF2       2   1.073  2 0.05566 0.94602\nF1*F2    2  13.723  4 0.71212 0.50391\nResiduo 18 173.435  5                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.36 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6606527 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\neasyanova::ea2(dados2[-3], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2168 0.6471\nfactor_2           2      1.0726      0.5363  0.0557  0.946\nfactor_1:factor_2  2     13.7229      6.8614  0.7121 0.5039\nresiduals         18    173.4346      9.6353       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.8961     a   a      a a           a\n2       A2        29.679 3.2191 0.8961     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6471 0.6471    0.6471 0.6471\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.0975     a   a      a a           a\n2       C3       30.0767 3.6356 1.0975     a   a      a a           a\n3       C1       29.6795 1.9564 1.0975     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9982 0.9549    0.9549 0.9549\n2 C2 - C1   0.4862   0.9475 0.9475    0.7709 0.7577\n3 C3 - C1   0.3972   0.9646 0.8009    0.8009 0.8009\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3414 0.3414    0.3414 0.3414\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5146 0.5146    0.5146 0.5146\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6272 0.6272    0.6272 0.6272\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9980 0.9523    0.9523 0.9523\n2 A1.C1 - A1.C2   1.3158   0.8221 0.8221    0.5783 0.5563\n3 A1.C3 - A1.C2   1.1828   0.8533 0.5966    0.5966 0.5966\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8112 0.5430    0.5430 0.5430\n2 A2.C2 - A2.C1   2.2883   0.5605 0.5605    0.3371 0.3109\n3 A2.C3 - A2.C1   0.9275   0.9068 0.6776    0.6776 0.6776\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6607\np.value Bartlett test (factor_1)    0.5289\np.value Bartlett test (factor_2)    0.1309\np.value Bartlett test (treatments)  0.5464\ncoefficient of variation (%)       10.3600\nfirst value most discrepant         6.0000\nsecond value most discrepant       18.0000\nthird value most discrepant         3.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n-2.43335287  0.70247809  5.23998198 -0.68381331 -0.23104847  5.61066714 \n          7           8           9          10          11          12 \n 0.63082268 -2.40217314 -1.49670152 -2.23232439  3.05333372  1.54491366 \n         13          14          15          16          17          18 \n 0.45038842  1.72505871 -1.10366637  4.46540093  0.87463976 -5.43437929 \n         19          20          21          22          23          24 \n 1.35214177 -0.02536366 -2.63961408 -1.54926323 -3.69692502 -1.72120151 \n\n$`Residual analysis`$`standardized residuals`\n           1            2            3            4            5            6 \n-0.886137644  0.255816692  1.908208766 -0.249019664 -0.084139356  2.043198673 \n           7            8            9           10           11           12 \n 0.229722427 -0.874783133 -0.545043662 -0.812930463  1.111911873  0.562600750 \n          13           14           15           16           17           18 \n 0.164014901  0.628202953 -0.401914711  1.626134829  0.318511642 -1.979001121 \n          19           20           21           22           23           24 \n 0.492400316 -0.009236513 -0.961250393 -0.564184702 -1.346284159 -0.626798303 \n\n\n\n\n\n\n\n# ANOVA usando aov()\n# Aqui, bloco √© adicionado como efeito de erro\nmodelo_dbc &lt;- aov(produtividade ~ rep + adubacao * cultivar, data = dados2)\nsummary(modelo_dbc)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nrep                3  22.94   7.647   0.762  0.533\nadubacao           1   2.09   2.089   0.208  0.655\ncultivar           2   1.07   0.536   0.053  0.948\nadubacao:cultivar  2  13.72   6.861   0.684  0.520\nResiduals         15 150.49  10.033               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ rep + adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1               rep   3  15 0.762 0.533       0.132\n2          adubacao   1  15 0.208 0.655       0.014\n3          cultivar   2  15 0.053 0.948       0.007\n4 adubacao:cultivar   2  15 0.684 0.520       0.084\n\n# ExpDes.pt\n# fat2.dbc √© a fun√ß√£o para fatorial em blocos no pacote ExpDes.pt\nfat2.dbc(\n  bloco = dados2$rep,\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nBloco    3  22.942  6 0.76223 0.53264\nF1       1   2.089  4 0.20821 0.65471\nF2       2   1.073  2 0.05345 0.94813\nF1*F2    2  13.723  5 0.68390 0.51971\nResiduo 15 150.493  3                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.57 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6960048 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\n# Em DBC, design = 2 (fatorial em blocos)\neasyanova::ea2(dados2, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2082 0.6547\nfactor_2           2      1.0726      0.5363  0.0535 0.9481\nblocks             3     22.9420      7.6473  0.7622 0.5326\nfactor_1:factor_2  2     13.7229      6.8614  0.6839 0.5197\nresiduals         15    150.4926     10.0328       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.9144     a   a      a a           a\n2       A2        29.679 3.2191 0.9144     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6547 0.6547    0.6547 0.6547\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.1199     a   a      a a           a\n2       C3       30.0767 3.6356 1.1199     a   a      a a           a\n3       C1       29.6795 1.9564 1.1199     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9983 0.9559    0.9559 0.9559\n2 C2 - C1   0.4862   0.9495 0.9495    0.7754 0.7631\n3 C3 - C1   0.3972   0.9660 0.8054    0.8054 0.8054\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3534 0.3534    0.3534 0.3534\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5246 0.5246    0.5246 0.5246\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6353 0.6353    0.6353 0.6353\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9981 0.9534    0.9534 0.9534\n2 A1.C1 - A1.C2   1.3158   0.8288 0.8288    0.5862 0.5656\n3 A1.C3 - A1.C2   1.1828   0.8589 0.6051    0.6051 0.6051\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8182 0.5526    0.5526 0.5526\n2 A2.C2 - A2.C1   2.2883   0.5751 0.5751    0.3481 0.3231\n3 A2.C3 - A2.C1   0.9275   0.9104 0.6846    0.6846 0.6846\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6960\np.value Bartlett test (factor_1)    0.5441\np.value Bartlett test (factor_2)    0.6041\np.value Bartlett test (treatments)  0.8490\ncoefficient of variation (%)       10.5700\nfirst value most discrepant        18.0000\nsecond value most discrepant       16.0000\nthird value most discrepant         6.0000\n\n$`Residual analysis`$residuals\n         1          2          3          4          5          6          7 \n-3.8008383 -0.6650073  3.8724965 -2.0512987 -1.5985339  4.2431817  0.7811775 \n         8          9         10         11         12         13         14 \n-2.2518183 -1.3463467 -2.0819696  3.2036886  1.6952685  0.2874814  1.5621517 \n        15         16         17         18         19         20         21 \n-1.2665734  4.3024939  0.7117327 -5.5972863  2.7321794  1.3546740 -1.2595765 \n        22         23         24 \n-0.1692256 -2.3168874 -0.3411639 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n-1.48588700 -0.25997574  1.51390084 -0.80192786 -0.62492549  1.65881525 \n          7           8           9          10          11          12 \n 0.30539092 -0.88031831 -0.52633627 -0.81391821  1.25243928  0.66274259 \n         13          14          15          16          17          18 \n 0.11238701  0.61070235 -0.49514996  1.68200256  0.27824241 -2.18818437 \n         19          20          21          22          23          24 \n 1.06810906  0.52959170 -0.49241461 -0.06615649 -0.90575620 -0.13337347 \n\n\n\n\n\n\n\n\n\n\ndose &lt;- c(0, 50, 100, 150, 200)\nprod &lt;- c(20, 28, 35, 40, 38)\ndados_reg &lt;- data.frame(dose, prod)\n\nmodelo_reg &lt;- lm(prod ~ dose, data = dados_reg)\na &lt;- summary(modelo_reg)\n\n# Coeficientes\ncoeficientes &lt;- coef(modelo_reg)\nintercepto &lt;- round(coeficientes[1], 2) # sem sinal extra\nslope &lt;- formatC(coeficientes[2], format = \"f\", digits = 2, flag = \"+\") # sempre com sinal\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n\n\n\n# Equa√ß√£o no formato correto\nequacao &lt;- paste0(\"y = \", intercepto, slope, \"x\")\n\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", f_value,\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n\n\ndados_reg |&gt;\n  ggplot(aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  annotate(\"text\",\n           x = 100, y = 10,\n           label = legenda,\n           hjust = 0, size = 5) +\n  labs(x = \"Frequ√™ncia de irriga√ß√£o\", y = \"CRA (%)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ajustar modelo de regress√£o quadr√°tica\nmodelo_quad &lt;- lm(prod ~ dose + I(dose^2), data = dados_reg)\na &lt;- summary(modelo_quad)\na\n\n\nCall:\nlm(formula = prod ~ dose + I(dose^2), data = dados_reg)\n\nResiduals:\n      1       2       3       4       5 \n 0.5429 -0.9714 -0.3429  1.4286 -0.6571 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 19.4571429  1.3021176  14.943  0.00445 **\ndose         0.2217143  0.0308492   7.187  0.01882 * \nI(dose^2)   -0.0006286  0.0001479  -4.250  0.05116 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.384 on 2 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9715 \nF-statistic: 69.21 on 2 and 2 DF,  p-value: 0.01424\n\n# Coeficientes da regress√£o quadr√°tica (com mais casas decimais)\ncoef_quad &lt;- coef(modelo_quad)\nintercepto &lt;- formatC(coef_quad[1], format = \"f\", digits = 4)\nlinear     &lt;- formatC(coef_quad[2], format = \"f\", digits = 4, flag = \"+\")\nquadratico &lt;- formatC(coef_quad[3], format = \"f\", digits = 4, flag = \"+\") \n# usei 6 casas para o termo quadr√°tico porque geralmente √© bem pequeno\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n# Equa√ß√£o para legenda\nequacao &lt;- paste0(\"y = \", intercepto, \" \", linear, \"x \", quadratico, \"x¬≤\")\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", round(f_value, 2),\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n# Gr√°fico\nlibrary(ggplot2)\n\nregressao_quad &lt;- ggplot(dados_reg, aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  stat_smooth(\n    method = \"lm\",\n    formula = y ~ x + I(x^2),\n    se = FALSE,\n    color = \"black\"\n  ) +\n  annotate(\"text\", x = 50, y = 10, label = legenda, hjust = 0, size = 5) +\n  labs(x = \"Dose\", y = \"Produ√ß√£o\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n# Exibir gr√°fico\nregressao_quad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste pr√≥prio arquivo √© um exemplo.\n\nPode ser exportado em HTML, Word ou PDF.\n\n\n\n\n\n\nAnalise um conjunto de dados agr√≠colas (real ou fornecido):\n- Estruture os dados no Excel/CSV.\n- Importe para o R.\n- Realize ANOVA (com aov(), ExpDes.pt, easyanova e rstatix).\n- Teste pressupostos.\n- Se necess√°rio, ajuste modelos de regress√£o.\n- Gere gr√°ficos com ggplot2.\n- Organize os resultados em relat√≥rio RMarkdown."
  },
  {
    "objectID": "codigos.html#m√≥dulo-1-introdu√ß√£o-ao-r-e-organiza√ß√£o-de-dados",
    "href": "codigos.html#m√≥dulo-1-introdu√ß√£o-ao-r-e-organiza√ß√£o-de-dados",
    "title": "Primeiros passos",
    "section": "",
    "text": "Instale o R e o RStudio em seu computador.\n\n\nO R √© o programa principal, ou seja, a linguagem de programa√ß√£o e o ambiente de c√°lculo.\n√â nele que todos os comandos s√£o processados e as an√°lises estat√≠sticas s√£o realizadas.\nPor isso, o primeiro passo √© instalar o R no computador.\nO download deve ser feito diretamente no site oficial do CRAN (Comprehensive R Archive Network):\n https://cran.r-project.org/\nAo abrir o link, basta escolher o sistema operacional do seu computador (Windows, macOS ou Linux) e seguir as instru√ß√µes de instala√ß√£o.\nCom isso, voc√™ j√° ter√° o R funcionando, embora a sua interface seja bastante simples e pouco intuitiva para quem est√° come√ßando.\n√â justamente nesse ponto que entra o RStudio.\nO RStudio n√£o √© um programa separado do R, mas sim uma IDE (Integrated Development Environment), ou seja, um ambiente de desenvolvimento que facilita o uso do R.\nEle oferece uma interface gr√°fica amig√°vel, onde voc√™ pode escrever c√≥digos, visualizar gr√°ficos, organizar projetos e instalar pacotes com muito mais facilidade.\nNo entanto, √© fundamental compreender que o RStudio n√£o funciona sozinho.\nEle depende do R j√° instalado na m√°quina, pois √© o R quem executa de fato os c√°lculos.\nPor isso, a ordem correta √©: primeiro instalar o R e, em seguida, instalar o RStudio.\nO download do RStudio pode ser feito no site oficial da Posit (empresa respons√°vel pelo software):\nüëâ https://posit.co/download/rstudio-desktop/\nAo instalar os dois programas, voc√™ ter√° o R como motor de c√°lculo e o RStudio como painel de controle, trabalhando em conjunto.\nEssa combina√ß√£o √© a mais utilizada no mundo acad√™mico e profissional para an√°lises estat√≠sticas e ci√™ncia de dados.\n\nConhe√ßa os principais pain√©is do RStudio:\n\nConsole (execu√ß√£o de comandos)\n\nSource (script)\n\nEnvironment/History (objetos)\n\nPlots/Packages/Help\n\n\nVerificando vers√£o do R\n\n# Verificando vers√£o do R\nversion\n\n               _                                \nplatform       x86_64-w64-mingw32               \narch           x86_64                           \nos             mingw32                          \ncrt            ucrt                             \nsystem         x86_64, mingw32                  \nstatus                                          \nmajor          4                                \nminor          4.2                              \nyear           2024                             \nmonth          10                               \nday            31                               \nsvn rev        87279                            \nlanguage       R                                \nversion.string R version 4.4.2 (2024-10-31 ucrt)\nnickname       Pile of Leaves                   \n\n\nCitando o R\n\n# Cita√ß√£o do R\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nUma entrada BibTeX para usu√°rios(as) de LaTeX √©\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nOpera√ß√µes simples\n\n# Opera√ß√µes simples\n\n## Soma\n2 + 2\n\n[1] 4\n\n## Subtra√ß√£o\n7 - 2\n\n[1] 5\n\n## Mutiplica√ß√£o\n4 * 3\n\n[1] 12\n\n## Divis√£o\n10 / 3\n\n[1] 3.333333\n\n## Raiz quadrada\nsqrt(25)\n\n[1] 5\n\n\n\n\n\n\nNesta aula, aprendemos a criar e manipular objetos no R. Objetos s√£o vari√°veis que armazenam valores ou resultados de c√°lculos, permitindo que possamos reutiliz√°-los em outras opera√ß√µes.\nNo exemplo apresentado, criamos dois objetos num√©ricos:\n\n# Criando objetos\nx &lt;- 5\ny &lt;- 10\n\nAqui, x recebe o valor 5 e y recebe o valor 10. Em seguida, criamos um terceiro objeto chamado soma, que armazena a soma de x e y:\n\nsoma &lt;- x + y\nsoma\n\n[1] 15\n\n\nAo digitar apenas soma, o R retorna o valor armazenado neste objeto, que neste caso √© 15.\nEste exemplo ilustra a forma b√°sica de criar objetos no R e realizar opera√ß√µes simples com eles, fundamental para qualquer an√°lise de dados ou programa√ß√£o no software.\n\n\n\n\nNo R, os pacotes s√£o conjuntos de fun√ß√µes, dados e recursos que estendem as capacidades b√°sicas do software, permitindo realizar an√°lises mais complexas de forma pr√°tica e eficiente.\nNo exemplo abaixo, veja como instalar alguns pacotes importantes um de cada vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"dplyr\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e an√°lise de experimentos agr√≠colas\ninstall.packages(\"easyanova\")   # Para facilitar an√°lises de vari√¢ncia\ninstall.packages(\"rstatix\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organiza√ß√£o de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\nOuse preferir pode instalar v√°rios de uma √∫nica vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\", \"readxl\", \"ExpDes.pt\", \"easyanova\", \"rstatix\", \"emmeans\", \"janitor\", \"kableExtra\")\n\nNo exemplo abaixo, carregamos alguns pacotes importantes:\n\n# Carregando pacotes\n\n# ---------------------------\n# Pacotes para manipula√ß√£o e leitura de dados\n# ---------------------------\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipula√ß√£o de dados\nlibrary(readxl)      # Para importar planilhas Excel\n\n# ---------------------------\n# Pacotes para an√°lise de experimentos\n# ---------------------------\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n# ---------------------------\n# Pacotes para estat√≠stica e p√≥s-testes\n# ---------------------------\nlibrary(rstatix)     # Testes estat√≠sticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # M√©dias ajustadas e compara√ß√µes m√∫ltiplas\n\n# ---------------------------\n# Pacotes para organiza√ß√£o e visualiza√ß√£o de dados\n# ---------------------------\nlibrary(janitor)     # Limpeza e organiza√ß√£o de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n\n\n\n\nUm dos passos mais importantes em qualquer an√°lise √© a organiza√ß√£o adequada dos dados. Dados desorganizados ou com nomes de vari√°veis inconsistentes podem dificultar o trabalho, aumentar a chance de erros e at√© inviabilizar o uso de fun√ß√µes em softwares estat√≠sticos como o R.\nVeja esse esse exmeplo de banco de dados (dados_ruins_dic) no Excel:\n\n\n\n\n\nRepeti√ß√£o\nTratamento\nAltura da planta (cm)\nMat√©ria seca (g)\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nImport√¢ncia de bons t√≠tulos nas vari√°veis\nNo R, os nomes das colunas (ou t√≠tulos das vari√°veis) devem seguir algumas boas pr√°ticas para facilitar a an√°lise:\n\nPadr√£o snake_case: usar letras min√∫sculas e sublinhados para separar palavras, como altura_planta_g.\nEvitar espa√ßos: em vez de Altura da Planta, utilizar Altura_Planta.\n\nUsar unidades no nome da vari√°vel: em vez de Altura da Planta (cm), utilizar Altura_Planta_cm.\n\nUsar letras min√∫sculas (ou padr√£o definido): altura_planta_cm.\n\nEvitar acentos e caracteres especiais: em vez de Mat√©ria seca (g), utilizar materia_seca_g.\n\nSer descritivo, mas n√£o excessivamente longo: peso_frutos em vez de pf_colheita_experimental_2024.\n\nEsses cuidados tornam o banco de dados mais limpo, reprodut√≠vel e compat√≠vel com fun√ß√µes e pacotes do R.\nComo organizar os t√≠tulos\n\nPode fazer manulamente no Excel\n\nAntes de importar o arquivo para o R, pode-se renomear diretamente no Excel.\n\nExemplo: renomear a coluna de Massa seca total (g) para massa_seca_total_g.\n\nManualmente no R usando o pacote dplyr\n\nA fun√ß√£o rename() do pacote dplyr permite renomear manualmente colunas espec√≠ficas.\n\n# Renomear colunas espec√≠ficas\nlibrary(dplyr)\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    repeticao = `Repeti√ß√£o`,\n    tratamento = Tratamento,\n    altura_planta_cm = `Altura da planta (cm)`,\n    materia_seca_g = `Mat√©ria seca (g)`\n  )\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_dplyr)\n\n[1] \"repeticao\"        \"tratamento\"       \"altura_planta_cm\" \"materia_seca_g\"  \n\n\n\nAutom√°tico usando o pacote janitor\nExistem pacotes que auxiliam na padroniza√ß√£o dos nomes de maneira autom√°tica:\n\nPacote janitor: a fun√ß√£o clean_names() desse pacote converte automaticamente os t√≠tulos para um formato padr√£o (snake_case).\n\n\nVeja o que acontece com esse banco de dados (dados_ruins_dic):\n\n# Corrigir nomes das colunas -&gt; formato \"snake_case\"\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt; \n  janitor::clean_names()\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_da_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_janitor)\n\n[1] \"repeticao\"           \"tratamento\"          \"altura_da_planta_cm\"\n[4] \"materia_seca_g\"     \n\n\n\n\n\n\nImportando dados\nImportar dados para o R √© um passo fundamental para qualquer an√°lise. No R, √© poss√≠vel importar dados de diferentes formatos, o que √© essencial para iniciar qualquer an√°lise. O R permite ler diferentes formatos de arquivos, como CSV e Excel.\n\n# Importando CSV\n# dados_csv &lt;- read.csv(\"meus_dados.csv\", sep = \";\", dec = \",\")\n# L√™ arquivos CSV, permitindo especificar o separador de colunas (sep) e o separador decimal (dec)\n\n# Importando Excel\n# dados_excel &lt;- readxl::read_excel(\"meus_dados.xlsx\")\n# L√™ planilhas do Excel diretamente para o R\n\n# Importando arquivo de texto (TXT)\n# dados_txt &lt;- read.table(\"meus_dados.txt\", header = TRUE, sep = \"\\t\", dec = \".\")\n# L√™ arquivos de texto, onde 'header = TRUE' indica que a primeira linha cont√©m os nomes das colunas,\n# 'sep = \"\\t\"' indica que as colunas s√£o separadas por tabula√ß√£o, e 'dec = \".\"' define o separador decimal\n\n\nread.csv() l√™ arquivos no formato CSV (Comma-Separated Values), permitindo especificar o separador de colunas (sep) e o separador decimal (dec). √â indicado para planilhas exportadas como CSV ou dados gerados por outros programas.\nread_excel() (do pacote readxl) l√™ arquivos do Excel (.xls ou .xlsx) diretamente, mantendo nomes das colunas e tipos de dados corretamente, o que facilita a importa√ß√£o de planilhas complexas sem precisar convert√™-las.\nread.table() l√™ arquivos de texto simples (TXT ou outros delimitados), oferecendo flexibilidade para especificar se h√° cabe√ßalho (header = TRUE), o separador de colunas (sep) e o separador decimal (dec). √â ideal para arquivos de texto com diferentes formatos de separa√ß√£o.\n\nVisualizando os dados\nAp√≥s a importa√ß√£o, podemos visualizar os dados para verificar se foram carregados corretamente: Ap√≥s a importa√ß√£o, √© importante visualizar os dados para conferir se foram carregados corretamente. Para isso, podem ser usadas fun√ß√µes como:\n\nhead() (exibe as primeiras linhas),\nsummary() (mostra resumo estat√≠stico das vari√°veis),\nstr() (mostra a estrutura do objeto) e\nglimpse() (exibe de forma compacta e leg√≠vel a estrutura e os tipos das vari√°veis).\n\n\n# head(dados_csv)    # Mostra as primeiras linhas do conjunto de dados\n# summary(dados_csv) # Mostra um resumo estat√≠stico das vari√°veis\n# str(dados_csv)     # Mostra a estrutura do objeto, incluindo tipos de vari√°veis e dimens√µes\n# glimpse(dados_csv)  # Mostra todas as vari√°veis, seus tipos e algumas observa√ß√µes de cada coluna"
  },
  {
    "objectID": "codigos.html#m√≥dulo-2-manipula√ß√£o-e-explora√ß√£o-de-dados",
    "href": "codigos.html#m√≥dulo-2-manipula√ß√£o-e-explora√ß√£o-de-dados",
    "title": "Primeiros passos",
    "section": "",
    "text": "Vari√°veis num√©ricas\n\nCont√≠nuas (numeric / dbl): podem assumir qualquer valor dentro de um intervalo, incluindo decimais.\nExemplo: Produtividade (t/ha), √Årea (m¬≤)\nDiscretas (integer / int): assumem apenas valores inteiros.\nExemplo: Parcela (identificador das parcelas)\n\nVari√°veis categ√≥ricas (fatores) (factor / fct)\n\nRepresentam categorias ou grupos que o R reconhece para an√°lises estat√≠sticas.\nExemplo: Tratamento, Variedade\n\nIdeais para an√°lise de vari√¢ncia e compara√ß√µes entre grupos\n\nVari√°veis de texto (character / chr)\n\nCont√™m informa√ß√µes textuais ou descritivas, que n√£o t√™m ordem ou significado num√©rico.\nExemplo: Local (Norte, Sul, Leste)\n\nN√£o s√£o usadas diretamente em c√°lculos estat√≠sticos, mas servem para identificar ou agrupar dados\n\nVari√°veis l√≥gicas (logical / logi)\n\nAssumem apenas dois valores: TRUE ou FALSE\nExemplo: Irrigado\n\n√öteis para condi√ß√µes, filtros e an√°lises condicionais\n\nOutros tipos dispon√≠veis em R\n\nComplexo (complex / sem abrevia√ß√£o comum): n√∫meros complexos, como 1+2i\nRaw (raw / sem abrevia√ß√£o comum): representa dados brutos em bytes\n\nDate (Date / sem abrevia√ß√£o comum): datas no formato \"YYYY-MM-DD\"\n\nPOSIXct / POSIXlt (POSIXct / POSIXlt): datas e horas com tempo\nOrdered factor (ordered / ord): fatores com ordem natural definida\n\n\n\nNeste exemplo, iremos criar vari√°veis de diferentes tipos em R ‚Äî num√©ricas cont√≠nuas, num√©ricas discretas e categ√≥ricas (fatores) ‚Äî e, em seguida, identificar o tipo de cada vari√°vel usando a fun√ß√£o class().\nIsso nos permite compreender como o R armazena cada tipo de dado e como ele ser√° tratado em an√°lises estat√≠sticas.\n\n# Num√©rica cont√≠nua\nnum_cont &lt;- 3.5      # numeric / dbl\nclass(num_cont) # Checando classes\n\n[1] \"numeric\"\n\n# Num√©rica discreta\nnum_disc &lt;- 5L       # integer / int\nclass(num_disc)\n\n[1] \"integer\"\n\n# Fator (categ√≥rica)\ntrat &lt;- factor(c(\"T1\", \"T2\", \"T3\"))  # factor / fct\nclass(trat)\n\n[1] \"factor\"\n\n# Ordered factor\nord_trat &lt;- factor(c(\"Baixo\", \"M√©dio\", \"Alto\"), ordered = TRUE) # ordered / ord\nclass(ord_trat)\n\n[1] \"ordered\" \"factor\" \n\n# Character\nlocal &lt;- c(\"Norte\", \"Sul\")  # character / chr\nclass(local)\n\n[1] \"character\"\n\n# L√≥gica\nirr &lt;- c(TRUE, FALSE)       # logical / logi\nclass(irr)\n\n[1] \"logical\"\n\n# Complexo\ncplx &lt;- 1 + 2i              # complex\nclass(cplx)\n\n[1] \"complex\"\n\n# Raw\nr &lt;- charToRaw(\"A\")         # raw\nclass(r)\n\n[1] \"raw\"\n\n# Datas\nd &lt;- as.Date(\"2025-08-29\")  # Date\nclass(d)\n\n[1] \"Date\"\n\ndt &lt;- as.POSIXct(\"2025-08-29 12:00:00\") # POSIXct\nclass(dt)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\nCriando banco de dados fict√≠cio\nNeste exemplo, iremos criar um banco de dados fict√≠cio de um experimento agr√≠cola com diferentes tipos de vari√°veis: num√©ricas (cont√≠nuas e discretas), categ√≥ricas, l√≥gicas e de texto.\nEm seguida, iremos visualizar o banco de dados e identificar os tipos de vari√°veis, para entender como o R armazena cada tipo e como podemos manipul√°-las em an√°lises estat√≠sticas.\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = factor(rep(c(\"T1\", \"T2\", \"T3\"), each = 3)), # Fator (categ√≥rica nominal)\n  Variedade = factor(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\")), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 3), # Fator (categ√≥rica nominal)\n  Variedade = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\nFun√ß√µes para Visualiza√ß√£o e Estrutura de Dados no R\n\nhead(dados_agro)\nMostra as primeiras linhas do conjunto de dados.\n\n√ötil para ter uma vis√£o r√°pida do conte√∫do do banco, verificando se os dados foram importados corretamente.\n\nExemplo de sa√≠da:\n\n\n\nhead(dados_agro) \n\n  Parcela Tratamento Variedade Area Produtividade Irrigado Local\n1       1         T1         A   10          30.5     TRUE Norte\n2       2         T1         A   10          32.0     TRUE Norte\n3       3         T1         A   10          31.0     TRUE Norte\n4       4         T2         B   12          28.0    FALSE   Sul\n5       5         T2         B   12          29.5    FALSE   Sul\n6       6         T2         B   12          30.0    FALSE   Sul\n\n\n\n\nstr(dados_agro)\n\nMostra a estrutura do objeto, permitindo entender rapidamente como os dados est√£o organizados no R.\nCom essa fun√ß√£o, √© poss√≠vel:\n\nVer o n√∫mero de observa√ß√µes (linhas) e o n√∫mero de vari√°veis (colunas) do banco de dados, por exemplo, 9 obs. of 7 variables.\n\nIdentificar o tipo de cada vari√°vel, como int (inteiro), num (num√©rico cont√≠nuo), Factor (categ√≥rica), logi (l√≥gica/boolean) e chr (texto).\n\nConferir alguns valores iniciais de cada coluna, ajudando a verificar se os dados foram importados corretamente e se os tipos est√£o adequados para an√°lise.\n\nEm resumo, str() √© uma fun√ß√£o essencial para inspecionar rapidamente a estrutura e os tipos das vari√°veis, antes de realizar qualquer an√°lise estat√≠stica ou manipula√ß√£o dos dados.\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : chr  \"T1\" \"T1\" \"T1\" \"T2\" ...\n $ Variedade    : chr  \"A\" \"A\" \"A\" \"B\" ...\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nObserve que Tratamento e Variedade aparecem como character, ou seja, texto.\nPara an√°lises estat√≠sticas, √© recomendado transformar essas vari√°veis em fatores.\n\n\nsummary(dados_agro)\n\nMostra um resumo estat√≠stico das vari√°veis:\n- Para vari√°veis num√©ricas: m√≠nimo, m√°ximo, m√©dia, quartis\n- Para fatores: contagem de cada n√≠vel\n- Para l√≥gicas: contagem de TRUE e FALSE\n- √ötil para identificar tend√™ncias, valores extremos e distribui√ß√£o dos dados.\n\nsummary(dados_agro)\n\n    Parcela   Tratamento         Variedade              Area    Produtividade  \n Min.   :1   Length:9           Length:9           Min.   :10   Min.   :28.00  \n 1st Qu.:3   Class :character   Class :character   1st Qu.:10   1st Qu.:30.00  \n Median :5   Mode  :character   Mode  :character   Median :11   Median :31.00  \n Mean   :5                                         Mean   :11   Mean   :31.22  \n 3rd Qu.:7                                         3rd Qu.:12   3rd Qu.:32.50  \n Max.   :9                                         Max.   :12   Max.   :34.50  \n  Irrigado          Local          \n Mode :logical   Length:9          \n FALSE:3         Class :character  \n TRUE :6         Mode  :character  \n                                   \n                                   \n                                   \n\n\nVeja novamente que Tratamento e Variedade aparecem como character.\nE n√£o s√£o reconhecidas como fatores.\nE n√£o √© poss√≠vel perceber quais s√£o os n√≠veis de cada vari√°vel categ√≥rica.\n\nConvertendo variaveis categ√≥ricas em fatores\n\nPode-se convert√™-las em fatores usando a fun√ß√£o as.factor():\n\n\ndados_agro$Tratamento &lt;- as.factor(dados_agro$Tratamento)\ndados_agro$Variedade &lt;- as.factor(dados_agro$Variedade)\n\nAgora veja como fica a estrutura dos dados:\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : Factor w/ 3 levels \"T1\",\"T2\",\"T3\": 1 1 1 2 2 2 3 3 3\n $ Variedade    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 1 1 2 2 2 3 3 3\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nAgora sim, Tratamento e variedade aparecem como Factor com 3 n√≠veis cada.\nveja como fica o resumo estat√≠stico dos dados:\n\nsummary(dados_agro)\n\n    Parcela  Tratamento Variedade      Area    Produtividade    Irrigado      \n Min.   :1   T1:3       A:3       Min.   :10   Min.   :28.00   Mode :logical  \n 1st Qu.:3   T2:3       B:3       1st Qu.:10   1st Qu.:30.00   FALSE:3        \n Median :5   T3:3       C:3       Median :11   Median :31.00   TRUE :6        \n Mean   :5                        Mean   :11   Mean   :31.22                  \n 3rd Qu.:7                        3rd Qu.:12   3rd Qu.:32.50                  \n Max.   :9                        Max.   :12   Max.   :34.50                  \n    Local          \n Length:9          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nAgora √© poss√≠vel ver a contagem de cada n√≠vel das vari√°veis categ√≥ricas. Ou seja, s√£o 3 n√≠veis em cada vari√°vel (T1, T2, T3 para Tratamento e A, B, C para Variedade).\n\nPode-se convert√™-las em fatores usando a fun√ß√£o factor():\n\nTamb√©m d√° para criar o fator diretamente com a fun√ß√£o factor(), que √© mais flex√≠vel porque permite:\n\nDefinir os n√≠veis (levels)\nDefinir as etiquetas (labels)\n\nOu seja, permite controlar a ordem e o r√≥tulo dos n√≠veis (mais recomendado para ANOVA e modelos, pois evita ordem alfab√©tica indesejada).\n\nPode-se ainda convert√™-las em fatores usando a fun√ß√£o convert_as_factor() do pacote {rstatix}:\n\nA fun√ß√£o convert_as_factor() pode converter uma ou v√°rias colunas ao mesmo tempo.\n\n\nglimpse(dados_agro) (do pacote dplyr)\n\nMostra a estrutura dos dados de forma compacta e leg√≠vel, similar ao str(), mas em formato horizontal:\n\nExibe todas as vari√°veis, seus tipos e algumas observa√ß√µes iniciais\n\nMais f√°cil de ler quando o banco de dados tem muitas colunas\n\nExemplo de sa√≠da (resumida):\n\nglimpse(dados_agro)\n\nRows: 9\nColumns: 7\n$ Parcela       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ Tratamento    &lt;fct&gt; Controle, Controle, Controle, Adubo, Adubo, Adubo, Bioes‚Ä¶\n$ Variedade     &lt;fct&gt; IPA 11, IPA 11, IPA 11, Campo Lindo, Campo Lindo, Campo ‚Ä¶\n$ Area          &lt;dbl&gt; 10, 10, 10, 12, 12, 12, 11, 11, 11\n$ Produtividade &lt;dbl&gt; 30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5\n$ Irrigado      &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE\n$ Local         &lt;chr&gt; \"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\",‚Ä¶\n\n\n\n\n\n\n\n# Exemplo fict√≠cio\ndados &lt;- data.frame(\n  tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 4),\n  repeticao = rep(1:4, 3),\n  produtividade = c(30, 32, 28, 31, 35, 36, 34, 37, 25, 27, 26, 28)\n)\n\n# Selecionar colunas e filtrar\ndados |&gt; dplyr::select(tratamento, produtividade) |&gt; filter(produtividade &gt; 30)\n\n  tratamento produtividade\n1         T1            32\n2         T1            31\n3         T2            35\n4         T2            36\n5         T2            34\n6         T2            37\n\n# Resumo estat√≠stico\ndados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    media = mean(produtividade),\n    sd = sd(produtividade)\n  )\n\n# A tibble: 3 √ó 3\n  tratamento media    sd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 T1          30.2  1.71\n2 T2          35.5  1.29\n3 T3          26.5  1.29\n\n\n\n\n\n\n\n# Histograma\nggplot(dados, aes(x = produtividade)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n# Boxplot\nggplot(dados, aes(x = tratamento, y = produtividade)) +\n  geom_boxplot(fill = \"orange\")"
  },
  {
    "objectID": "codigos.html#m√≥dulo-3-an√°lise-de-vari√¢ncia-anova",
    "href": "codigos.html#m√≥dulo-3-an√°lise-de-vari√¢ncia-anova",
    "title": "Primeiros passos",
    "section": "",
    "text": "# Primeiro transformar vari√°veis em fatores\ndados$tratamento &lt;- factor(dados$tratamento)\ndados$repeticao &lt;- factor(dados$repeticao)\n\n# ANOVA usando aov()\nmodelo &lt;- aov(produtividade ~ tratamento, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamento   2 163.50   81.75   39.24 3.59e-05 ***\nResiduals    9  18.75    2.08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd     F        p p&lt;.05   ges\n1 tratamento   2   9 39.24 3.59e-05     * 0.897\n\n# ANOVA usando ExpDes.pt\ndic(\n  trat = dados$tratamento,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM    Fc      Pr&gt;Fc\nTratamento  2 163.50 81.750 39.24 3.5934e-05\nResiduo     9  18.75  2.083                 \nTotal      11 182.25                        \n------------------------------------------------------------------------\nCV = 4.69 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.5375769 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.8663487 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\neasyanova::ea1(dados[-2], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type I SS mean square F value    p&gt;F\ntreatments  2    163.50     81.7500   39.24 &lt;0.001\nResiduals   9     18.75      2.0833       -      -\n\n$Means\n  treatment  mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2 35.50 1.2910 0.7217  34  37     a   a      a a           a\n2        T1 30.25 1.7078 0.7217  28  32     b   b      b b           b\n3        T3 26.50 1.2910 0.7217  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 T2 - T1     5.25   0.0016 0.0006    0.0006 0.0006\n2 T2 - T3     9.00   0.0000 0.0000    0.0000 0.0000\n3 T1 - T3     3.75   0.0128 0.0051    0.0051 0.0051\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                             values\np.value Shapiro-Wilk test    0.5376\np.value Bartlett test        0.8663\ncoefficient of variation (%) 4.6900\nfirst value most discrepant  3.0000\nsecond value most discrepant 2.0000\nthird value most discrepant  8.0000\n\n$`Residual analysis`$residuals\n    1     2     3     4     5     6     7     8     9    10    11    12 \n-0.25  1.75 -2.25  0.75 -0.50  0.50 -1.50  1.50 -1.50  0.50 -0.50  1.50 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n-0.1914854  1.3403980 -1.7233688  0.5744563 -0.3829708  0.3829708 -1.1489125 \n         8          9         10         11         12 \n 1.1489125 -1.1489125  0.3829708 -0.3829708  1.1489125 \n\n\nTestes de Pressupostos\nAntes da an√°lise de vari√¢ncia (ANOVA), foi realizada a verifica√ß√£o dos pressupostos de normalidade dos res√≠duos e homogeneidade das vari√¢ncias, que s√£o condi√ß√µes necess√°rias para a validade do teste F.\nNormalidade dos res√≠duos\n\nO teste de Shapiro-Wilk foi aplicado sobre os res√≠duos do modelo, verificando se a distribui√ß√£o se aproxima da normal.\nAl√©m disso, a normalidade foi testada dentro de cada grupo experimental utilizando a fun√ß√£o shapiro_test() do pacote rstatix, o que permite avaliar poss√≠veis desvios em tratamentos espec√≠ficos.\nQuando o valor de p &gt; 0,05, n√£o se rejeita a hip√≥tese nula de normalidade, indicando que os res√≠duos podem ser considerados normalmente distribu√≠dos.\n\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.94298, p-value = 0.5376\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n\nHomogeneidade das vari√¢ncias\n\nPara verificar se os tratamentos apresentam vari√¢ncias homog√™neas, foram aplicados tr√™s testes:\n\nTeste de Bartlett: sens√≠vel a desvios de normalidade, mas adequado quando os dados s√£o normais.\nTeste de Levene: mais robusto quando a normalidade n√£o √© estritamente atendida.\n\n\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nDessa forma, a an√°lise de vari√¢ncia pode ser conduzida com confian√ßa, uma vez que os pressupostos de normalidade e homogeneidade foram verificados.\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento, data = dados)\n\n$tratamento\n       diff        lwr        upr     p adj\nT2-T1  5.25   2.400421  8.0995788 0.0015767\nT3-T1 -3.75  -6.599579 -0.9004212 0.0127984\nT3-T2 -9.00 -11.849579 -6.1504212 0.0000269\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean    SE df lower.CL upper.CL .group\n T3           26.5 0.722  9     24.4     28.6  a    \n T1           30.2 0.722  9     28.1     32.4   b   \n T2           35.5 0.722  9     33.4     37.6    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nAnova\nNo DBC (delineamento em blocos casualizados) a diferen√ßa principal √© que voc√™ precisa considerar o efeito de blocos no modelo. Seguindo o mesmo estilo da sua aula de DIC, aqui est√° a vers√£o para DBC:\n\n# ANOVA usando aov()\n# Aqui usamos Error(bloco) ou bloco como efeito\nmodelo &lt;- aov(produtividade ~ tratamento + repeticao, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \ntratamento   2 163.50   81.75 127.957 1.2e-05 ***\nrepeticao    3  14.92    4.97   7.783  0.0172 *  \nResiduals    6   3.83    0.64                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento + repeticao)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd       F       p p&lt;.05   ges\n1 tratamento   2   6 127.957 1.2e-05     * 0.977\n2  repeticao   3   6   7.783 1.7e-02     * 0.796\n\n# ANOVA usando ExpDes.pt\ndbc(\n  trat = dados$tratamento,\n  bloco = dados$repeticao,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ     QM      Fc    Pr&gt;Fc\nTratamento  2 163.500 81.750 127.957 0.000012\nBloco       3  14.917  4.972   7.783 0.017195\nResiduo     6   3.833  0.639                 \nTotal      11 182.250                        \n------------------------------------------------------------------------\nCV = 2.6 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.4793843 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.1530654 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\n# design = 2 corresponde a DBC\neasyanova::ea1(dados, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type III SS mean square  F value    p&gt;F\ntreatments  2    163.5000     81.7500 127.9565 &lt;0.001\nblocks      3     14.9167      4.9722   7.7826 0.0172\nresiduals   6      3.8333      0.6389        -      -\n\n$`Adjusted means`\n  treatment adjusted.mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2         35.50 1.2910 0.3997  34  37     a   a      a a           a\n2        T1         30.25 1.7078 0.3997  28  32     b   b      b b           b\n3        T3         26.50 1.2910 0.3997  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)  p(t)\n1 T2 - T1     5.25   0.0002  1e-04     1e-04 1e-04\n2 T2 - T3     9.00   0.0000  0e+00     0e+00 0e+00\n3 T1 - T3     3.75   0.0014  6e-04     6e-04 6e-04\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                              values\np.value Shapiro-Wilk test     0.4794\np.value Bartlett test         0.8663\ncoefficient of variation (%)  2.6000\nfirst value most discrepant  11.0000\nsecond value most discrepant  3.0000\nthird value most discrepant   2.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n 0.50000000  0.83333333 -0.83333333 -0.50000000  0.25000000 -0.41666667 \n          7           8           9          10          11          12 \n-0.08333333  0.25000000 -0.75000000 -0.41666667  0.91666667  0.25000000 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n 0.8469896  1.4116493 -1.4116493 -0.8469896  0.4234948 -0.7058246 -0.1411649 \n         8          9         10         11         12 \n 0.4234948 -1.2704843 -0.7058246  1.5528142  0.4234948 \n\n\nObserva√ß√µes importantes:\n\nNo aov(), o termo + bloco garante que a varia√ß√£o entre blocos seja considerada.\nNo ExpDes.pt, usamos dbc() no lugar de dic().\nNo easyanova, o argumento design = 2 √© usado para DBC.\n\nTestes de Pressupostos\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.93854, p-value = 0.4794\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n## Teste de ONeill e Mathews\noneilldbc(trat = dados$tratamento, resp = dados$produtividade, bloco = dados$repeticao)\n\n[1] 0.1530654\n\n\nEm DBC tamb√©m foi realizado Teste de O‚ÄôNeill e Mathews, espec√≠fico para experimentos em blocos casualizados (DBC), sendo recomendado como alternativa robusta para esse delineamento.\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento + repeticao, data = dados)\n\n$tratamento\n       diff        lwr       upr     p adj\nT2-T1  5.25   3.515829  6.984171 0.0002167\nT3-T1 -3.75  -5.484171 -2.015829 0.0013765\nT3-T2 -9.00 -10.734171 -7.265829 0.0000092\n\n$repeticao\n          diff        lwr         upr     p adj\n2-1  1.6666667 -0.5925501  3.92588339 0.1472526\n3-1 -0.6666667 -2.9258834  1.59255006 0.7441939\n4-1  2.0000000 -0.2592167  4.25921672 0.0796674\n3-2 -2.3333333 -4.5925501 -0.07411661 0.0438895\n4-2  0.3333333 -1.9258834  2.59255006 0.9535148\n4-3  2.6666667  0.4074499  4.92588339 0.0248704\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean  SE df lower.CL upper.CL .group\n T3           26.5 0.4  6     25.2     27.8  a    \n T1           30.2 0.4  6     28.9     31.6   b   \n T2           35.5 0.4  6     34.2     36.8    c  \n\nResults are averaged over the levels of: repeticao \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\n# Exemplo com dois fatores\ndados2 &lt;- expand.grid(\n  adubacao = c(\"A1\", \"A2\"),\n  cultivar = c(\"C1\", \"C2\", \"C3\"),\n  rep = 1:4\n)\n\nset.seed(123)\n\ndados2$produtividade &lt;- rnorm(24, mean = 30, sd = 3)\ndados2$adubacao &lt;- factor(dados2$adubacao)\ndados2$cultivar &lt;- factor(dados2$cultivar)\ndados2$rep &lt;- factor(dados2$rep)\n\n# ANOVA usando aov()\nmodelo2 &lt;- aov(produtividade ~ adubacao * cultivar, data = dados2)\nsummary(modelo2)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nadubacao           1   2.09   2.089   0.217  0.647\ncultivar           2   1.07   0.536   0.056  0.946\nadubacao:cultivar  2  13.72   6.861   0.712  0.504\nResiduals         18 173.43   9.635               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1          adubacao   1  18 0.217 0.647       0.012\n2          cultivar   2  18 0.056 0.946       0.006\n3 adubacao:cultivar   2  18 0.712 0.504       0.073\n\n# ExpDes.pt\nfat2.dic(\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nF1       1   2.089  3 0.21680 0.64708\nF2       2   1.073  2 0.05566 0.94602\nF1*F2    2  13.723  4 0.71212 0.50391\nResiduo 18 173.435  5                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.36 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6606527 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\neasyanova::ea2(dados2[-3], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2168 0.6471\nfactor_2           2      1.0726      0.5363  0.0557  0.946\nfactor_1:factor_2  2     13.7229      6.8614  0.7121 0.5039\nresiduals         18    173.4346      9.6353       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.8961     a   a      a a           a\n2       A2        29.679 3.2191 0.8961     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6471 0.6471    0.6471 0.6471\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.0975     a   a      a a           a\n2       C3       30.0767 3.6356 1.0975     a   a      a a           a\n3       C1       29.6795 1.9564 1.0975     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9982 0.9549    0.9549 0.9549\n2 C2 - C1   0.4862   0.9475 0.9475    0.7709 0.7577\n3 C3 - C1   0.3972   0.9646 0.8009    0.8009 0.8009\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3414 0.3414    0.3414 0.3414\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5146 0.5146    0.5146 0.5146\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6272 0.6272    0.6272 0.6272\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9980 0.9523    0.9523 0.9523\n2 A1.C1 - A1.C2   1.3158   0.8221 0.8221    0.5783 0.5563\n3 A1.C3 - A1.C2   1.1828   0.8533 0.5966    0.5966 0.5966\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8112 0.5430    0.5430 0.5430\n2 A2.C2 - A2.C1   2.2883   0.5605 0.5605    0.3371 0.3109\n3 A2.C3 - A2.C1   0.9275   0.9068 0.6776    0.6776 0.6776\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6607\np.value Bartlett test (factor_1)    0.5289\np.value Bartlett test (factor_2)    0.1309\np.value Bartlett test (treatments)  0.5464\ncoefficient of variation (%)       10.3600\nfirst value most discrepant         6.0000\nsecond value most discrepant       18.0000\nthird value most discrepant         3.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n-2.43335287  0.70247809  5.23998198 -0.68381331 -0.23104847  5.61066714 \n          7           8           9          10          11          12 \n 0.63082268 -2.40217314 -1.49670152 -2.23232439  3.05333372  1.54491366 \n         13          14          15          16          17          18 \n 0.45038842  1.72505871 -1.10366637  4.46540093  0.87463976 -5.43437929 \n         19          20          21          22          23          24 \n 1.35214177 -0.02536366 -2.63961408 -1.54926323 -3.69692502 -1.72120151 \n\n$`Residual analysis`$`standardized residuals`\n           1            2            3            4            5            6 \n-0.886137644  0.255816692  1.908208766 -0.249019664 -0.084139356  2.043198673 \n           7            8            9           10           11           12 \n 0.229722427 -0.874783133 -0.545043662 -0.812930463  1.111911873  0.562600750 \n          13           14           15           16           17           18 \n 0.164014901  0.628202953 -0.401914711  1.626134829  0.318511642 -1.979001121 \n          19           20           21           22           23           24 \n 0.492400316 -0.009236513 -0.961250393 -0.564184702 -1.346284159 -0.626798303 \n\n\n\n\n\n\n\n# ANOVA usando aov()\n# Aqui, bloco √© adicionado como efeito de erro\nmodelo_dbc &lt;- aov(produtividade ~ rep + adubacao * cultivar, data = dados2)\nsummary(modelo_dbc)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nrep                3  22.94   7.647   0.762  0.533\nadubacao           1   2.09   2.089   0.208  0.655\ncultivar           2   1.07   0.536   0.053  0.948\nadubacao:cultivar  2  13.72   6.861   0.684  0.520\nResiduals         15 150.49  10.033               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ rep + adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1               rep   3  15 0.762 0.533       0.132\n2          adubacao   1  15 0.208 0.655       0.014\n3          cultivar   2  15 0.053 0.948       0.007\n4 adubacao:cultivar   2  15 0.684 0.520       0.084\n\n# ExpDes.pt\n# fat2.dbc √© a fun√ß√£o para fatorial em blocos no pacote ExpDes.pt\nfat2.dbc(\n  bloco = dados2$rep,\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nBloco    3  22.942  6 0.76223 0.53264\nF1       1   2.089  4 0.20821 0.65471\nF2       2   1.073  2 0.05345 0.94813\nF1*F2    2  13.723  5 0.68390 0.51971\nResiduo 15 150.493  3                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.57 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6960048 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\n# Em DBC, design = 2 (fatorial em blocos)\neasyanova::ea2(dados2, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2082 0.6547\nfactor_2           2      1.0726      0.5363  0.0535 0.9481\nblocks             3     22.9420      7.6473  0.7622 0.5326\nfactor_1:factor_2  2     13.7229      6.8614  0.6839 0.5197\nresiduals         15    150.4926     10.0328       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.9144     a   a      a a           a\n2       A2        29.679 3.2191 0.9144     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6547 0.6547    0.6547 0.6547\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.1199     a   a      a a           a\n2       C3       30.0767 3.6356 1.1199     a   a      a a           a\n3       C1       29.6795 1.9564 1.1199     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9983 0.9559    0.9559 0.9559\n2 C2 - C1   0.4862   0.9495 0.9495    0.7754 0.7631\n3 C3 - C1   0.3972   0.9660 0.8054    0.8054 0.8054\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3534 0.3534    0.3534 0.3534\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5246 0.5246    0.5246 0.5246\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6353 0.6353    0.6353 0.6353\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9981 0.9534    0.9534 0.9534\n2 A1.C1 - A1.C2   1.3158   0.8288 0.8288    0.5862 0.5656\n3 A1.C3 - A1.C2   1.1828   0.8589 0.6051    0.6051 0.6051\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8182 0.5526    0.5526 0.5526\n2 A2.C2 - A2.C1   2.2883   0.5751 0.5751    0.3481 0.3231\n3 A2.C3 - A2.C1   0.9275   0.9104 0.6846    0.6846 0.6846\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6960\np.value Bartlett test (factor_1)    0.5441\np.value Bartlett test (factor_2)    0.6041\np.value Bartlett test (treatments)  0.8490\ncoefficient of variation (%)       10.5700\nfirst value most discrepant        18.0000\nsecond value most discrepant       16.0000\nthird value most discrepant         6.0000\n\n$`Residual analysis`$residuals\n         1          2          3          4          5          6          7 \n-3.8008383 -0.6650073  3.8724965 -2.0512987 -1.5985339  4.2431817  0.7811775 \n         8          9         10         11         12         13         14 \n-2.2518183 -1.3463467 -2.0819696  3.2036886  1.6952685  0.2874814  1.5621517 \n        15         16         17         18         19         20         21 \n-1.2665734  4.3024939  0.7117327 -5.5972863  2.7321794  1.3546740 -1.2595765 \n        22         23         24 \n-0.1692256 -2.3168874 -0.3411639 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n-1.48588700 -0.25997574  1.51390084 -0.80192786 -0.62492549  1.65881525 \n          7           8           9          10          11          12 \n 0.30539092 -0.88031831 -0.52633627 -0.81391821  1.25243928  0.66274259 \n         13          14          15          16          17          18 \n 0.11238701  0.61070235 -0.49514996  1.68200256  0.27824241 -2.18818437 \n         19          20          21          22          23          24 \n 1.06810906  0.52959170 -0.49241461 -0.06615649 -0.90575620 -0.13337347"
  },
  {
    "objectID": "codigos.html#m√≥dulo-4-regress√£o",
    "href": "codigos.html#m√≥dulo-4-regress√£o",
    "title": "Primeiros passos",
    "section": "",
    "text": "dose &lt;- c(0, 50, 100, 150, 200)\nprod &lt;- c(20, 28, 35, 40, 38)\ndados_reg &lt;- data.frame(dose, prod)\n\nmodelo_reg &lt;- lm(prod ~ dose, data = dados_reg)\na &lt;- summary(modelo_reg)\n\n# Coeficientes\ncoeficientes &lt;- coef(modelo_reg)\nintercepto &lt;- round(coeficientes[1], 2) # sem sinal extra\nslope &lt;- formatC(coeficientes[2], format = \"f\", digits = 2, flag = \"+\") # sempre com sinal\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n\n\n\n# Equa√ß√£o no formato correto\nequacao &lt;- paste0(\"y = \", intercepto, slope, \"x\")\n\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", f_value,\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n\n\ndados_reg |&gt;\n  ggplot(aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  annotate(\"text\",\n           x = 100, y = 10,\n           label = legenda,\n           hjust = 0, size = 5) +\n  labs(x = \"Frequ√™ncia de irriga√ß√£o\", y = \"CRA (%)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ajustar modelo de regress√£o quadr√°tica\nmodelo_quad &lt;- lm(prod ~ dose + I(dose^2), data = dados_reg)\na &lt;- summary(modelo_quad)\na\n\n\nCall:\nlm(formula = prod ~ dose + I(dose^2), data = dados_reg)\n\nResiduals:\n      1       2       3       4       5 \n 0.5429 -0.9714 -0.3429  1.4286 -0.6571 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 19.4571429  1.3021176  14.943  0.00445 **\ndose         0.2217143  0.0308492   7.187  0.01882 * \nI(dose^2)   -0.0006286  0.0001479  -4.250  0.05116 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.384 on 2 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9715 \nF-statistic: 69.21 on 2 and 2 DF,  p-value: 0.01424\n\n# Coeficientes da regress√£o quadr√°tica (com mais casas decimais)\ncoef_quad &lt;- coef(modelo_quad)\nintercepto &lt;- formatC(coef_quad[1], format = \"f\", digits = 4)\nlinear     &lt;- formatC(coef_quad[2], format = \"f\", digits = 4, flag = \"+\")\nquadratico &lt;- formatC(coef_quad[3], format = \"f\", digits = 4, flag = \"+\") \n# usei 6 casas para o termo quadr√°tico porque geralmente √© bem pequeno\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n# Equa√ß√£o para legenda\nequacao &lt;- paste0(\"y = \", intercepto, \" \", linear, \"x \", quadratico, \"x¬≤\")\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", round(f_value, 2),\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n# Gr√°fico\nlibrary(ggplot2)\n\nregressao_quad &lt;- ggplot(dados_reg, aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  stat_smooth(\n    method = \"lm\",\n    formula = y ~ x + I(x^2),\n    se = FALSE,\n    color = \"black\"\n  ) +\n  annotate(\"text\", x = 50, y = 10, label = legenda, hjust = 0, size = 5) +\n  labs(x = \"Dose\", y = \"Produ√ß√£o\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n# Exibir gr√°fico\nregressao_quad"
  },
  {
    "objectID": "codigos.html#m√≥dulo-5-relat√≥rios-e-projeto-final",
    "href": "codigos.html#m√≥dulo-5-relat√≥rios-e-projeto-final",
    "title": "Primeiros passos",
    "section": "",
    "text": "Este pr√≥prio arquivo √© um exemplo.\n\nPode ser exportado em HTML, Word ou PDF."
  },
  {
    "objectID": "codigos.html#projeto-final",
    "href": "codigos.html#projeto-final",
    "title": "Primeiros passos",
    "section": "",
    "text": "Analise um conjunto de dados agr√≠colas (real ou fornecido):\n- Estruture os dados no Excel/CSV.\n- Importe para o R.\n- Realize ANOVA (com aov(), ExpDes.pt, easyanova e rstatix).\n- Teste pressupostos.\n- Se necess√°rio, ajuste modelos de regress√£o.\n- Gere gr√°ficos com ggplot2.\n- Organize os resultados em relat√≥rio RMarkdown."
  },
  {
    "objectID": "andamento.html",
    "href": "andamento.html",
    "title": "Andamento do Curso",
    "section": "",
    "text": "Acompanhe o andamento do  Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola."
  },
  {
    "objectID": "andamento.html#aulas-ministradas",
    "href": "andamento.html#aulas-ministradas",
    "title": "Andamento do Curso",
    "section": "Aulas ministradas",
    "text": "Aulas ministradas\nAcompanhe o andamento das aulas minitradas no curso.\nAs aulas foram estruturadas de forma progressiva, para que cada etapa sirva de base para a seguinte.\n\n\n\nAulas ministradas no Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola.\n\n\nAula\nDescri√ß√£o\nData\nHor√°rio de n√≠cio da aula\nHor√°rio de fim da aula\nN√∫mero de horas\nAssunto\n\n\n\n\nAula 1\nPrimeiros passos no R e Rstudio.\n03/set/2025\n16:00\n17:10\n1.17\nInstala√ß√£o e atualiza√ß√£o do R; Instala√ß√£o e atualiza√ß√£o do RStudio; Apresenta√ß√£o da interface do RStudio; Cria√ß√£o e salvamento do primeiro script; Defini√ß√£o do diret√≥rio de trabalho (working directory) (setwd(); getwd()).\n\n\nAula 2\nConhecendo o RStudio e os tipos de vari√°veis no R\n04/set/2025\n10:00\n11:07\n1.12\nConhecendo os principais pain√©is do RStudio (Console , Editor/Script; Environment/History; Files/Plots/Packages/Help/Viewer); Comparar a diferen√ßa entre escrever direto no Console e salvar no Script; Reconhecendo os tipos de vari√°veis no Excel (num√©ricas, cont√≠nuas, discretas, categ√≥ricas, texto, data etc.).\n\n\nAula 3\nDiscuss√£o sobre tipos de vari√°veis e desenho de experimentos.\n10/set/2025\n16:00\n17:20\n1.33\nReconhecendo os tipos de vari√°veis no exerimento no Excel; Como organizar os dados no Excel; Entendo sobre vari√°veis dependentes e independentes; Entendendo sobre fatores e n√≠veis de fatores; Discuss√£o sobre desenho de experimento (simples e fatorial) e analises estat√≠sticas (param√©trica, n√£o-param√©trica, an√°lise univariada, bivariada e multivariada)."
  },
  {
    "objectID": "andamento.html#script-do-curso",
    "href": "andamento.html#script-do-curso",
    "title": "Andamento do Curso",
    "section": "Script do curso",
    "text": "Script do curso\nBaixe o script do curso e treine a progrma√ß√£o em [ utilizando o RStudio.\n\nCurso: Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola\nAutor: DSc. Marlenildo Ferreira Melo\nData: 03 de setembro de 2025\n\n Baixar script_cursoder.R\n Ver no GitHub\n\n\nMostrar/Ocultar script\n#' SCRIPT PARA AN√ÅLISE DE DADOS EXPERIMENTAIS EM R\n#' \n#' Curso: [Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola]\n#' Autor: [DSc. Marlenildo Ferreira Melo]\n#' Data: [03 de setembro de 2025]\n#' Vers√£o do R: [R version 4.5.1 (2025-06-13 ucrt)]\n#' Vers√£o do RStudio: [2025.05.1 Build 513]\n#' \n#' Objetivo: An√°lise de dados experimentais utilizando pacotes espec√≠ficos em R\n#' Descri√ß√£o: Este script cobre desde a instala√ß√£o e carregamento de pacotes,\n#' importa√ß√£o e organiza√ß√£o de dados, at√© a realiza√ß√£o de an√°lises estat√≠sticas\n#' como estat√≠sticas descritivas e an√°lise de vari√¢ncia (ANOVA).\n#' Requisitos: R e RStudio instalados, pacotes necess√°rios instalados\n\n\n#' ============================================================================\n# Aula 1. Introdu√ß√£o ao R e Rstudio----\n#' ===========================================================================\n#' Data: [03/set/2025]\n#'\n## 1.1 Primeiros passos----\n#' Instala√ß√£o e atualiza√ß√£o do R;\n#' Instala√ß√£o e atualiza√ß√£o do RStudio;\n#' Apresenta√ß√£o da interface do RStudio;\n#' Cria√ß√£o e salvamento do primeiro script;\n#'\n## 1.2. Diret√≥rio de trabalho----\n#' Defini√ß√£o do diret√≥rio de trabalho (working directory) \n#' Defina o diret√≥rio de trabalho para o local onde seus arquivos est√£o armazenados.\n#' Altere o caminho abaixo para o diret√≥rio desejado no seu computador.\n#' Exemplo de caminho no Windows: (\"C:/Users/SeuUsuario/Documentos/ProjetoR\")\n#' Use barras normais (/) ou duplas (\\\\) no Windows\n\nsetwd(\"C:/Users/marle/OneDrive/Documentos/Projetos R/site/logo_script\")\nsetwd(\"C:\\\\Users\\\\marle\\\\OneDrive\\\\Documentos\\\\Projetos R\\\\site\\\\logo_script\")\ngetwd() # Verifica o diret√≥rio de trabalho atual\n\n\n#' ============================================================================\n# Aula 2. Conhecendo o RStudio----\n#' ============================================================================\n#' Data: [04/set/2025]\n#'\n## 2.1 Conhecendo os pa√≠ne√≠s do RStudio\n#' Console , Editor/Script; Environment/History; Files/Plots/Packages/Help/Viewer);\n#' Comparar a diferen√ßa entre escrever direto no Console e salvar no Script;\n#'\n## 2.2 Reconhecendo tipos de vari√°veis\n#' Reconhecendo os tipos de vari√°veis no Excel:\n#' num√©ricas (cont√≠nuas, discretas)\n#' categ√≥ricas (nominal e ordinal, fatores)\n#' texto livre\n#' data\n#' l√≥gica (*boolean*) (VERDADEIRO/FALSO)\n\n\n#' ============================================================================\n# Aula 3. Instalando e carregando pacotes no R----\n#' ============================================================================\n#' Data: [10/set/2025]\n\n## 3.1 Instalando pacotes----\n\n### 3.1.1 Instala√ß√£o individual de pacotes----\ninstall.packages(\"tidyverse\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"dplyr\")       # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e an√°lise de experimentos agr√≠colas\ninstall.packages(\"easyanova\")   # Para facilitar an√°lises de vari√¢ncia\ninstall.packages(\"rstatix\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organiza√ß√£o de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\n### 3.1.2 Instalando pacotes de uma vez s√≥----\ninstall.packages(\n  \"tidyverse\",\n  \"readxl\",\n  \"ExpDes.pt\",\n  \"easyanova\",\n  \"rstatix\",\n  \"emmeans\",\n  \"janitor\",\n  \"kableExtra\"\n)\n\n## 3.2 Carregando pacotes----\n\n#' Pacotes para manipula√ß√£o e leitura de dados\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipula√ß√£o de dados\nlibrary(readxl)      # Para importar planilhas Excel\nlibrary(readr)       # Para importar arquivos de texto\n\n#' Pacotes para an√°lise de experimentos\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n#' Pacotes para estat√≠stica e p√≥s-testes\nlibrary(rstatix)     # Testes estat√≠sticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # M√©dias ajustadas e compara√ß√µes m√∫ltiplas\n\n#' Pacotes para organiza√ß√£o e visualiza√ß√£o de dados\nlibrary(janitor)     # Limpeza e organiza√ß√£o de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n## 3.3 Importando dados ara o R----\n\n### 3.3.1 Importando dados de um arquivo Excel usando pacote readxl----\ndados_ruins_dic &lt;- read_excel(\"C:\\\\Users\\\\marle\\\\OneDrive\\\\Documentos\\\\Projetos R\\\\site\\\\banco_dados\\\\dados_ruins_dic.xlsx\", sheet = \"Planilha1\")\n\n### 3.3.2 Importando dados de um arquivo .txt (arquivo de texo bloco de notas) usando pacote readr----\ndados_ruins_dic &lt;- read_delim(\"C:\\\\Users\\\\marle\\\\OneDrive\\\\Documentos\\\\Projetos R\\\\site\\\\banco_dados\\\\dados_ruins_dic.txt\", \n                              delim = \"\\t\", escape_double = FALSE, \n                              trim_ws = TRUE)\n\n\n\ndados_ruins_dic # Visualiza√ß√£o r√°pida no console\n\nView(dados_ruins_dic) # Visualiza√ß√£o em uma aba separada\n#' ============================================================================\n# 5. Renomear colunas espec√≠ficas----\n#' ============================================================================\n\n## 5.1 Usando pacote dplyr----\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    tratamento = Tratamento,\n    repeticao = `Repeti√ß√£o`,\n    altura_planta_cm = `Altura da planta (cm)`,\n    peso_fresco_g = `Peso fresco (g)`\n  )\n\ndados_organizados_dplyr\n\n## 5.2 Usando pacote janitor----\n#' formato \"snake_case\"\n\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt;\n  janitor::clean_names()\n\ndados_organizados_janitor\n\n\n#' ============================================================================\n# 6. Visualizando os dados----\n#' ============================================================================\n\n## 6.1 Visualiza√ß√£o dos dados originais----\n\ndados_organizados_janitor # Visualiza√ß√£o r√°pida no console\nView(dados_organizados_janitor) # Visualiza√ß√£o em uma aba separada (Atalho F2)\nhead(dados_organizados_janitor) # Primeiras linhas dos dados\ntail(dados_organizados_janitor) # √öltimas linhas dos dados\nnames(dados_organizados_janitor) # Nomes das colunas\n\n## 6.2 Visualiza√ß√£o da estrutura dos dados e resumo estat√≠stico----\n\nstr(dados_organizados_janitor) # Estrutura dos dados\nglimpse(dados_organizados_janitor) # Vis√£o geral dos dados (dplyr)\nsummary(dados_organizados_janitor) # Resumo estat√≠stico dos dados\n\n  \n#' ============================================================================\n# 7. Convertendo vari√°veis em fatores----\n#' ===========================================================================\n  \n## 7.1 Usando a fun√ß√£o `as.factor()`----\n  \ndados_organizados_janitor$tratamento &lt;- as.factor(dados_organizados_janitor$tratamento)\ndados_organizados_janitor$repeticao &lt;- as.factor(dados_organizados_janitor$repeticao)\n  \n  \nstr(dados_organizados_janitor) # Estrutura dos dados\nglimpse(dados_organizados_janitor) # Vis√£o geral dos dados (dplyr)\nsummary(dados_organizados_janitor) # Resumo estat√≠stico dos dados\n  \n##' 7.2 Usando a fun√ß√£o `convert_as_factor` do pacote rstatix----\n  \ndados_organizados_janitor &lt;- dados_organizados_janitor |&gt;\n  convert_as_factor(tratamento, repeticao)\n  \n  \nstr(dados_organizados_janitor) # Estrutura dos dados\nglimpse(dados_organizados_janitor) # Vis√£o geral dos dados (dplyr)\nsummary(dados_organizados_janitor) # Resumo estat√≠stico dos dados\n\n\n#' ============================================================================\n# 8. Conhecendo os tipos de vari√°veis no R----\n#' ============================================================================\n\n#' Exemplo de banco de dados com todos os tipos de vari√°veis\n#'   em experimenta√ß√£o agr√≠cola (Delineamento em Blocos Casualizados)\ndados_tipos &lt;- read_excel(\"dados_tipos.xlsx\", sheet = \"Planilha1\")\n\n  \n# Conferindo estrutura e resumo do banco\nstr(dados_tipos)          # Estrutura das vari√°veis\nglimpse(dados_tipos)      # Vis√£o geral das vari√°veis com dplyr\nsummary(dados_tipos)      # Resumo estat√≠stico dos dados\n  \n  \n# Renomeando colunas para facilitar o manuseio  \ndados_tipos_organizado &lt;- dados_tipos |&gt;\n    janitor::clean_names()\n\n# Visualizando parte do banco\nhead(dados_tipos_organizado) |&gt; view()\n\n\n#' EXPLICA√á√ÉO DOS TIPOS DE VARI√ÅVEIS\n\n#' 1) bloco -&gt; Vari√°vel num√©rica inteira (discreta)\n#' Representa os blocos do experimento (repeti√ß√µes). √â usada para controlar\n#' a variabilidade do campo. No R, aparece como \"numeric\" (ou \"integer\").\n\n#' 2) tipo_adubo -&gt; Vari√°vel de texto (character), pode ser transformada em fator\n#' Representa a descri√ß√£o do tratamento aplicado.\n#' Exemplo: \"Testemunha\", \"Adubo verde\".\n\n#' 3) tratamento -&gt; Vari√°vel categ√≥rica nominal (factor)\n#' √â o identificador do tratamento (T1, T2, ...).\n#' N√£o tem ordem l√≥gica, apenas categorias distintas.\n\n#' 4) data_coleta -&gt; Vari√°vel do tipo Date\n#' Representa a data em que os dados foram coletados.\n\n#' 5) nota_vigor -&gt; Vari√°vel ordinal\n#' Escala de 1 a 5 indicando o vigor da planta.\n#' Existe uma ordem (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\n#' 6) numero_folhas -&gt; Vari√°vel num√©rica inteira (discreta)\n#' Conta o n√∫mero de folhas da planta.\n#' S√≥ assume valores inteiros (5, 6, 7...).\n\n#' 7) altura_cm -&gt; Vari√°vel num√©rica cont√≠nua\n#' Medida da altura em cent√≠metros.\n#' Pode assumir qualquer valor real dentro de um intervalo.\n\n#' 8) sobreviveu -&gt; Vari√°vel l√≥gica (boolean)\n#' Indica se a planta sobreviveu (TRUE) ou morreu (FALSE).\n\n#' 9) observacao -&gt; Vari√°vel categ√≥rica nominal\n#' Anota√ß√µes pr√©-definidas sobre a planta: \"Normal\", \"Doen√ßa\", \"Atraso\".\n#' N√£o existe ordem entre as categorias.\n\n#' 10) comentario_livre -&gt; Vari√°vel de texto livre (character)\n#' Coment√°rios mais detalhados feitos pelo avaliador.\n#' Exemplo: \"Necessita irriga√ß√£o extra\", \"Presen√ßa de pragas\".\n\n#' ============================================================================\n# 9. Convertendo vari√°veis em fatores no banco 'dados_tipos' ----\n#' ============================================================================\n\n# Carregando pacote necess√°rio\nlibrary(rstatix)\nlibrary(dplyr)\n\n## 9.1 Usando a fun√ß√£o `as.factor()` ----\n\n# Convertendo vari√°veis categ√≥ricas para fator\ndados_tipos_organizado$tipo_de_adubo &lt;- as.factor(dados_tipos_organizado$tipo_de_adubo)\ndados_tipos_organizado$tratamento &lt;- as.factor(dados_tipos_organizado$tratamento)\ndados_tipos_organizado$observacao &lt;- as.factor(dados_tipos_organizado$observacao)\ndados_tipos_organizado$bloco &lt;- as.factor(dados_tipos_organizado$bloco) # opcional: bloco tamb√©m como fator\n\n# Conferindo estrutura e resumo do banco\nstr(dados_tipos_organizado)          # Estrutura das vari√°veis\nglimpse(dados_tipos_organizado)      # Vis√£o geral das vari√°veis com dplyr\nsummary(dados_tipos_organizado)      # Resumo estat√≠stico dos dados\n\n#' Estrutura geral do banco\ndados_tipos_organizado |&gt; view() # com v min√∫sculo - Visualiza√ß√£o em uma aba separada (Atalho F2)\ndados_tipos_organizado |&gt; View() # com v mai√∫sculo - Visualiza√ß√£o em uma aba separada (Atalho F2)\ndados_tipos_organizado |&gt;  str() # Estrutura das vari√°veis\ndados_tipos_organizado |&gt; glimpse() # Vis√£o geral dos dados (dplyr)\ndados_tipos_organizado |&gt; summary() # Resumo estat√≠stico dos dados\n\n\n\n## 9.2 Usando a fun√ß√£o `convert_as_factor()` do pacote rstatix ----\n\n# Convers√£o das vari√°veis categ√≥ricas para fatores de forma mais pr√°tica\ndados_tipos &lt;- dados_tipos %&gt;%\n  convert_as_factor(tipo_adubo, tratamento, observacao, bloco)\n\n# Conferindo novamente\nstr(dados_tipos)          # Estrutura das vari√°veis\nglimpse(dados_tipos)      # Vis√£o geral com dplyr\nsummary(dados_tipos)      # Resumo estat√≠stico\n\n\n#' ============================================================================\n# 10. Estat√≠sticas descritivas----\n#' ===========================================================================\n\n## 10.1 Estat√≠sticas descritivas gerais usando pacote dplyr----\n\n#' M√©dia geral\ndados_organizados_janitor |&gt;\n  summarise(\n    n = n(),  # Contagem total de observa√ß√µes\n    media_altura = mean(altura_da_planta_cm, na.rm = TRUE),  # M√©dia da altura\n    sd_altura = sd(altura_da_planta_cm, na.rm = TRUE),      # Desvio padr√£o da altura\n    media_peso = mean(peso_fresco_g, na.rm = TRUE),      # M√©dia do peso fresco\n    sd_peso = sd(peso_fresco_g, na.rm = TRUE)           # Desvio padr√£o do peso fresco\n  )\n\n#' M√©dia por tratamento\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  summarise(\n    n = n(),  # Contagem total de observa√ß√µes\n    media_altura = mean(altura_da_planta_cm, na.rm = TRUE),  # M√©dia da altura\n    sd_altura = sd(altura_da_planta_cm, na.rm = TRUE),      # Desvio padr√£o da altura\n    media_peso = mean(peso_fresco_g, na.rm = TRUE),      # M√©dia do peso fresco\n    sd_peso = sd(peso_fresco_g, na.rm = TRUE)           # Desvio padr√£o do peso fresco\n  )\n\n## 10.2 Estat√≠sticas descritivas usando pacote rstatix----\n\n#' Estat√≠sticas descritivas gerais *m√©dia e desvio-padr√£o*\ndados_organizados_janitor |&gt;\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g, type = \"mean_sd\")\n\n#' Estat√≠sticas descritivas por tratamento *m√©dia e desvio-padr√£o*\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g, type = \"mean_sd\")\n\n#' Estat√≠sticas descritivas por tratamento *m√©dia e erro-padr√£o*\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g, type = \"mean_se\")\n\n#' Estat√≠sticas descritivas completas por tratamento\ndados_organizados_janitor |&gt;\n  group_by(tratamento) |&gt;  # Agrupa por tratamento\n  rstatix::get_summary_stats(altura_da_planta_cm, peso_fresco_g)\n\n\n\n\n#' ============================================================================\n# 11. An√°lise de vari√¢ncia (ANOVA)----\n#' ===========================================================================\n\n## 11.1 Usando a fun√ß√£o `aov()`----\nmodelo &lt;- aov(altura_da_planta_cm  ~ tratamento, data = dados_organizados_janitor)\nsummary(modelo)\n\n## 11.2 Usando a fun√ß√£o `anova_test` do pacote rstatix----\ndados_organizados_janitor |&gt; anova_test(altura_da_planta_cm ~ tratamento) \n\n\n## 11.3 Usando a fun√ß√£o `dic()` do pacote ExpDes.pt----\n\ndic(\n  trat = dados_organizados_janitor$tratamento,\n  resp = dados_organizados_janitor$altura_da_planta_cm,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n## 11.4 Usando a fun√ß√£o `ea1` do pacote easyanova----\neasyanova::ea1(dados_organizados_janitor[-2], design = 1, plot = 2, list = TRUE)\n\n## 11.5 Usando o pacote easyanova (ANOVA)----\n\n\n## 11.6 Usando o pacote ExpDes.pt (DIC)----\n\n#' ANOVA para DIC\n#' O pacote ExpDes.pt √© espec√≠fico para experimentos agr√≠colas\n#' e facilita a an√°lise de delineamentos experimentais comuns.\n#' Ele √© especialmente √∫til para an√°lises de vari√¢ncia (ANOVA)\n#' em delineamentos inteiramente casualizados (DIC),\n#' delineamentos em blocos casualizados (DBC),\n#' parcelas subdivididas, entre outros.\n#' Ele tamb√©m oferece fun√ß√µes para realizar testes complementares,\n#' como o teste de Tukey, e para gerar gr√°ficos b√°sicos.\n#' #' A fun√ß√£o `dic()` do pacote ExpDes.pt √© usada para realizar a an√°lise de vari√¢ncia (ANOVA)\n#' em um delineamento inteiramente casualizado (DIC).\n#' Ela calcula a ANOVA para uma vari√°vel resposta em fun√ß√£o de um fator de tratamento,\n#' considerando as repeti√ß√µes do experimento.\n#' #' A fun√ß√£o tamb√©m pode realizar testes complementares, como o teste de Tukey,\n#' para comparar as m√©dias dos tratamentos.\n#' #' A sintaxe b√°sica da fun√ß√£o `dic()` √© a seguinte:\n#' #' ```R\n#' dic(response, treatment, block = NULL, quali = NULL, mcomp = \"tukey\", sigT = 0.05, sigF = 0.05, group = TRUE, console = TRUE)\n#' \n#' \n\n\n\n\n\n#'  ============================================================================\n#'  Fim do Script\n#'  ============================================================================"
  },
  {
    "objectID": "andamento.html#fa√ßa-as-atividades-propostas",
    "href": "andamento.html#fa√ßa-as-atividades-propostas",
    "title": "Andamento do Curso",
    "section": "Fa√ßa as atividades propostas",
    "text": "Fa√ßa as atividades propostas\n\nDesafios e exerc√≠cios √† frente!\n\nDesenvolva as atividades a seguir e fortale√ßa suas habilidades em R.\n\nAtividade 1\nNesta atividade voc√™ dever√° buscar um banco de dados, exportar para o Excel e, dentro do Excel, identificar os tipos de vari√°veis.\n\nProcure e selecione um banco de dados (de sites abertos ou de outra fonte confi√°vel).\n\nExporte o banco de dados para o Excel (formato .xlsx).\n\nAbra o banco no Excel.\n\nAnalise cada coluna e classifique o tipo de vari√°vel:\n\nNum√©rica (valores inteiros ou decimais)\n\nTexto / Caractere (nomes, palavras, descri√ß√µes)\n\nL√≥gica (valores Verdadeiro/Falso ou Sim/N√£o)\n\nCateg√≥rica / Fator (classes ou categorias, como tratamentos, cidades, esp√©cies etc.)\n\n\nCrie uma tabela resumo no Excel com as seguintes colunas:\n\nNome da vari√°vel\n\nTipo identificado\n\nJustificativa (por que √© desse tipo)\n\n\n\nüëâ Essa atividade vai treinar a percep√ß√£o dos diferentes tipos de vari√°veis e a organiza√ß√£o de informa√ß√µes em planilhas."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Marlenildo Melo √© Engenheiro Agr√¥nomo e doutror em Agronomia/Fitotecnia com foco em Melhoramento Gen√©tico, Tecnologia de Sementes e P√≥s-Colheita. Possui s√≥lida experi√™ncia em an√°lise de dados e estat√≠stica aplicada √† pesquisa agron√¥mica, utilizando a linguagem R para tratamento, visualiza√ß√£o e interpreta√ß√£o de dados.\n\n\nUniversidade Federal Rural do Semi-√Årido (UFERSA) | Mossor√≥, RN\nMestrado e Doutorado em Agronomia/Fitotecnia | 2016 - 2022\nInstituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia do Cear√° | Cear√°, CE\nEngenharia Agron√¥mica | 2012 - 2016\nUniversidade Federal do Cear√° | Cear√°, CE\nAdministra√ß√£o P√∫blica | 2011 - 2015\n\n\n\nPesquisador e Analista de Dados Agron√¥micos | 2016 - presente\nAtua√ß√£o em projetos de pesquisa envolvendo an√°lise de dados, estat√≠stica aplicada √† agronomia e uso avan√ßado da linguagem R para visualiza√ß√£o e interpreta√ß√£o de resultados.\n\n\n\nAcesse meus curr√≠culos ou entre em contato comigo atrav√©s dos links abaixo:\n Linktree\n marlenildo@gmail.com\n (84) 98752-1095"
  },
  {
    "objectID": "about.html#educa√ß√£o",
    "href": "about.html#educa√ß√£o",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Universidade Federal Rural do Semi-√Årido (UFERSA) | Mossor√≥, RN\nMestrado e Doutorado em Agronomia/Fitotecnia | 2016 - 2022\nInstituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia do Cear√° | Cear√°, CE\nEngenharia Agron√¥mica | 2012 - 2016\nUniversidade Federal do Cear√° | Cear√°, CE\nAdministra√ß√£o P√∫blica | 2011 - 2015"
  },
  {
    "objectID": "about.html#experi√™ncia-profissional",
    "href": "about.html#experi√™ncia-profissional",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Pesquisador e Analista de Dados Agron√¥micos | 2016 - presente\nAtua√ß√£o em projetos de pesquisa envolvendo an√°lise de dados, estat√≠stica aplicada √† agronomia e uso avan√ßado da linguagem R para visualiza√ß√£o e interpreta√ß√£o de resultados."
  },
  {
    "objectID": "about.html#meus-links",
    "href": "about.html#meus-links",
    "title": "Marlenildo Melo",
    "section": "",
    "text": "Acesse meus curr√≠culos ou entre em contato comigo atrav√©s dos links abaixo:\n Linktree\n marlenildo@gmail.com\n (84) 98752-1095"
  },
  {
    "objectID": "apresentacao.html",
    "href": "apresentacao.html",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Este material serve como guia para o curso Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola.\nCada aula cont√©m explica√ß√µes te√≥ricas resumidas e c√≥digos pr√°ticos para serem executados no RStudio.\n\n\nObjetivo: Familiarizar o aluno com R, RStudio e a prepara√ß√£o correta dos dados.\n\n\n\nO que √© R e RStudio\nInstala√ß√£o passo a passo\nEstrutura do RStudio (console, script, environment, plots, packages)\n\n\n\n\n\nComandos b√°sicos\nOperadores aritm√©ticos e l√≥gicos\nCriando e manipulando objetos\n\n\n\n\n\ninstall.packages(), library()\nPacotes √∫teis: tidyverse, readxl, agricolae, emmeans, broom, ggplot2\nComo procurar ajuda e documenta√ß√£o\n\n\n\n\n\nComo estruturar dados no Excel (linhas = observa√ß√µes, colunas = vari√°veis)\nImporta√ß√£o de arquivos (.csv, .xlsx, .txt)\nUso de read.csv(), readxl::read_excel(), read.table()\nVerifica√ß√£o e limpeza dos dados (head(), str(), summary())\n\n\n\n\n\n\nObjetivo: Aprender a organizar, transformar e explorar dados antes da an√°lise.\n\n\n\ndplyr: select(), filter(), mutate(), summarise(), group_by()\ntidyr: pivot_longer(), pivot_wider()\n\n\n\n\n\nM√©dias, desvios-padr√£o, erro-padr√£o\nTabelas resumo com dplyr\nVisualiza√ß√µes iniciais: histogramas, boxplots, gr√°ficos de barras\n\n\n\n\n\nEstrutura do ggplot2\nGr√°ficos b√°sicos aplicados a dados de experimenta√ß√£o agr√≠cola\nPersonaliza√ß√£o de gr√°ficos\n\n\n\n\n\nDelineamentos b√°sicos: DIC, DBC\nEstrutura dos dados em experimenta√ß√£o agr√≠cola\nPrepara√ß√£o dos dados no Excel para cada delineamento\n\n\n\n\n\n\nObjetivo: Ensinar a rodar ANOVA, verificar pressupostos e interpretar resultados, utilizando diferentes pacotes.\n\n\n\nFun√ß√µes base: aov()\nANOVA com ExpDes.pt (dic())\nANOVA com easyanova\n\n\n\n\n\nFun√ß√µes base: aov()\nANOVA com ExpDes.pt (dbc())\nCompara√ß√£o da sa√≠da entre pacotes\n\n\n\n\n\nNormalidade dos res√≠duos: shapiro.test(), rstatix::shapiro_test()\nHomogeneidade: bartlett.test(), car::leveneTest(), rstatix::levene_test()\nInterpreta√ß√£o pr√°tica\n\n\n\n\n\nTukeyHSD() (base R)\nExpDes.pt (j√° integrado √† ANOVA)\nemmeans + cld()\nrstatix::t_test() e rstatix::anova_test()\n\n\n\n\n\nDois fatores com aov()\nDois fatores com ExpDes.pt::fat2.dic() e fat2.dbc()\nInterpreta√ß√£o das intera√ß√µes\n\n\n\n\n\nEstrutura de dados\nExpDes.pt::psub2.dbc() (ou fun√ß√µes equivalentes)\nModelos mistos com lme4::lmer()\n\n\n\n\n\nbroom::tidy() para organizar tabelas\nExporta√ß√£o de resultados com rstatix (get_anova_table())\nApresenta√ß√£o de m√©dias e letras com agricolae, emmeans e ExpDes.pt\n\n\n\n\n\nMesmos dados analisados em aov(), ExpDes.pt, easyanova e rstatix\nDiscuss√£o: qual usar em cada situa√ß√£o\n\n\n\n\n\n\nObjetivo: Introduzir regress√£o e aplica√ß√µes em experimenta√ß√£o agr√≠cola.\n\n\n\nConceito, ajuste com lm()\nGr√°ficos de regress√£o no ggplot2\n\n\n\n\n\nlm(y ~ poly(x, 2))\nAplica√ß√µes em curvas de dose, tempo, crescimento\n\n\n\n\n\nCrit√©rios AIC e BIC\nCompara√ß√£o de modelos\n\n\n\n\n\nnls()\nAjuste de curvas de resposta √† dose\n\n\n\n\n\nglm(family = binomial)\nExemplos em fitossanidade e sobreviv√™ncia\n\n\n\n\n\n\n\n\n\nObjetivo: Consolidar o aprendizado com aplica√ß√µes pr√°ticas.\n\n\n\nUso do RMarkdown\nExportar para Word e PDF\nOrganiza√ß√£o dos resultados\n\n\n\n\nCada aluno analisa um banco de dados de experimenta√ß√£o agr√≠cola.\nEntrega de relat√≥rio com:\n\nEstrutura dos dados\nANOVA + testes de m√©dias ou regress√£o\nGr√°ficos e tabelas\nInterpreta√ß√£o\n\n\n\n\n\n\n\nSemanas 1-2: R, RStudio, pacotes, organiza√ß√£o/importa√ß√£o de dados\n\nSemanas 3-4: Manipula√ß√£o de dados, gr√°ficos, delineamentos\n\nSemanas 5-8: ANOVA com base R, ExpDes.pt, easyanova e rstatix\n\nSemanas 9-11: Regress√£o (linear, polinomial, n√£o linear, log√≠stica)\n\nSemana 12: Relat√≥rios e Projeto Final"
  },
  {
    "objectID": "apresentacao.html#m√≥dulo-1-introdu√ß√£o-ao-r-e-organiza√ß√£o-de-dados-semanas-1-2",
    "href": "apresentacao.html#m√≥dulo-1-introdu√ß√£o-ao-r-e-organiza√ß√£o-de-dados-semanas-1-2",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Objetivo: Familiarizar o aluno com R, RStudio e a prepara√ß√£o correta dos dados.\n\n\n\nO que √© R e RStudio\nInstala√ß√£o passo a passo\nEstrutura do RStudio (console, script, environment, plots, packages)\n\n\n\n\n\nComandos b√°sicos\nOperadores aritm√©ticos e l√≥gicos\nCriando e manipulando objetos\n\n\n\n\n\ninstall.packages(), library()\nPacotes √∫teis: tidyverse, readxl, agricolae, emmeans, broom, ggplot2\nComo procurar ajuda e documenta√ß√£o\n\n\n\n\n\nComo estruturar dados no Excel (linhas = observa√ß√µes, colunas = vari√°veis)\nImporta√ß√£o de arquivos (.csv, .xlsx, .txt)\nUso de read.csv(), readxl::read_excel(), read.table()\nVerifica√ß√£o e limpeza dos dados (head(), str(), summary())"
  },
  {
    "objectID": "apresentacao.html#m√≥dulo-2-manipula√ß√£o-e-explora√ß√£o-de-dados-semanas-3-4",
    "href": "apresentacao.html#m√≥dulo-2-manipula√ß√£o-e-explora√ß√£o-de-dados-semanas-3-4",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Objetivo: Aprender a organizar, transformar e explorar dados antes da an√°lise.\n\n\n\ndplyr: select(), filter(), mutate(), summarise(), group_by()\ntidyr: pivot_longer(), pivot_wider()\n\n\n\n\n\nM√©dias, desvios-padr√£o, erro-padr√£o\nTabelas resumo com dplyr\nVisualiza√ß√µes iniciais: histogramas, boxplots, gr√°ficos de barras\n\n\n\n\n\nEstrutura do ggplot2\nGr√°ficos b√°sicos aplicados a dados de experimenta√ß√£o agr√≠cola\nPersonaliza√ß√£o de gr√°ficos\n\n\n\n\n\nDelineamentos b√°sicos: DIC, DBC\nEstrutura dos dados em experimenta√ß√£o agr√≠cola\nPrepara√ß√£o dos dados no Excel para cada delineamento"
  },
  {
    "objectID": "apresentacao.html#m√≥dulo-3-an√°lise-de-vari√¢ncia-anova-semanas-5-8",
    "href": "apresentacao.html#m√≥dulo-3-an√°lise-de-vari√¢ncia-anova-semanas-5-8",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Objetivo: Ensinar a rodar ANOVA, verificar pressupostos e interpretar resultados, utilizando diferentes pacotes.\n\n\n\nFun√ß√µes base: aov()\nANOVA com ExpDes.pt (dic())\nANOVA com easyanova\n\n\n\n\n\nFun√ß√µes base: aov()\nANOVA com ExpDes.pt (dbc())\nCompara√ß√£o da sa√≠da entre pacotes\n\n\n\n\n\nNormalidade dos res√≠duos: shapiro.test(), rstatix::shapiro_test()\nHomogeneidade: bartlett.test(), car::leveneTest(), rstatix::levene_test()\nInterpreta√ß√£o pr√°tica\n\n\n\n\n\nTukeyHSD() (base R)\nExpDes.pt (j√° integrado √† ANOVA)\nemmeans + cld()\nrstatix::t_test() e rstatix::anova_test()\n\n\n\n\n\nDois fatores com aov()\nDois fatores com ExpDes.pt::fat2.dic() e fat2.dbc()\nInterpreta√ß√£o das intera√ß√µes\n\n\n\n\n\nEstrutura de dados\nExpDes.pt::psub2.dbc() (ou fun√ß√µes equivalentes)\nModelos mistos com lme4::lmer()\n\n\n\n\n\nbroom::tidy() para organizar tabelas\nExporta√ß√£o de resultados com rstatix (get_anova_table())\nApresenta√ß√£o de m√©dias e letras com agricolae, emmeans e ExpDes.pt\n\n\n\n\n\nMesmos dados analisados em aov(), ExpDes.pt, easyanova e rstatix\nDiscuss√£o: qual usar em cada situa√ß√£o"
  },
  {
    "objectID": "apresentacao.html#m√≥dulo-4-regress√£o-e-modelos-semanas-9-11",
    "href": "apresentacao.html#m√≥dulo-4-regress√£o-e-modelos-semanas-9-11",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Objetivo: Introduzir regress√£o e aplica√ß√µes em experimenta√ß√£o agr√≠cola.\n\n\n\nConceito, ajuste com lm()\nGr√°ficos de regress√£o no ggplot2\n\n\n\n\n\nlm(y ~ poly(x, 2))\nAplica√ß√µes em curvas de dose, tempo, crescimento\n\n\n\n\n\nCrit√©rios AIC e BIC\nCompara√ß√£o de modelos\n\n\n\n\n\nnls()\nAjuste de curvas de resposta √† dose\n\n\n\n\n\nglm(family = binomial)\nExemplos em fitossanidade e sobreviv√™ncia"
  },
  {
    "objectID": "apresentacao.html#m√≥dulo-5-encerramento-e-projeto-final-semana-12",
    "href": "apresentacao.html#m√≥dulo-5-encerramento-e-projeto-final-semana-12",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Objetivo: Consolidar o aprendizado com aplica√ß√µes pr√°ticas.\n\n\n\nUso do RMarkdown\nExportar para Word e PDF\nOrganiza√ß√£o dos resultados\n\n\n\n\nCada aluno analisa um banco de dados de experimenta√ß√£o agr√≠cola.\nEntrega de relat√≥rio com:\n\nEstrutura dos dados\nANOVA + testes de m√©dias ou regress√£o\nGr√°ficos e tabelas\nInterpreta√ß√£o"
  },
  {
    "objectID": "apresentacao.html#cronograma-resumido-atualizado",
    "href": "apresentacao.html#cronograma-resumido-atualizado",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Semanas 1-2: R, RStudio, pacotes, organiza√ß√£o/importa√ß√£o de dados\n\nSemanas 3-4: Manipula√ß√£o de dados, gr√°ficos, delineamentos\n\nSemanas 5-8: ANOVA com base R, ExpDes.pt, easyanova e rstatix\n\nSemanas 9-11: Regress√£o (linear, polinomial, n√£o linear, log√≠stica)\n\nSemana 12: Relat√≥rios e Projeto Final"
  },
  {
    "objectID": "cursoder/index.html",
    "href": "cursoder/index.html",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Instale o R e o RStudio em seu computador.\n\n\nO R √© o programa principal, ou seja, a linguagem de programa√ß√£o e o ambiente de c√°lculo.\n√â nele que todos os comandos s√£o processados e as an√°lises estat√≠sticas s√£o realizadas.\nPor isso, o primeiro passo √© instalar o R no computador.\nO download deve ser feito diretamente no site oficial do CRAN (Comprehensive R Archive Network):\n https://cran.r-project.org/\nAo abrir o link, basta escolher o sistema operacional do seu computador (Windows, macOS ou Linux) e seguir as instru√ß√µes de instala√ß√£o.\nCom isso, voc√™ j√° ter√° o R funcionando, embora a sua interface seja bastante simples e pouco intuitiva para quem est√° come√ßando.\n√â justamente nesse ponto que entra o RStudio.\nO RStudio n√£o √© um programa separado do R, mas sim uma IDE (Integrated Development Environment), ou seja, um ambiente de desenvolvimento que facilita o uso do R.\nEle oferece uma interface gr√°fica amig√°vel, onde voc√™ pode escrever c√≥digos, visualizar gr√°ficos, organizar projetos e instalar pacotes com muito mais facilidade.\nNo entanto, √© fundamental compreender que o RStudio n√£o funciona sozinho.\nEle depende do R j√° instalado na m√°quina, pois √© o R quem executa de fato os c√°lculos.\nPor isso, a ordem correta √©: primeiro instalar o R e, em seguida, instalar o RStudio.\nO download do RStudio pode ser feito no site oficial da Posit (empresa respons√°vel pelo software):\nüëâ https://posit.co/download/rstudio-desktop/\nAo instalar os dois programas, voc√™ ter√° o R como motor de c√°lculo e o RStudio como painel de controle, trabalhando em conjunto.\nEssa combina√ß√£o √© a mais utilizada no mundo acad√™mico e profissional para an√°lises estat√≠sticas e ci√™ncia de dados.\n\nConhe√ßa os principais pain√©is do RStudio:\n\nConsole (execu√ß√£o de comandos)\n\nSource (script)\n\nEnvironment/History (objetos)\n\nPlots/Packages/Help\n\n\nVerificando vers√£o do R\n\n# Verificando vers√£o do R\nversion\n\n               _                                \nplatform       x86_64-w64-mingw32               \narch           x86_64                           \nos             mingw32                          \ncrt            ucrt                             \nsystem         x86_64, mingw32                  \nstatus                                          \nmajor          4                                \nminor          4.2                              \nyear           2024                             \nmonth          10                               \nday            31                               \nsvn rev        87279                            \nlanguage       R                                \nversion.string R version 4.4.2 (2024-10-31 ucrt)\nnickname       Pile of Leaves                   \n\n\nCitando o R\n\n# Cita√ß√£o do R\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nUma entrada BibTeX para usu√°rios(as) de LaTeX √©\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nOpera√ß√µes simples\n\n# Opera√ß√µes simples\n\n## Soma\n2 + 2\n\n[1] 4\n\n## Subtra√ß√£o\n7 - 2\n\n[1] 5\n\n## Mutiplica√ß√£o\n4 * 3\n\n[1] 12\n\n## Divis√£o\n10 / 3\n\n[1] 3.333333\n\n## Raiz quadrada\nsqrt(25)\n\n[1] 5\n\n\n\n\n\n\nNesta aula, aprendemos a criar e manipular objetos no R. Objetos s√£o vari√°veis que armazenam valores ou resultados de c√°lculos, permitindo que possamos reutiliz√°-los em outras opera√ß√µes.\nNo exemplo apresentado, criamos dois objetos num√©ricos:\n\n# Criando objetos\nx &lt;- 5\ny &lt;- 10\n\nAqui, x recebe o valor 5 e y recebe o valor 10. Em seguida, criamos um terceiro objeto chamado soma, que armazena a soma de x e y:\n\nsoma &lt;- x + y\nsoma\n\n[1] 15\n\n\nAo digitar apenas soma, o R retorna o valor armazenado neste objeto, que neste caso √© 15.\nEste exemplo ilustra a forma b√°sica de criar objetos no R e realizar opera√ß√µes simples com eles, fundamental para qualquer an√°lise de dados ou programa√ß√£o no software.\n\n\n\n\nNo R, os pacotes s√£o conjuntos de fun√ß√µes, dados e recursos que estendem as capacidades b√°sicas do software, permitindo realizar an√°lises mais complexas de forma pr√°tica e eficiente.\nNo exemplo abaixo, veja como instalar alguns pacotes importantes um de cada vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"dplyr\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e an√°lise de experimentos agr√≠colas\ninstall.packages(\"easyanova\")   # Para facilitar an√°lises de vari√¢ncia\ninstall.packages(\"rstatix\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organiza√ß√£o de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\nOuse preferir pode instalar v√°rios de uma √∫nica vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\", \"readxl\", \"ExpDes.pt\", \"easyanova\", \"rstatix\", \"emmeans\", \"janitor\", \"kableExtra\")\n\nNo exemplo abaixo, carregamos alguns pacotes importantes:\n\n# Carregando pacotes\n\n# ---------------------------\n# Pacotes para manipula√ß√£o e leitura de dados\n# ---------------------------\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipula√ß√£o de dados\nlibrary(readxl)      # Para importar planilhas Excel\n\n# ---------------------------\n# Pacotes para an√°lise de experimentos\n# ---------------------------\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n# ---------------------------\n# Pacotes para estat√≠stica e p√≥s-testes\n# ---------------------------\nlibrary(rstatix)     # Testes estat√≠sticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # M√©dias ajustadas e compara√ß√µes m√∫ltiplas\n\n# ---------------------------\n# Pacotes para organiza√ß√£o e visualiza√ß√£o de dados\n# ---------------------------\nlibrary(janitor)     # Limpeza e organiza√ß√£o de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n\n\n\n\nUm dos passos mais importantes em qualquer an√°lise √© a organiza√ß√£o adequada dos dados. Dados desorganizados ou com nomes de vari√°veis inconsistentes podem dificultar o trabalho, aumentar a chance de erros e at√© inviabilizar o uso de fun√ß√µes em softwares estat√≠sticos como o R.\nVeja esse esse exmeplo de banco de dados (dados_ruins_dic) no Excel:\n\n\n\n\n\nRepeti√ß√£o\nTratamento\nAltura da planta (cm)\nMat√©ria seca (g)\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nImport√¢ncia de bons t√≠tulos nas vari√°veis\nNo R, os nomes das colunas (ou t√≠tulos das vari√°veis) devem seguir algumas boas pr√°ticas para facilitar a an√°lise:\n\nPadr√£o snake_case: usar letras min√∫sculas e sublinhados para separar palavras, como altura_planta_g.\nEvitar espa√ßos: em vez de Altura da Planta, utilizar Altura_Planta.\n\nUsar unidades no nome da vari√°vel: em vez de Altura da Planta (cm), utilizar Altura_Planta_cm.\n\nUsar letras min√∫sculas (ou padr√£o definido): altura_planta_cm.\n\nEvitar acentos e caracteres especiais: em vez de Mat√©ria seca (g), utilizar materia_seca_g.\n\nSer descritivo, mas n√£o excessivamente longo: peso_frutos em vez de pf_colheita_experimental_2024.\n\nEsses cuidados tornam o banco de dados mais limpo, reprodut√≠vel e compat√≠vel com fun√ß√µes e pacotes do R.\nComo organizar os t√≠tulos\n\nPode fazer manulamente no Excel\n\nAntes de importar o arquivo para o R, pode-se renomear diretamente no Excel.\n\nExemplo: renomear a coluna de Massa seca total (g) para massa_seca_total_g.\n\nManualmente no R usando o pacote dplyr\n\nA fun√ß√£o rename() do pacote dplyr permite renomear manualmente colunas espec√≠ficas.\n\n# Renomear colunas espec√≠ficas\nlibrary(dplyr)\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    repeticao = `Repeti√ß√£o`,\n    tratamento = Tratamento,\n    altura_planta_cm = `Altura da planta (cm)`,\n    materia_seca_g = `Mat√©ria seca (g)`\n  )\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_dplyr)\n\n[1] \"repeticao\"        \"tratamento\"       \"altura_planta_cm\" \"materia_seca_g\"  \n\n\n\nAutom√°tico usando o pacote janitor\nExistem pacotes que auxiliam na padroniza√ß√£o dos nomes de maneira autom√°tica:\n\nPacote janitor: a fun√ß√£o clean_names() desse pacote converte automaticamente os t√≠tulos para um formato padr√£o (snake_case).\n\n\nVeja o que acontece com esse banco de dados (dados_ruins_dic):\n\n# Corrigir nomes das colunas -&gt; formato \"snake_case\"\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt; \n  janitor::clean_names()\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_da_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_janitor)\n\n[1] \"repeticao\"           \"tratamento\"          \"altura_da_planta_cm\"\n[4] \"materia_seca_g\"     \n\n\n\n\n\n\nImportando dados\nImportar dados para o R √© um passo fundamental para qualquer an√°lise. No R, √© poss√≠vel importar dados de diferentes formatos, o que √© essencial para iniciar qualquer an√°lise. O R permite ler diferentes formatos de arquivos, como CSV e Excel.\n\n# Importando CSV\n# dados_csv &lt;- read.csv(\"meus_dados.csv\", sep = \";\", dec = \",\")\n# L√™ arquivos CSV, permitindo especificar o separador de colunas (sep) e o separador decimal (dec)\n\n# Importando Excel\n# dados_excel &lt;- readxl::read_excel(\"meus_dados.xlsx\")\n# L√™ planilhas do Excel diretamente para o R\n\n# Importando arquivo de texto (TXT)\n# dados_txt &lt;- read.table(\"meus_dados.txt\", header = TRUE, sep = \"\\t\", dec = \".\")\n# L√™ arquivos de texto, onde 'header = TRUE' indica que a primeira linha cont√©m os nomes das colunas,\n# 'sep = \"\\t\"' indica que as colunas s√£o separadas por tabula√ß√£o, e 'dec = \".\"' define o separador decimal\n\n\nread.csv() l√™ arquivos no formato CSV (Comma-Separated Values), permitindo especificar o separador de colunas (sep) e o separador decimal (dec). √â indicado para planilhas exportadas como CSV ou dados gerados por outros programas.\nread_excel() (do pacote readxl) l√™ arquivos do Excel (.xls ou .xlsx) diretamente, mantendo nomes das colunas e tipos de dados corretamente, o que facilita a importa√ß√£o de planilhas complexas sem precisar convert√™-las.\nread.table() l√™ arquivos de texto simples (TXT ou outros delimitados), oferecendo flexibilidade para especificar se h√° cabe√ßalho (header = TRUE), o separador de colunas (sep) e o separador decimal (dec). √â ideal para arquivos de texto com diferentes formatos de separa√ß√£o.\n\nVisualizando os dados\nAp√≥s a importa√ß√£o, podemos visualizar os dados para verificar se foram carregados corretamente: Ap√≥s a importa√ß√£o, √© importante visualizar os dados para conferir se foram carregados corretamente. Para isso, podem ser usadas fun√ß√µes como:\n\nhead() (exibe as primeiras linhas),\nsummary() (mostra resumo estat√≠stico das vari√°veis),\nstr() (mostra a estrutura do objeto) e\nglimpse() (exibe de forma compacta e leg√≠vel a estrutura e os tipos das vari√°veis).\n\n\n# head(dados_csv)    # Mostra as primeiras linhas do conjunto de dados\n# summary(dados_csv) # Mostra um resumo estat√≠stico das vari√°veis\n# str(dados_csv)     # Mostra a estrutura do objeto, incluindo tipos de vari√°veis e dimens√µes\n# glimpse(dados_csv)  # Mostra todas as vari√°veis, seus tipos e algumas observa√ß√µes de cada coluna\n\n\n\n\n\n\n\n\n\nVari√°veis num√©ricas\n\nCont√≠nuas (numeric / dbl): podem assumir qualquer valor dentro de um intervalo, incluindo decimais.\nExemplo: Produtividade (t/ha), √Årea (m¬≤)\nDiscretas (integer / int): assumem apenas valores inteiros.\nExemplo: Parcela (identificador das parcelas)\n\nVari√°veis categ√≥ricas (fatores) (factor / fct)\n\nRepresentam categorias ou grupos que o R reconhece para an√°lises estat√≠sticas.\nExemplo: Tratamento, Variedade\n\nIdeais para an√°lise de vari√¢ncia e compara√ß√µes entre grupos\n\nVari√°veis de texto (character / chr)\n\nCont√™m informa√ß√µes textuais ou descritivas, que n√£o t√™m ordem ou significado num√©rico.\nExemplo: Local (Norte, Sul, Leste)\n\nN√£o s√£o usadas diretamente em c√°lculos estat√≠sticos, mas servem para identificar ou agrupar dados\n\nVari√°veis l√≥gicas (logical / logi)\n\nAssumem apenas dois valores: TRUE ou FALSE\nExemplo: Irrigado\n\n√öteis para condi√ß√µes, filtros e an√°lises condicionais\n\nOutros tipos dispon√≠veis em R\n\nComplexo (complex / sem abrevia√ß√£o comum): n√∫meros complexos, como 1+2i\nRaw (raw / sem abrevia√ß√£o comum): representa dados brutos em bytes\n\nDate (Date / sem abrevia√ß√£o comum): datas no formato \"YYYY-MM-DD\"\n\nPOSIXct / POSIXlt (POSIXct / POSIXlt): datas e horas com tempo\nOrdered factor (ordered / ord): fatores com ordem natural definida\n\n\n\nNeste exemplo, iremos criar vari√°veis de diferentes tipos em R ‚Äî num√©ricas cont√≠nuas, num√©ricas discretas e categ√≥ricas (fatores) ‚Äî e, em seguida, identificar o tipo de cada vari√°vel usando a fun√ß√£o class().\nIsso nos permite compreender como o R armazena cada tipo de dado e como ele ser√° tratado em an√°lises estat√≠sticas.\n\n# Num√©rica cont√≠nua\nnum_cont &lt;- 3.5      # numeric / dbl\nclass(num_cont) # Checando classes\n\n[1] \"numeric\"\n\n# Num√©rica discreta\nnum_disc &lt;- 5L       # integer / int\nclass(num_disc)\n\n[1] \"integer\"\n\n# Fator (categ√≥rica)\ntrat &lt;- factor(c(\"T1\", \"T2\", \"T3\"))  # factor / fct\nclass(trat)\n\n[1] \"factor\"\n\n# Ordered factor\nord_trat &lt;- factor(c(\"Baixo\", \"M√©dio\", \"Alto\"), ordered = TRUE) # ordered / ord\nclass(ord_trat)\n\n[1] \"ordered\" \"factor\" \n\n# Character\nlocal &lt;- c(\"Norte\", \"Sul\")  # character / chr\nclass(local)\n\n[1] \"character\"\n\n# L√≥gica\nirr &lt;- c(TRUE, FALSE)       # logical / logi\nclass(irr)\n\n[1] \"logical\"\n\n# Complexo\ncplx &lt;- 1 + 2i              # complex\nclass(cplx)\n\n[1] \"complex\"\n\n# Raw\nr &lt;- charToRaw(\"A\")         # raw\nclass(r)\n\n[1] \"raw\"\n\n# Datas\nd &lt;- as.Date(\"2025-08-29\")  # Date\nclass(d)\n\n[1] \"Date\"\n\ndt &lt;- as.POSIXct(\"2025-08-29 12:00:00\") # POSIXct\nclass(dt)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\nCriando banco de dados fict√≠cio\nNeste exemplo, iremos criar um banco de dados fict√≠cio de um experimento agr√≠cola com diferentes tipos de vari√°veis: num√©ricas (cont√≠nuas e discretas), categ√≥ricas, l√≥gicas e de texto.\nEm seguida, iremos visualizar o banco de dados e identificar os tipos de vari√°veis, para entender como o R armazena cada tipo e como podemos manipul√°-las em an√°lises estat√≠sticas.\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = factor(rep(c(\"T1\", \"T2\", \"T3\"), each = 3)), # Fator (categ√≥rica nominal)\n  Variedade = factor(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\")), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 3), # Fator (categ√≥rica nominal)\n  Variedade = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\nFun√ß√µes para Visualiza√ß√£o e Estrutura de Dados no R\n\nhead(dados_agro)\nMostra as primeiras linhas do conjunto de dados.\n\n√ötil para ter uma vis√£o r√°pida do conte√∫do do banco, verificando se os dados foram importados corretamente.\n\nExemplo de sa√≠da:\n\n\n\nhead(dados_agro) \n\n  Parcela Tratamento Variedade Area Produtividade Irrigado Local\n1       1         T1         A   10          30.5     TRUE Norte\n2       2         T1         A   10          32.0     TRUE Norte\n3       3         T1         A   10          31.0     TRUE Norte\n4       4         T2         B   12          28.0    FALSE   Sul\n5       5         T2         B   12          29.5    FALSE   Sul\n6       6         T2         B   12          30.0    FALSE   Sul\n\n\n\n\nstr(dados_agro)\n\nMostra a estrutura do objeto, permitindo entender rapidamente como os dados est√£o organizados no R.\nCom essa fun√ß√£o, √© poss√≠vel:\n\nVer o n√∫mero de observa√ß√µes (linhas) e o n√∫mero de vari√°veis (colunas) do banco de dados, por exemplo, 9 obs. of 7 variables.\n\nIdentificar o tipo de cada vari√°vel, como int (inteiro), num (num√©rico cont√≠nuo), Factor (categ√≥rica), logi (l√≥gica/boolean) e chr (texto).\n\nConferir alguns valores iniciais de cada coluna, ajudando a verificar se os dados foram importados corretamente e se os tipos est√£o adequados para an√°lise.\n\nEm resumo, str() √© uma fun√ß√£o essencial para inspecionar rapidamente a estrutura e os tipos das vari√°veis, antes de realizar qualquer an√°lise estat√≠stica ou manipula√ß√£o dos dados.\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : chr  \"T1\" \"T1\" \"T1\" \"T2\" ...\n $ Variedade    : chr  \"A\" \"A\" \"A\" \"B\" ...\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nObserve que Tratamento e Variedade aparecem como character, ou seja, texto.\nPara an√°lises estat√≠sticas, √© recomendado transformar essas vari√°veis em fatores.\n\n\nsummary(dados_agro)\n\nMostra um resumo estat√≠stico das vari√°veis:\n- Para vari√°veis num√©ricas: m√≠nimo, m√°ximo, m√©dia, quartis\n- Para fatores: contagem de cada n√≠vel\n- Para l√≥gicas: contagem de TRUE e FALSE\n- √ötil para identificar tend√™ncias, valores extremos e distribui√ß√£o dos dados.\n\nsummary(dados_agro)\n\n    Parcela   Tratamento         Variedade              Area    Produtividade  \n Min.   :1   Length:9           Length:9           Min.   :10   Min.   :28.00  \n 1st Qu.:3   Class :character   Class :character   1st Qu.:10   1st Qu.:30.00  \n Median :5   Mode  :character   Mode  :character   Median :11   Median :31.00  \n Mean   :5                                         Mean   :11   Mean   :31.22  \n 3rd Qu.:7                                         3rd Qu.:12   3rd Qu.:32.50  \n Max.   :9                                         Max.   :12   Max.   :34.50  \n  Irrigado          Local          \n Mode :logical   Length:9          \n FALSE:3         Class :character  \n TRUE :6         Mode  :character  \n                                   \n                                   \n                                   \n\n\nVeja novamente que Tratamento e Variedade aparecem como character.\nE n√£o s√£o reconhecidas como fatores.\nE n√£o √© poss√≠vel perceber quais s√£o os n√≠veis de cada vari√°vel categ√≥rica.\n\nConvertendo variaveis categ√≥ricas em fatores\n\nPode-se convert√™-las em fatores usando a fun√ß√£o as.factor():\n\n\ndados_agro$Tratamento &lt;- as.factor(dados_agro$Tratamento)\ndados_agro$Variedade &lt;- as.factor(dados_agro$Variedade)\n\nAgora veja como fica a estrutura dos dados:\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : Factor w/ 3 levels \"T1\",\"T2\",\"T3\": 1 1 1 2 2 2 3 3 3\n $ Variedade    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 1 1 2 2 2 3 3 3\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nAgora sim, Tratamento e variedade aparecem como Factor com 3 n√≠veis cada.\nveja como fica o resumo estat√≠stico dos dados:\n\nsummary(dados_agro)\n\n    Parcela  Tratamento Variedade      Area    Produtividade    Irrigado      \n Min.   :1   T1:3       A:3       Min.   :10   Min.   :28.00   Mode :logical  \n 1st Qu.:3   T2:3       B:3       1st Qu.:10   1st Qu.:30.00   FALSE:3        \n Median :5   T3:3       C:3       Median :11   Median :31.00   TRUE :6        \n Mean   :5                        Mean   :11   Mean   :31.22                  \n 3rd Qu.:7                        3rd Qu.:12   3rd Qu.:32.50                  \n Max.   :9                        Max.   :12   Max.   :34.50                  \n    Local          \n Length:9          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nAgora √© poss√≠vel ver a contagem de cada n√≠vel das vari√°veis categ√≥ricas. Ou seja, s√£o 3 n√≠veis em cada vari√°vel (T1, T2, T3 para Tratamento e A, B, C para Variedade).\n\nPode-se convert√™-las em fatores usando a fun√ß√£o factor():\n\nTamb√©m d√° para criar o fator diretamente com a fun√ß√£o factor(), que √© mais flex√≠vel porque permite:\n\nDefinir os n√≠veis (levels)\nDefinir as etiquetas (labels)\n\nOu seja, permite controlar a ordem e o r√≥tulo dos n√≠veis (mais recomendado para ANOVA e modelos, pois evita ordem alfab√©tica indesejada).\n\nPode-se ainda convert√™-las em fatores usando a fun√ß√£o convert_as_factor() do pacote {rstatix}:\n\nA fun√ß√£o convert_as_factor() pode converter uma ou v√°rias colunas ao mesmo tempo.\n\n\nglimpse(dados_agro) (do pacote dplyr)\n\nMostra a estrutura dos dados de forma compacta e leg√≠vel, similar ao str(), mas em formato horizontal:\n\nExibe todas as vari√°veis, seus tipos e algumas observa√ß√µes iniciais\n\nMais f√°cil de ler quando o banco de dados tem muitas colunas\n\nExemplo de sa√≠da (resumida):\n\nglimpse(dados_agro)\n\nRows: 9\nColumns: 7\n$ Parcela       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ Tratamento    &lt;fct&gt; Controle, Controle, Controle, Adubo, Adubo, Adubo, Bioes‚Ä¶\n$ Variedade     &lt;fct&gt; IPA 11, IPA 11, IPA 11, Campo Lindo, Campo Lindo, Campo ‚Ä¶\n$ Area          &lt;dbl&gt; 10, 10, 10, 12, 12, 12, 11, 11, 11\n$ Produtividade &lt;dbl&gt; 30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5\n$ Irrigado      &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE\n$ Local         &lt;chr&gt; \"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\",‚Ä¶\n\n\n\n\n\n\n\n# Exemplo fict√≠cio\ndados &lt;- data.frame(\n  tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 4),\n  repeticao = rep(1:4, 3),\n  produtividade = c(30, 32, 28, 31, 35, 36, 34, 37, 25, 27, 26, 28)\n)\n\n# Selecionar colunas e filtrar\ndados |&gt; dplyr::select(tratamento, produtividade) |&gt; filter(produtividade &gt; 30)\n\n  tratamento produtividade\n1         T1            32\n2         T1            31\n3         T2            35\n4         T2            36\n5         T2            34\n6         T2            37\n\n# Resumo estat√≠stico\ndados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    media = mean(produtividade),\n    sd = sd(produtividade)\n  )\n\n# A tibble: 3 √ó 3\n  tratamento media    sd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 T1          30.2  1.71\n2 T2          35.5  1.29\n3 T3          26.5  1.29\n\n\n\n\n\n\n\n# Histograma\nggplot(dados, aes(x = produtividade)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n# Boxplot\nggplot(dados, aes(x = tratamento, y = produtividade)) +\n  geom_boxplot(fill = \"orange\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Primeiro transformar vari√°veis em fatores\ndados$tratamento &lt;- factor(dados$tratamento)\ndados$repeticao &lt;- factor(dados$repeticao)\n\n# ANOVA usando aov()\nmodelo &lt;- aov(produtividade ~ tratamento, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamento   2 163.50   81.75   39.24 3.59e-05 ***\nResiduals    9  18.75    2.08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd     F        p p&lt;.05   ges\n1 tratamento   2   9 39.24 3.59e-05     * 0.897\n\n# ANOVA usando ExpDes.pt\ndic(\n  trat = dados$tratamento,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM    Fc      Pr&gt;Fc\nTratamento  2 163.50 81.750 39.24 3.5934e-05\nResiduo     9  18.75  2.083                 \nTotal      11 182.25                        \n------------------------------------------------------------------------\nCV = 4.69 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.5375769 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.8663487 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\neasyanova::ea1(dados[-2], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type I SS mean square F value    p&gt;F\ntreatments  2    163.50     81.7500   39.24 &lt;0.001\nResiduals   9     18.75      2.0833       -      -\n\n$Means\n  treatment  mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2 35.50 1.2910 0.7217  34  37     a   a      a a           a\n2        T1 30.25 1.7078 0.7217  28  32     b   b      b b           b\n3        T3 26.50 1.2910 0.7217  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 T2 - T1     5.25   0.0016 0.0006    0.0006 0.0006\n2 T2 - T3     9.00   0.0000 0.0000    0.0000 0.0000\n3 T1 - T3     3.75   0.0128 0.0051    0.0051 0.0051\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                             values\np.value Shapiro-Wilk test    0.5376\np.value Bartlett test        0.8663\ncoefficient of variation (%) 4.6900\nfirst value most discrepant  3.0000\nsecond value most discrepant 2.0000\nthird value most discrepant  8.0000\n\n$`Residual analysis`$residuals\n    1     2     3     4     5     6     7     8     9    10    11    12 \n-0.25  1.75 -2.25  0.75 -0.50  0.50 -1.50  1.50 -1.50  0.50 -0.50  1.50 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n-0.1914854  1.3403980 -1.7233688  0.5744563 -0.3829708  0.3829708 -1.1489125 \n         8          9         10         11         12 \n 1.1489125 -1.1489125  0.3829708 -0.3829708  1.1489125 \n\n\nTestes de Pressupostos\nAntes da an√°lise de vari√¢ncia (ANOVA), foi realizada a verifica√ß√£o dos pressupostos de normalidade dos res√≠duos e homogeneidade das vari√¢ncias, que s√£o condi√ß√µes necess√°rias para a validade do teste F.\nNormalidade dos res√≠duos\n\nO teste de Shapiro-Wilk foi aplicado sobre os res√≠duos do modelo, verificando se a distribui√ß√£o se aproxima da normal.\nAl√©m disso, a normalidade foi testada dentro de cada grupo experimental utilizando a fun√ß√£o shapiro_test() do pacote rstatix, o que permite avaliar poss√≠veis desvios em tratamentos espec√≠ficos.\nQuando o valor de p &gt; 0,05, n√£o se rejeita a hip√≥tese nula de normalidade, indicando que os res√≠duos podem ser considerados normalmente distribu√≠dos.\n\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.94298, p-value = 0.5376\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n\nHomogeneidade das vari√¢ncias\n\nPara verificar se os tratamentos apresentam vari√¢ncias homog√™neas, foram aplicados tr√™s testes:\n\nTeste de Bartlett: sens√≠vel a desvios de normalidade, mas adequado quando os dados s√£o normais.\nTeste de Levene: mais robusto quando a normalidade n√£o √© estritamente atendida.\n\n\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nDessa forma, a an√°lise de vari√¢ncia pode ser conduzida com confian√ßa, uma vez que os pressupostos de normalidade e homogeneidade foram verificados.\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento, data = dados)\n\n$tratamento\n       diff        lwr        upr     p adj\nT2-T1  5.25   2.400421  8.0995788 0.0015767\nT3-T1 -3.75  -6.599579 -0.9004212 0.0127984\nT3-T2 -9.00 -11.849579 -6.1504212 0.0000269\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean    SE df lower.CL upper.CL .group\n T3           26.5 0.722  9     24.4     28.6  a    \n T1           30.2 0.722  9     28.1     32.4   b   \n T2           35.5 0.722  9     33.4     37.6    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nAnova\nNo DBC (delineamento em blocos casualizados) a diferen√ßa principal √© que voc√™ precisa considerar o efeito de blocos no modelo. Seguindo o mesmo estilo da sua aula de DIC, aqui est√° a vers√£o para DBC:\n\n# ANOVA usando aov()\n# Aqui usamos Error(bloco) ou bloco como efeito\nmodelo &lt;- aov(produtividade ~ tratamento + repeticao, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \ntratamento   2 163.50   81.75 127.957 1.2e-05 ***\nrepeticao    3  14.92    4.97   7.783  0.0172 *  \nResiduals    6   3.83    0.64                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento + repeticao)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd       F       p p&lt;.05   ges\n1 tratamento   2   6 127.957 1.2e-05     * 0.977\n2  repeticao   3   6   7.783 1.7e-02     * 0.796\n\n# ANOVA usando ExpDes.pt\ndbc(\n  trat = dados$tratamento,\n  bloco = dados$repeticao,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ     QM      Fc    Pr&gt;Fc\nTratamento  2 163.500 81.750 127.957 0.000012\nBloco       3  14.917  4.972   7.783 0.017195\nResiduo     6   3.833  0.639                 \nTotal      11 182.250                        \n------------------------------------------------------------------------\nCV = 2.6 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.4793843 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.1530654 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\n# design = 2 corresponde a DBC\neasyanova::ea1(dados, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type III SS mean square  F value    p&gt;F\ntreatments  2    163.5000     81.7500 127.9565 &lt;0.001\nblocks      3     14.9167      4.9722   7.7826 0.0172\nresiduals   6      3.8333      0.6389        -      -\n\n$`Adjusted means`\n  treatment adjusted.mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2         35.50 1.2910 0.3997  34  37     a   a      a a           a\n2        T1         30.25 1.7078 0.3997  28  32     b   b      b b           b\n3        T3         26.50 1.2910 0.3997  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)  p(t)\n1 T2 - T1     5.25   0.0002  1e-04     1e-04 1e-04\n2 T2 - T3     9.00   0.0000  0e+00     0e+00 0e+00\n3 T1 - T3     3.75   0.0014  6e-04     6e-04 6e-04\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                              values\np.value Shapiro-Wilk test     0.4794\np.value Bartlett test         0.8663\ncoefficient of variation (%)  2.6000\nfirst value most discrepant  11.0000\nsecond value most discrepant  3.0000\nthird value most discrepant   2.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n 0.50000000  0.83333333 -0.83333333 -0.50000000  0.25000000 -0.41666667 \n          7           8           9          10          11          12 \n-0.08333333  0.25000000 -0.75000000 -0.41666667  0.91666667  0.25000000 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n 0.8469896  1.4116493 -1.4116493 -0.8469896  0.4234948 -0.7058246 -0.1411649 \n         8          9         10         11         12 \n 0.4234948 -1.2704843 -0.7058246  1.5528142  0.4234948 \n\n\nObserva√ß√µes importantes:\n\nNo aov(), o termo + bloco garante que a varia√ß√£o entre blocos seja considerada.\nNo ExpDes.pt, usamos dbc() no lugar de dic().\nNo easyanova, o argumento design = 2 √© usado para DBC.\n\nTestes de Pressupostos\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.93854, p-value = 0.4794\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n## Teste de ONeill e Mathews\noneilldbc(trat = dados$tratamento, resp = dados$produtividade, bloco = dados$repeticao)\n\n[1] 0.1530654\n\n\nEm DBC tamb√©m foi realizado Teste de O‚ÄôNeill e Mathews, espec√≠fico para experimentos em blocos casualizados (DBC), sendo recomendado como alternativa robusta para esse delineamento.\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento + repeticao, data = dados)\n\n$tratamento\n       diff        lwr       upr     p adj\nT2-T1  5.25   3.515829  6.984171 0.0002167\nT3-T1 -3.75  -5.484171 -2.015829 0.0013765\nT3-T2 -9.00 -10.734171 -7.265829 0.0000092\n\n$repeticao\n          diff        lwr         upr     p adj\n2-1  1.6666667 -0.5925501  3.92588339 0.1472526\n3-1 -0.6666667 -2.9258834  1.59255006 0.7441939\n4-1  2.0000000 -0.2592167  4.25921672 0.0796674\n3-2 -2.3333333 -4.5925501 -0.07411661 0.0438895\n4-2  0.3333333 -1.9258834  2.59255006 0.9535148\n4-3  2.6666667  0.4074499  4.92588339 0.0248704\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean  SE df lower.CL upper.CL .group\n T3           26.5 0.4  6     25.2     27.8  a    \n T1           30.2 0.4  6     28.9     31.6   b   \n T2           35.5 0.4  6     34.2     36.8    c  \n\nResults are averaged over the levels of: repeticao \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\n# Exemplo com dois fatores\ndados2 &lt;- expand.grid(\n  adubacao = c(\"A1\", \"A2\"),\n  cultivar = c(\"C1\", \"C2\", \"C3\"),\n  rep = 1:4\n)\n\nset.seed(123)\n\ndados2$produtividade &lt;- rnorm(24, mean = 30, sd = 3)\ndados2$adubacao &lt;- factor(dados2$adubacao)\ndados2$cultivar &lt;- factor(dados2$cultivar)\ndados2$rep &lt;- factor(dados2$rep)\n\n# ANOVA usando aov()\nmodelo2 &lt;- aov(produtividade ~ adubacao * cultivar, data = dados2)\nsummary(modelo2)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nadubacao           1   2.09   2.089   0.217  0.647\ncultivar           2   1.07   0.536   0.056  0.946\nadubacao:cultivar  2  13.72   6.861   0.712  0.504\nResiduals         18 173.43   9.635               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1          adubacao   1  18 0.217 0.647       0.012\n2          cultivar   2  18 0.056 0.946       0.006\n3 adubacao:cultivar   2  18 0.712 0.504       0.073\n\n# ExpDes.pt\nfat2.dic(\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nF1       1   2.089  3 0.21680 0.64708\nF2       2   1.073  2 0.05566 0.94602\nF1*F2    2  13.723  4 0.71212 0.50391\nResiduo 18 173.435  5                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.36 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6606527 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\neasyanova::ea2(dados2[-3], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2168 0.6471\nfactor_2           2      1.0726      0.5363  0.0557  0.946\nfactor_1:factor_2  2     13.7229      6.8614  0.7121 0.5039\nresiduals         18    173.4346      9.6353       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.8961     a   a      a a           a\n2       A2        29.679 3.2191 0.8961     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6471 0.6471    0.6471 0.6471\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.0975     a   a      a a           a\n2       C3       30.0767 3.6356 1.0975     a   a      a a           a\n3       C1       29.6795 1.9564 1.0975     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9982 0.9549    0.9549 0.9549\n2 C2 - C1   0.4862   0.9475 0.9475    0.7709 0.7577\n3 C3 - C1   0.3972   0.9646 0.8009    0.8009 0.8009\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3414 0.3414    0.3414 0.3414\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5146 0.5146    0.5146 0.5146\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6272 0.6272    0.6272 0.6272\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9980 0.9523    0.9523 0.9523\n2 A1.C1 - A1.C2   1.3158   0.8221 0.8221    0.5783 0.5563\n3 A1.C3 - A1.C2   1.1828   0.8533 0.5966    0.5966 0.5966\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8112 0.5430    0.5430 0.5430\n2 A2.C2 - A2.C1   2.2883   0.5605 0.5605    0.3371 0.3109\n3 A2.C3 - A2.C1   0.9275   0.9068 0.6776    0.6776 0.6776\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6607\np.value Bartlett test (factor_1)    0.5289\np.value Bartlett test (factor_2)    0.1309\np.value Bartlett test (treatments)  0.5464\ncoefficient of variation (%)       10.3600\nfirst value most discrepant         6.0000\nsecond value most discrepant       18.0000\nthird value most discrepant         3.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n-2.43335287  0.70247809  5.23998198 -0.68381331 -0.23104847  5.61066714 \n          7           8           9          10          11          12 \n 0.63082268 -2.40217314 -1.49670152 -2.23232439  3.05333372  1.54491366 \n         13          14          15          16          17          18 \n 0.45038842  1.72505871 -1.10366637  4.46540093  0.87463976 -5.43437929 \n         19          20          21          22          23          24 \n 1.35214177 -0.02536366 -2.63961408 -1.54926323 -3.69692502 -1.72120151 \n\n$`Residual analysis`$`standardized residuals`\n           1            2            3            4            5            6 \n-0.886137644  0.255816692  1.908208766 -0.249019664 -0.084139356  2.043198673 \n           7            8            9           10           11           12 \n 0.229722427 -0.874783133 -0.545043662 -0.812930463  1.111911873  0.562600750 \n          13           14           15           16           17           18 \n 0.164014901  0.628202953 -0.401914711  1.626134829  0.318511642 -1.979001121 \n          19           20           21           22           23           24 \n 0.492400316 -0.009236513 -0.961250393 -0.564184702 -1.346284159 -0.626798303 \n\n\n\n\n\n\n\n# ANOVA usando aov()\n# Aqui, bloco √© adicionado como efeito de erro\nmodelo_dbc &lt;- aov(produtividade ~ rep + adubacao * cultivar, data = dados2)\nsummary(modelo_dbc)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nrep                3  22.94   7.647   0.762  0.533\nadubacao           1   2.09   2.089   0.208  0.655\ncultivar           2   1.07   0.536   0.053  0.948\nadubacao:cultivar  2  13.72   6.861   0.684  0.520\nResiduals         15 150.49  10.033               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ rep + adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1               rep   3  15 0.762 0.533       0.132\n2          adubacao   1  15 0.208 0.655       0.014\n3          cultivar   2  15 0.053 0.948       0.007\n4 adubacao:cultivar   2  15 0.684 0.520       0.084\n\n# ExpDes.pt\n# fat2.dbc √© a fun√ß√£o para fatorial em blocos no pacote ExpDes.pt\nfat2.dbc(\n  bloco = dados2$rep,\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nBloco    3  22.942  6 0.76223 0.53264\nF1       1   2.089  4 0.20821 0.65471\nF2       2   1.073  2 0.05345 0.94813\nF1*F2    2  13.723  5 0.68390 0.51971\nResiduo 15 150.493  3                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.57 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6960048 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\n# Em DBC, design = 2 (fatorial em blocos)\neasyanova::ea2(dados2, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2082 0.6547\nfactor_2           2      1.0726      0.5363  0.0535 0.9481\nblocks             3     22.9420      7.6473  0.7622 0.5326\nfactor_1:factor_2  2     13.7229      6.8614  0.6839 0.5197\nresiduals         15    150.4926     10.0328       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.9144     a   a      a a           a\n2       A2        29.679 3.2191 0.9144     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6547 0.6547    0.6547 0.6547\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.1199     a   a      a a           a\n2       C3       30.0767 3.6356 1.1199     a   a      a a           a\n3       C1       29.6795 1.9564 1.1199     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9983 0.9559    0.9559 0.9559\n2 C2 - C1   0.4862   0.9495 0.9495    0.7754 0.7631\n3 C3 - C1   0.3972   0.9660 0.8054    0.8054 0.8054\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3534 0.3534    0.3534 0.3534\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5246 0.5246    0.5246 0.5246\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6353 0.6353    0.6353 0.6353\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9981 0.9534    0.9534 0.9534\n2 A1.C1 - A1.C2   1.3158   0.8288 0.8288    0.5862 0.5656\n3 A1.C3 - A1.C2   1.1828   0.8589 0.6051    0.6051 0.6051\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8182 0.5526    0.5526 0.5526\n2 A2.C2 - A2.C1   2.2883   0.5751 0.5751    0.3481 0.3231\n3 A2.C3 - A2.C1   0.9275   0.9104 0.6846    0.6846 0.6846\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6960\np.value Bartlett test (factor_1)    0.5441\np.value Bartlett test (factor_2)    0.6041\np.value Bartlett test (treatments)  0.8490\ncoefficient of variation (%)       10.5700\nfirst value most discrepant        18.0000\nsecond value most discrepant       16.0000\nthird value most discrepant         6.0000\n\n$`Residual analysis`$residuals\n         1          2          3          4          5          6          7 \n-3.8008383 -0.6650073  3.8724965 -2.0512987 -1.5985339  4.2431817  0.7811775 \n         8          9         10         11         12         13         14 \n-2.2518183 -1.3463467 -2.0819696  3.2036886  1.6952685  0.2874814  1.5621517 \n        15         16         17         18         19         20         21 \n-1.2665734  4.3024939  0.7117327 -5.5972863  2.7321794  1.3546740 -1.2595765 \n        22         23         24 \n-0.1692256 -2.3168874 -0.3411639 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n-1.48588700 -0.25997574  1.51390084 -0.80192786 -0.62492549  1.65881525 \n          7           8           9          10          11          12 \n 0.30539092 -0.88031831 -0.52633627 -0.81391821  1.25243928  0.66274259 \n         13          14          15          16          17          18 \n 0.11238701  0.61070235 -0.49514996  1.68200256  0.27824241 -2.18818437 \n         19          20          21          22          23          24 \n 1.06810906  0.52959170 -0.49241461 -0.06615649 -0.90575620 -0.13337347 \n\n\n\n\n\n\n\n\n\n\ndose &lt;- c(0, 50, 100, 150, 200)\nprod &lt;- c(20, 28, 35, 40, 38)\ndados_reg &lt;- data.frame(dose, prod)\n\nmodelo_reg &lt;- lm(prod ~ dose, data = dados_reg)\na &lt;- summary(modelo_reg)\n\n# Coeficientes\ncoeficientes &lt;- coef(modelo_reg)\nintercepto &lt;- round(coeficientes[1], 2) # sem sinal extra\nslope &lt;- formatC(coeficientes[2], format = \"f\", digits = 2, flag = \"+\") # sempre com sinal\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n\n\n\n# Equa√ß√£o no formato correto\nequacao &lt;- paste0(\"y = \", intercepto, slope, \"x\")\n\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", f_value,\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n\n\ndados_reg |&gt;\n  ggplot(aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  annotate(\"text\",\n           x = 100, y = 10,\n           label = legenda,\n           hjust = 0, size = 5) +\n  labs(x = \"Frequ√™ncia de irriga√ß√£o\", y = \"CRA (%)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ajustar modelo de regress√£o quadr√°tica\nmodelo_quad &lt;- lm(prod ~ dose + I(dose^2), data = dados_reg)\na &lt;- summary(modelo_quad)\na\n\n\nCall:\nlm(formula = prod ~ dose + I(dose^2), data = dados_reg)\n\nResiduals:\n      1       2       3       4       5 \n 0.5429 -0.9714 -0.3429  1.4286 -0.6571 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 19.4571429  1.3021176  14.943  0.00445 **\ndose         0.2217143  0.0308492   7.187  0.01882 * \nI(dose^2)   -0.0006286  0.0001479  -4.250  0.05116 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.384 on 2 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9715 \nF-statistic: 69.21 on 2 and 2 DF,  p-value: 0.01424\n\n# Coeficientes da regress√£o quadr√°tica (com mais casas decimais)\ncoef_quad &lt;- coef(modelo_quad)\nintercepto &lt;- formatC(coef_quad[1], format = \"f\", digits = 4)\nlinear     &lt;- formatC(coef_quad[2], format = \"f\", digits = 4, flag = \"+\")\nquadratico &lt;- formatC(coef_quad[3], format = \"f\", digits = 4, flag = \"+\") \n# usei 6 casas para o termo quadr√°tico porque geralmente √© bem pequeno\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n# Equa√ß√£o para legenda\nequacao &lt;- paste0(\"y = \", intercepto, \" \", linear, \"x \", quadratico, \"x¬≤\")\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", round(f_value, 2),\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n# Gr√°fico\nlibrary(ggplot2)\n\nregressao_quad &lt;- ggplot(dados_reg, aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  stat_smooth(\n    method = \"lm\",\n    formula = y ~ x + I(x^2),\n    se = FALSE,\n    color = \"black\"\n  ) +\n  annotate(\"text\", x = 50, y = 10, label = legenda, hjust = 0, size = 5) +\n  labs(x = \"Dose\", y = \"Produ√ß√£o\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n# Exibir gr√°fico\nregressao_quad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste pr√≥prio arquivo √© um exemplo.\n\nPode ser exportado em HTML, Word ou PDF.\n\n\n\n\n\n\nAnalise um conjunto de dados agr√≠colas (real ou fornecido):\n- Estruture os dados no Excel/CSV.\n- Importe para o R.\n- Realize ANOVA (com aov(), ExpDes.pt, easyanova e rstatix).\n- Teste pressupostos.\n- Se necess√°rio, ajuste modelos de regress√£o.\n- Gere gr√°ficos com ggplot2.\n- Organize os resultados em relat√≥rio RMarkdown."
  },
  {
    "objectID": "cursoder/index.html#m√≥dulo-1-introdu√ß√£o-ao-r-e-organiza√ß√£o-de-dados",
    "href": "cursoder/index.html#m√≥dulo-1-introdu√ß√£o-ao-r-e-organiza√ß√£o-de-dados",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Instale o R e o RStudio em seu computador.\n\n\nO R √© o programa principal, ou seja, a linguagem de programa√ß√£o e o ambiente de c√°lculo.\n√â nele que todos os comandos s√£o processados e as an√°lises estat√≠sticas s√£o realizadas.\nPor isso, o primeiro passo √© instalar o R no computador.\nO download deve ser feito diretamente no site oficial do CRAN (Comprehensive R Archive Network):\n https://cran.r-project.org/\nAo abrir o link, basta escolher o sistema operacional do seu computador (Windows, macOS ou Linux) e seguir as instru√ß√µes de instala√ß√£o.\nCom isso, voc√™ j√° ter√° o R funcionando, embora a sua interface seja bastante simples e pouco intuitiva para quem est√° come√ßando.\n√â justamente nesse ponto que entra o RStudio.\nO RStudio n√£o √© um programa separado do R, mas sim uma IDE (Integrated Development Environment), ou seja, um ambiente de desenvolvimento que facilita o uso do R.\nEle oferece uma interface gr√°fica amig√°vel, onde voc√™ pode escrever c√≥digos, visualizar gr√°ficos, organizar projetos e instalar pacotes com muito mais facilidade.\nNo entanto, √© fundamental compreender que o RStudio n√£o funciona sozinho.\nEle depende do R j√° instalado na m√°quina, pois √© o R quem executa de fato os c√°lculos.\nPor isso, a ordem correta √©: primeiro instalar o R e, em seguida, instalar o RStudio.\nO download do RStudio pode ser feito no site oficial da Posit (empresa respons√°vel pelo software):\nüëâ https://posit.co/download/rstudio-desktop/\nAo instalar os dois programas, voc√™ ter√° o R como motor de c√°lculo e o RStudio como painel de controle, trabalhando em conjunto.\nEssa combina√ß√£o √© a mais utilizada no mundo acad√™mico e profissional para an√°lises estat√≠sticas e ci√™ncia de dados.\n\nConhe√ßa os principais pain√©is do RStudio:\n\nConsole (execu√ß√£o de comandos)\n\nSource (script)\n\nEnvironment/History (objetos)\n\nPlots/Packages/Help\n\n\nVerificando vers√£o do R\n\n# Verificando vers√£o do R\nversion\n\n               _                                \nplatform       x86_64-w64-mingw32               \narch           x86_64                           \nos             mingw32                          \ncrt            ucrt                             \nsystem         x86_64, mingw32                  \nstatus                                          \nmajor          4                                \nminor          4.2                              \nyear           2024                             \nmonth          10                               \nday            31                               \nsvn rev        87279                            \nlanguage       R                                \nversion.string R version 4.4.2 (2024-10-31 ucrt)\nnickname       Pile of Leaves                   \n\n\nCitando o R\n\n# Cita√ß√£o do R\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nUma entrada BibTeX para usu√°rios(as) de LaTeX √©\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nOpera√ß√µes simples\n\n# Opera√ß√µes simples\n\n## Soma\n2 + 2\n\n[1] 4\n\n## Subtra√ß√£o\n7 - 2\n\n[1] 5\n\n## Mutiplica√ß√£o\n4 * 3\n\n[1] 12\n\n## Divis√£o\n10 / 3\n\n[1] 3.333333\n\n## Raiz quadrada\nsqrt(25)\n\n[1] 5\n\n\n\n\n\n\nNesta aula, aprendemos a criar e manipular objetos no R. Objetos s√£o vari√°veis que armazenam valores ou resultados de c√°lculos, permitindo que possamos reutiliz√°-los em outras opera√ß√µes.\nNo exemplo apresentado, criamos dois objetos num√©ricos:\n\n# Criando objetos\nx &lt;- 5\ny &lt;- 10\n\nAqui, x recebe o valor 5 e y recebe o valor 10. Em seguida, criamos um terceiro objeto chamado soma, que armazena a soma de x e y:\n\nsoma &lt;- x + y\nsoma\n\n[1] 15\n\n\nAo digitar apenas soma, o R retorna o valor armazenado neste objeto, que neste caso √© 15.\nEste exemplo ilustra a forma b√°sica de criar objetos no R e realizar opera√ß√µes simples com eles, fundamental para qualquer an√°lise de dados ou programa√ß√£o no software.\n\n\n\n\nNo R, os pacotes s√£o conjuntos de fun√ß√µes, dados e recursos que estendem as capacidades b√°sicas do software, permitindo realizar an√°lises mais complexas de forma pr√°tica e eficiente.\nNo exemplo abaixo, veja como instalar alguns pacotes importantes um de cada vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"dplyr\")   # Para manipula√ß√£o e visualiza√ß√£o de dados\ninstall.packages(\"readxl\")      # Para ler arquivos do Excel\ninstall.packages(\"ExpDes.pt\")   # Para planejamento e an√°lise de experimentos agr√≠colas\ninstall.packages(\"easyanova\")   # Para facilitar an√°lises de vari√¢ncia\ninstall.packages(\"rstatix\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"emmeans\")     # Para estat√≠sticas descritivas e testes inferenciais\ninstall.packages(\"janitor\")     # Para limpeza e organiza√ß√£o de dados\ninstall.packages(\"kableExtra\")  # Para tabelas formatadas\n\nOuse preferir pode instalar v√°rios de uma √∫nica vez:\n\n# Carregando pacotes\ninstall.packages(\"tidyverse\", \"readxl\", \"ExpDes.pt\", \"easyanova\", \"rstatix\", \"emmeans\", \"janitor\", \"kableExtra\")\n\nNo exemplo abaixo, carregamos alguns pacotes importantes:\n\n# Carregando pacotes\n\n# ---------------------------\n# Pacotes para manipula√ß√£o e leitura de dados\n# ---------------------------\nlibrary(tidyverse)   # Inclui dplyr, ggplot2, readr, tidyr, etc.\nlibrary(dplyr)       # Manipula√ß√£o de dados\nlibrary(readxl)      # Para importar planilhas Excel\n\n# ---------------------------\n# Pacotes para an√°lise de experimentos\n# ---------------------------\nlibrary(ExpDes.pt)   # ANOVA para DIC, DBC, parcelas subdivididas etc.\nlibrary(easyanova)   # ANOVA e testes complementares de forma simplificada\n\n# ---------------------------\n# Pacotes para estat√≠stica e p√≥s-testes\n# ---------------------------\nlibrary(rstatix)     # Testes estat√≠sticos (normalidade, homogeneidade, etc.)\nlibrary(emmeans)     # M√©dias ajustadas e compara√ß√µes m√∫ltiplas\n\n# ---------------------------\n# Pacotes para organiza√ß√£o e visualiza√ß√£o de dados\n# ---------------------------\nlibrary(janitor)     # Limpeza e organiza√ß√£o de dados\nlibrary(kableExtra)  # Tabelas formatadas\n\n\n\n\n\nUm dos passos mais importantes em qualquer an√°lise √© a organiza√ß√£o adequada dos dados. Dados desorganizados ou com nomes de vari√°veis inconsistentes podem dificultar o trabalho, aumentar a chance de erros e at√© inviabilizar o uso de fun√ß√µes em softwares estat√≠sticos como o R.\nVeja esse esse exmeplo de banco de dados (dados_ruins_dic) no Excel:\n\n\n\n\n\nRepeti√ß√£o\nTratamento\nAltura da planta (cm)\nMat√©ria seca (g)\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nImport√¢ncia de bons t√≠tulos nas vari√°veis\nNo R, os nomes das colunas (ou t√≠tulos das vari√°veis) devem seguir algumas boas pr√°ticas para facilitar a an√°lise:\n\nPadr√£o snake_case: usar letras min√∫sculas e sublinhados para separar palavras, como altura_planta_g.\nEvitar espa√ßos: em vez de Altura da Planta, utilizar Altura_Planta.\n\nUsar unidades no nome da vari√°vel: em vez de Altura da Planta (cm), utilizar Altura_Planta_cm.\n\nUsar letras min√∫sculas (ou padr√£o definido): altura_planta_cm.\n\nEvitar acentos e caracteres especiais: em vez de Mat√©ria seca (g), utilizar materia_seca_g.\n\nSer descritivo, mas n√£o excessivamente longo: peso_frutos em vez de pf_colheita_experimental_2024.\n\nEsses cuidados tornam o banco de dados mais limpo, reprodut√≠vel e compat√≠vel com fun√ß√µes e pacotes do R.\nComo organizar os t√≠tulos\n\nPode fazer manulamente no Excel\n\nAntes de importar o arquivo para o R, pode-se renomear diretamente no Excel.\n\nExemplo: renomear a coluna de Massa seca total (g) para massa_seca_total_g.\n\nManualmente no R usando o pacote dplyr\n\nA fun√ß√£o rename() do pacote dplyr permite renomear manualmente colunas espec√≠ficas.\n\n# Renomear colunas espec√≠ficas\nlibrary(dplyr)\ndados_organizados_dplyr &lt;- dados_ruins_dic |&gt;\n  rename(\n    repeticao = `Repeti√ß√£o`,\n    tratamento = Tratamento,\n    altura_planta_cm = `Altura da planta (cm)`,\n    materia_seca_g = `Mat√©ria seca (g)`\n  )\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_dplyr)\n\n[1] \"repeticao\"        \"tratamento\"       \"altura_planta_cm\" \"materia_seca_g\"  \n\n\n\nAutom√°tico usando o pacote janitor\nExistem pacotes que auxiliam na padroniza√ß√£o dos nomes de maneira autom√°tica:\n\nPacote janitor: a fun√ß√£o clean_names() desse pacote converte automaticamente os t√≠tulos para um formato padr√£o (snake_case).\n\n\nVeja o que acontece com esse banco de dados (dados_ruins_dic):\n\n# Corrigir nomes das colunas -&gt; formato \"snake_case\"\ndados_organizados_janitor &lt;- dados_ruins_dic |&gt; \n  janitor::clean_names()\n\n\n\n\n\n\nrepeticao\ntratamento\naltura_da_planta_cm\nmateria_seca_g\n\n\n\n\nT1 - Testemunha\n1\n160\n280\n\n\nT1 - Testemunha\n2\n165\n300\n\n\nT1 - Testemunha\n3\n158\n290\n\n\nT1 - Testemunha\n4\n162\n295\n\n\nT1 - Testemunha\n5\n161\n285\n\n\nT2 - 50kg N\n1\n180\n360\n\n\nT2 - 50kg N\n2\n185\n370\n\n\nT2 - 50kg N\n3\n178\n365\n\n\nT2 - 50kg N\n4\n182\n368\n\n\nT2 - 50kg N\n5\n184\n362\n\n\nT3 - 100kg N\n1\n200\n450\n\n\nT3 - 100kg N\n2\n205\n460\n\n\nT3 - 100kg N\n3\n198\n455\n\n\nT3 - 100kg N\n4\n202\n465\n\n\nT3 - 100kg N\n5\n201\n458\n\n\nT4 - 150kg N\n1\n220\n550\n\n\nT4 - 150kg N\n2\n225\n560\n\n\nT4 - 150kg N\n3\n218\n545\n\n\nT4 - 150kg N\n4\n222\n555\n\n\nT4 - 150kg N\n5\n221\n548\n\n\n\n\n\nNomes antes:\n\n# Ver como eram\nnames(dados_ruins_dic)\n\n[1] \"Repeti√ß√£o\"             \"Tratamento\"            \"Altura da planta (cm)\"\n[4] \"Mat√©ria seca (g)\"     \n\n\nNomes depois:\n\n# Ver como ficaram\nnames(dados_organizados_janitor)\n\n[1] \"repeticao\"           \"tratamento\"          \"altura_da_planta_cm\"\n[4] \"materia_seca_g\"     \n\n\n\n\n\n\nImportando dados\nImportar dados para o R √© um passo fundamental para qualquer an√°lise. No R, √© poss√≠vel importar dados de diferentes formatos, o que √© essencial para iniciar qualquer an√°lise. O R permite ler diferentes formatos de arquivos, como CSV e Excel.\n\n# Importando CSV\n# dados_csv &lt;- read.csv(\"meus_dados.csv\", sep = \";\", dec = \",\")\n# L√™ arquivos CSV, permitindo especificar o separador de colunas (sep) e o separador decimal (dec)\n\n# Importando Excel\n# dados_excel &lt;- readxl::read_excel(\"meus_dados.xlsx\")\n# L√™ planilhas do Excel diretamente para o R\n\n# Importando arquivo de texto (TXT)\n# dados_txt &lt;- read.table(\"meus_dados.txt\", header = TRUE, sep = \"\\t\", dec = \".\")\n# L√™ arquivos de texto, onde 'header = TRUE' indica que a primeira linha cont√©m os nomes das colunas,\n# 'sep = \"\\t\"' indica que as colunas s√£o separadas por tabula√ß√£o, e 'dec = \".\"' define o separador decimal\n\n\nread.csv() l√™ arquivos no formato CSV (Comma-Separated Values), permitindo especificar o separador de colunas (sep) e o separador decimal (dec). √â indicado para planilhas exportadas como CSV ou dados gerados por outros programas.\nread_excel() (do pacote readxl) l√™ arquivos do Excel (.xls ou .xlsx) diretamente, mantendo nomes das colunas e tipos de dados corretamente, o que facilita a importa√ß√£o de planilhas complexas sem precisar convert√™-las.\nread.table() l√™ arquivos de texto simples (TXT ou outros delimitados), oferecendo flexibilidade para especificar se h√° cabe√ßalho (header = TRUE), o separador de colunas (sep) e o separador decimal (dec). √â ideal para arquivos de texto com diferentes formatos de separa√ß√£o.\n\nVisualizando os dados\nAp√≥s a importa√ß√£o, podemos visualizar os dados para verificar se foram carregados corretamente: Ap√≥s a importa√ß√£o, √© importante visualizar os dados para conferir se foram carregados corretamente. Para isso, podem ser usadas fun√ß√µes como:\n\nhead() (exibe as primeiras linhas),\nsummary() (mostra resumo estat√≠stico das vari√°veis),\nstr() (mostra a estrutura do objeto) e\nglimpse() (exibe de forma compacta e leg√≠vel a estrutura e os tipos das vari√°veis).\n\n\n# head(dados_csv)    # Mostra as primeiras linhas do conjunto de dados\n# summary(dados_csv) # Mostra um resumo estat√≠stico das vari√°veis\n# str(dados_csv)     # Mostra a estrutura do objeto, incluindo tipos de vari√°veis e dimens√µes\n# glimpse(dados_csv)  # Mostra todas as vari√°veis, seus tipos e algumas observa√ß√µes de cada coluna"
  },
  {
    "objectID": "cursoder/index.html#m√≥dulo-2-manipula√ß√£o-e-explora√ß√£o-de-dados",
    "href": "cursoder/index.html#m√≥dulo-2-manipula√ß√£o-e-explora√ß√£o-de-dados",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Vari√°veis num√©ricas\n\nCont√≠nuas (numeric / dbl): podem assumir qualquer valor dentro de um intervalo, incluindo decimais.\nExemplo: Produtividade (t/ha), √Årea (m¬≤)\nDiscretas (integer / int): assumem apenas valores inteiros.\nExemplo: Parcela (identificador das parcelas)\n\nVari√°veis categ√≥ricas (fatores) (factor / fct)\n\nRepresentam categorias ou grupos que o R reconhece para an√°lises estat√≠sticas.\nExemplo: Tratamento, Variedade\n\nIdeais para an√°lise de vari√¢ncia e compara√ß√µes entre grupos\n\nVari√°veis de texto (character / chr)\n\nCont√™m informa√ß√µes textuais ou descritivas, que n√£o t√™m ordem ou significado num√©rico.\nExemplo: Local (Norte, Sul, Leste)\n\nN√£o s√£o usadas diretamente em c√°lculos estat√≠sticos, mas servem para identificar ou agrupar dados\n\nVari√°veis l√≥gicas (logical / logi)\n\nAssumem apenas dois valores: TRUE ou FALSE\nExemplo: Irrigado\n\n√öteis para condi√ß√µes, filtros e an√°lises condicionais\n\nOutros tipos dispon√≠veis em R\n\nComplexo (complex / sem abrevia√ß√£o comum): n√∫meros complexos, como 1+2i\nRaw (raw / sem abrevia√ß√£o comum): representa dados brutos em bytes\n\nDate (Date / sem abrevia√ß√£o comum): datas no formato \"YYYY-MM-DD\"\n\nPOSIXct / POSIXlt (POSIXct / POSIXlt): datas e horas com tempo\nOrdered factor (ordered / ord): fatores com ordem natural definida\n\n\n\nNeste exemplo, iremos criar vari√°veis de diferentes tipos em R ‚Äî num√©ricas cont√≠nuas, num√©ricas discretas e categ√≥ricas (fatores) ‚Äî e, em seguida, identificar o tipo de cada vari√°vel usando a fun√ß√£o class().\nIsso nos permite compreender como o R armazena cada tipo de dado e como ele ser√° tratado em an√°lises estat√≠sticas.\n\n# Num√©rica cont√≠nua\nnum_cont &lt;- 3.5      # numeric / dbl\nclass(num_cont) # Checando classes\n\n[1] \"numeric\"\n\n# Num√©rica discreta\nnum_disc &lt;- 5L       # integer / int\nclass(num_disc)\n\n[1] \"integer\"\n\n# Fator (categ√≥rica)\ntrat &lt;- factor(c(\"T1\", \"T2\", \"T3\"))  # factor / fct\nclass(trat)\n\n[1] \"factor\"\n\n# Ordered factor\nord_trat &lt;- factor(c(\"Baixo\", \"M√©dio\", \"Alto\"), ordered = TRUE) # ordered / ord\nclass(ord_trat)\n\n[1] \"ordered\" \"factor\" \n\n# Character\nlocal &lt;- c(\"Norte\", \"Sul\")  # character / chr\nclass(local)\n\n[1] \"character\"\n\n# L√≥gica\nirr &lt;- c(TRUE, FALSE)       # logical / logi\nclass(irr)\n\n[1] \"logical\"\n\n# Complexo\ncplx &lt;- 1 + 2i              # complex\nclass(cplx)\n\n[1] \"complex\"\n\n# Raw\nr &lt;- charToRaw(\"A\")         # raw\nclass(r)\n\n[1] \"raw\"\n\n# Datas\nd &lt;- as.Date(\"2025-08-29\")  # Date\nclass(d)\n\n[1] \"Date\"\n\ndt &lt;- as.POSIXct(\"2025-08-29 12:00:00\") # POSIXct\nclass(dt)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\nCriando banco de dados fict√≠cio\nNeste exemplo, iremos criar um banco de dados fict√≠cio de um experimento agr√≠cola com diferentes tipos de vari√°veis: num√©ricas (cont√≠nuas e discretas), categ√≥ricas, l√≥gicas e de texto.\nEm seguida, iremos visualizar o banco de dados e identificar os tipos de vari√°veis, para entender como o R armazena cada tipo e como podemos manipul√°-las em an√°lises estat√≠sticas.\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = factor(rep(c(\"T1\", \"T2\", \"T3\"), each = 3)), # Fator (categ√≥rica nominal)\n  Variedade = factor(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\")), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\n# Exemplo de banco de dados de experimento agr√≠cola\ndados_agro &lt;- data.frame(\n  Parcela = 1:9,                               # Num√©rica discreta (identifica√ß√£o das parcelas)\n  Tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 3), # Fator (categ√≥rica nominal)\n  Variedade = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"), # Fator (categ√≥rica nominal)\n  Area = c(10, 10, 10, 12, 12, 12, 11, 11, 11),  # Num√©rica cont√≠nua (m¬≤)\n  Produtividade = c(30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5), # Num√©rica cont√≠nua (t/ha)\n  Irrigado = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),   # L√≥gica\n  Local = c(\"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\", \"Leste\", \"Leste\") # Texto (character)\n)\n\n\nFun√ß√µes para Visualiza√ß√£o e Estrutura de Dados no R\n\nhead(dados_agro)\nMostra as primeiras linhas do conjunto de dados.\n\n√ötil para ter uma vis√£o r√°pida do conte√∫do do banco, verificando se os dados foram importados corretamente.\n\nExemplo de sa√≠da:\n\n\n\nhead(dados_agro) \n\n  Parcela Tratamento Variedade Area Produtividade Irrigado Local\n1       1         T1         A   10          30.5     TRUE Norte\n2       2         T1         A   10          32.0     TRUE Norte\n3       3         T1         A   10          31.0     TRUE Norte\n4       4         T2         B   12          28.0    FALSE   Sul\n5       5         T2         B   12          29.5    FALSE   Sul\n6       6         T2         B   12          30.0    FALSE   Sul\n\n\n\n\nstr(dados_agro)\n\nMostra a estrutura do objeto, permitindo entender rapidamente como os dados est√£o organizados no R.\nCom essa fun√ß√£o, √© poss√≠vel:\n\nVer o n√∫mero de observa√ß√µes (linhas) e o n√∫mero de vari√°veis (colunas) do banco de dados, por exemplo, 9 obs. of 7 variables.\n\nIdentificar o tipo de cada vari√°vel, como int (inteiro), num (num√©rico cont√≠nuo), Factor (categ√≥rica), logi (l√≥gica/boolean) e chr (texto).\n\nConferir alguns valores iniciais de cada coluna, ajudando a verificar se os dados foram importados corretamente e se os tipos est√£o adequados para an√°lise.\n\nEm resumo, str() √© uma fun√ß√£o essencial para inspecionar rapidamente a estrutura e os tipos das vari√°veis, antes de realizar qualquer an√°lise estat√≠stica ou manipula√ß√£o dos dados.\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : chr  \"T1\" \"T1\" \"T1\" \"T2\" ...\n $ Variedade    : chr  \"A\" \"A\" \"A\" \"B\" ...\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nObserve que Tratamento e Variedade aparecem como character, ou seja, texto.\nPara an√°lises estat√≠sticas, √© recomendado transformar essas vari√°veis em fatores.\n\n\nsummary(dados_agro)\n\nMostra um resumo estat√≠stico das vari√°veis:\n- Para vari√°veis num√©ricas: m√≠nimo, m√°ximo, m√©dia, quartis\n- Para fatores: contagem de cada n√≠vel\n- Para l√≥gicas: contagem de TRUE e FALSE\n- √ötil para identificar tend√™ncias, valores extremos e distribui√ß√£o dos dados.\n\nsummary(dados_agro)\n\n    Parcela   Tratamento         Variedade              Area    Produtividade  \n Min.   :1   Length:9           Length:9           Min.   :10   Min.   :28.00  \n 1st Qu.:3   Class :character   Class :character   1st Qu.:10   1st Qu.:30.00  \n Median :5   Mode  :character   Mode  :character   Median :11   Median :31.00  \n Mean   :5                                         Mean   :11   Mean   :31.22  \n 3rd Qu.:7                                         3rd Qu.:12   3rd Qu.:32.50  \n Max.   :9                                         Max.   :12   Max.   :34.50  \n  Irrigado          Local          \n Mode :logical   Length:9          \n FALSE:3         Class :character  \n TRUE :6         Mode  :character  \n                                   \n                                   \n                                   \n\n\nVeja novamente que Tratamento e Variedade aparecem como character.\nE n√£o s√£o reconhecidas como fatores.\nE n√£o √© poss√≠vel perceber quais s√£o os n√≠veis de cada vari√°vel categ√≥rica.\n\nConvertendo variaveis categ√≥ricas em fatores\n\nPode-se convert√™-las em fatores usando a fun√ß√£o as.factor():\n\n\ndados_agro$Tratamento &lt;- as.factor(dados_agro$Tratamento)\ndados_agro$Variedade &lt;- as.factor(dados_agro$Variedade)\n\nAgora veja como fica a estrutura dos dados:\n\nstr(dados_agro)\n\n'data.frame':   9 obs. of  7 variables:\n $ Parcela      : int  1 2 3 4 5 6 7 8 9\n $ Tratamento   : Factor w/ 3 levels \"T1\",\"T2\",\"T3\": 1 1 1 2 2 2 3 3 3\n $ Variedade    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 1 1 2 2 2 3 3 3\n $ Area         : num  10 10 10 12 12 12 11 11 11\n $ Produtividade: num  30.5 32 31 28 29.5 30 33 34.5 32.5\n $ Irrigado     : logi  TRUE TRUE TRUE FALSE FALSE FALSE ...\n $ Local        : chr  \"Norte\" \"Norte\" \"Norte\" \"Sul\" ...\n\n\nAgora sim, Tratamento e variedade aparecem como Factor com 3 n√≠veis cada.\nveja como fica o resumo estat√≠stico dos dados:\n\nsummary(dados_agro)\n\n    Parcela  Tratamento Variedade      Area    Produtividade    Irrigado      \n Min.   :1   T1:3       A:3       Min.   :10   Min.   :28.00   Mode :logical  \n 1st Qu.:3   T2:3       B:3       1st Qu.:10   1st Qu.:30.00   FALSE:3        \n Median :5   T3:3       C:3       Median :11   Median :31.00   TRUE :6        \n Mean   :5                        Mean   :11   Mean   :31.22                  \n 3rd Qu.:7                        3rd Qu.:12   3rd Qu.:32.50                  \n Max.   :9                        Max.   :12   Max.   :34.50                  \n    Local          \n Length:9          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nAgora √© poss√≠vel ver a contagem de cada n√≠vel das vari√°veis categ√≥ricas. Ou seja, s√£o 3 n√≠veis em cada vari√°vel (T1, T2, T3 para Tratamento e A, B, C para Variedade).\n\nPode-se convert√™-las em fatores usando a fun√ß√£o factor():\n\nTamb√©m d√° para criar o fator diretamente com a fun√ß√£o factor(), que √© mais flex√≠vel porque permite:\n\nDefinir os n√≠veis (levels)\nDefinir as etiquetas (labels)\n\nOu seja, permite controlar a ordem e o r√≥tulo dos n√≠veis (mais recomendado para ANOVA e modelos, pois evita ordem alfab√©tica indesejada).\n\nPode-se ainda convert√™-las em fatores usando a fun√ß√£o convert_as_factor() do pacote {rstatix}:\n\nA fun√ß√£o convert_as_factor() pode converter uma ou v√°rias colunas ao mesmo tempo.\n\n\nglimpse(dados_agro) (do pacote dplyr)\n\nMostra a estrutura dos dados de forma compacta e leg√≠vel, similar ao str(), mas em formato horizontal:\n\nExibe todas as vari√°veis, seus tipos e algumas observa√ß√µes iniciais\n\nMais f√°cil de ler quando o banco de dados tem muitas colunas\n\nExemplo de sa√≠da (resumida):\n\nglimpse(dados_agro)\n\nRows: 9\nColumns: 7\n$ Parcela       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ Tratamento    &lt;fct&gt; Controle, Controle, Controle, Adubo, Adubo, Adubo, Bioes‚Ä¶\n$ Variedade     &lt;fct&gt; IPA 11, IPA 11, IPA 11, Campo Lindo, Campo Lindo, Campo ‚Ä¶\n$ Area          &lt;dbl&gt; 10, 10, 10, 12, 12, 12, 11, 11, 11\n$ Produtividade &lt;dbl&gt; 30.5, 32.0, 31.0, 28.0, 29.5, 30.0, 33.0, 34.5, 32.5\n$ Irrigado      &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE\n$ Local         &lt;chr&gt; \"Norte\", \"Norte\", \"Norte\", \"Sul\", \"Sul\", \"Sul\", \"Leste\",‚Ä¶\n\n\n\n\n\n\n\n# Exemplo fict√≠cio\ndados &lt;- data.frame(\n  tratamento = rep(c(\"T1\", \"T2\", \"T3\"), each = 4),\n  repeticao = rep(1:4, 3),\n  produtividade = c(30, 32, 28, 31, 35, 36, 34, 37, 25, 27, 26, 28)\n)\n\n# Selecionar colunas e filtrar\ndados |&gt; dplyr::select(tratamento, produtividade) |&gt; filter(produtividade &gt; 30)\n\n  tratamento produtividade\n1         T1            32\n2         T1            31\n3         T2            35\n4         T2            36\n5         T2            34\n6         T2            37\n\n# Resumo estat√≠stico\ndados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    media = mean(produtividade),\n    sd = sd(produtividade)\n  )\n\n# A tibble: 3 √ó 3\n  tratamento media    sd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 T1          30.2  1.71\n2 T2          35.5  1.29\n3 T3          26.5  1.29\n\n\n\n\n\n\n\n# Histograma\nggplot(dados, aes(x = produtividade)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n# Boxplot\nggplot(dados, aes(x = tratamento, y = produtividade)) +\n  geom_boxplot(fill = \"orange\")"
  },
  {
    "objectID": "cursoder/index.html#m√≥dulo-3-an√°lise-de-vari√¢ncia-anova",
    "href": "cursoder/index.html#m√≥dulo-3-an√°lise-de-vari√¢ncia-anova",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "# Primeiro transformar vari√°veis em fatores\ndados$tratamento &lt;- factor(dados$tratamento)\ndados$repeticao &lt;- factor(dados$repeticao)\n\n# ANOVA usando aov()\nmodelo &lt;- aov(produtividade ~ tratamento, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamento   2 163.50   81.75   39.24 3.59e-05 ***\nResiduals    9  18.75    2.08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd     F        p p&lt;.05   ges\n1 tratamento   2   9 39.24 3.59e-05     * 0.897\n\n# ANOVA usando ExpDes.pt\ndic(\n  trat = dados$tratamento,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM    Fc      Pr&gt;Fc\nTratamento  2 163.50 81.750 39.24 3.5934e-05\nResiduo     9  18.75  2.083                 \nTotal      11 182.25                        \n------------------------------------------------------------------------\nCV = 4.69 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.5375769 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.8663487 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\neasyanova::ea1(dados[-2], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type I SS mean square F value    p&gt;F\ntreatments  2    163.50     81.7500   39.24 &lt;0.001\nResiduals   9     18.75      2.0833       -      -\n\n$Means\n  treatment  mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2 35.50 1.2910 0.7217  34  37     a   a      a a           a\n2        T1 30.25 1.7078 0.7217  28  32     b   b      b b           b\n3        T3 26.50 1.2910 0.7217  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 T2 - T1     5.25   0.0016 0.0006    0.0006 0.0006\n2 T2 - T3     9.00   0.0000 0.0000    0.0000 0.0000\n3 T1 - T3     3.75   0.0128 0.0051    0.0051 0.0051\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                             values\np.value Shapiro-Wilk test    0.5376\np.value Bartlett test        0.8663\ncoefficient of variation (%) 4.6900\nfirst value most discrepant  3.0000\nsecond value most discrepant 2.0000\nthird value most discrepant  8.0000\n\n$`Residual analysis`$residuals\n    1     2     3     4     5     6     7     8     9    10    11    12 \n-0.25  1.75 -2.25  0.75 -0.50  0.50 -1.50  1.50 -1.50  0.50 -0.50  1.50 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n-0.1914854  1.3403980 -1.7233688  0.5744563 -0.3829708  0.3829708 -1.1489125 \n         8          9         10         11         12 \n 1.1489125 -1.1489125  0.3829708 -0.3829708  1.1489125 \n\n\nTestes de Pressupostos\nAntes da an√°lise de vari√¢ncia (ANOVA), foi realizada a verifica√ß√£o dos pressupostos de normalidade dos res√≠duos e homogeneidade das vari√¢ncias, que s√£o condi√ß√µes necess√°rias para a validade do teste F.\nNormalidade dos res√≠duos\n\nO teste de Shapiro-Wilk foi aplicado sobre os res√≠duos do modelo, verificando se a distribui√ß√£o se aproxima da normal.\nAl√©m disso, a normalidade foi testada dentro de cada grupo experimental utilizando a fun√ß√£o shapiro_test() do pacote rstatix, o que permite avaliar poss√≠veis desvios em tratamentos espec√≠ficos.\nQuando o valor de p &gt; 0,05, n√£o se rejeita a hip√≥tese nula de normalidade, indicando que os res√≠duos podem ser considerados normalmente distribu√≠dos.\n\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.94298, p-value = 0.5376\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n\nHomogeneidade das vari√¢ncias\n\nPara verificar se os tratamentos apresentam vari√¢ncias homog√™neas, foram aplicados tr√™s testes:\n\nTeste de Bartlett: sens√≠vel a desvios de normalidade, mas adequado quando os dados s√£o normais.\nTeste de Levene: mais robusto quando a normalidade n√£o √© estritamente atendida.\n\n\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nDessa forma, a an√°lise de vari√¢ncia pode ser conduzida com confian√ßa, uma vez que os pressupostos de normalidade e homogeneidade foram verificados.\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento, data = dados)\n\n$tratamento\n       diff        lwr        upr     p adj\nT2-T1  5.25   2.400421  8.0995788 0.0015767\nT3-T1 -3.75  -6.599579 -0.9004212 0.0127984\nT3-T2 -9.00 -11.849579 -6.1504212 0.0000269\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean    SE df lower.CL upper.CL .group\n T3           26.5 0.722  9     24.4     28.6  a    \n T1           30.2 0.722  9     28.1     32.4   b   \n T2           35.5 0.722  9     33.4     37.6    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nAnova\nNo DBC (delineamento em blocos casualizados) a diferen√ßa principal √© que voc√™ precisa considerar o efeito de blocos no modelo. Seguindo o mesmo estilo da sua aula de DIC, aqui est√° a vers√£o para DBC:\n\n# ANOVA usando aov()\n# Aqui usamos Error(bloco) ou bloco como efeito\nmodelo &lt;- aov(produtividade ~ tratamento + repeticao, data = dados)\nsummary(modelo)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \ntratamento   2 163.50   81.75 127.957 1.2e-05 ***\nrepeticao    3  14.92    4.97   7.783  0.0172 *  \nResiduals    6   3.83    0.64                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# ANOVA usando rstatix\ndados |&gt; anova_test(produtividade ~ tratamento + repeticao)\n\nANOVA Table (type II tests)\n\n      Effect DFn DFd       F       p p&lt;.05   ges\n1 tratamento   2   6 127.957 1.2e-05     * 0.977\n2  repeticao   3   6   7.783 1.7e-02     * 0.796\n\n# ANOVA usando ExpDes.pt\ndbc(\n  trat = dados$tratamento,\n  bloco = dados$repeticao,\n  resp = dados$produtividade,\n  quali = TRUE,\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ     QM      Fc    Pr&gt;Fc\nTratamento  2 163.500 81.750 127.957 0.000012\nBloco       3  14.917  4.972   7.783 0.017195\nResiduo     6   3.833  0.639                 \nTotal      11 182.250                        \n------------------------------------------------------------------------\nCV = 2.6 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.4793843 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.1530654 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    T2      35.5 \n b   T1      30.25 \n  c      T3      26.5 \n------------------------------------------------------------------------\n\n# ANOVA usando easyanova\n# design = 2 corresponde a DBC\neasyanova::ea1(dados, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n           df type III SS mean square  F value    p&gt;F\ntreatments  2    163.5000     81.7500 127.9565 &lt;0.001\nblocks      3     14.9167      4.9722   7.7826 0.0172\nresiduals   6      3.8333      0.6389        -      -\n\n$`Adjusted means`\n  treatment adjusted.mean     sd    sem min max tukey snk duncan t scott_knott\n1        T2         35.50 1.2910 0.3997  34  37     a   a      a a           a\n2        T1         30.25 1.7078 0.3997  28  32     b   b      b b           b\n3        T3         26.50 1.2910 0.3997  25  28     c   c      c c           c\n\n$`Multiple comparison test`\n     pair contrast p(tukey) p(snk) p(duncan)  p(t)\n1 T2 - T1     5.25   0.0002  1e-04     1e-04 1e-04\n2 T2 - T3     9.00   0.0000  0e+00     0e+00 0e+00\n3 T1 - T3     3.75   0.0014  6e-04     6e-04 6e-04\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                              values\np.value Shapiro-Wilk test     0.4794\np.value Bartlett test         0.8663\ncoefficient of variation (%)  2.6000\nfirst value most discrepant  11.0000\nsecond value most discrepant  3.0000\nthird value most discrepant   2.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n 0.50000000  0.83333333 -0.83333333 -0.50000000  0.25000000 -0.41666667 \n          7           8           9          10          11          12 \n-0.08333333  0.25000000 -0.75000000 -0.41666667  0.91666667  0.25000000 \n\n$`Residual analysis`$`standardized residuals`\n         1          2          3          4          5          6          7 \n 0.8469896  1.4116493 -1.4116493 -0.8469896  0.4234948 -0.7058246 -0.1411649 \n         8          9         10         11         12 \n 0.4234948 -1.2704843 -0.7058246  1.5528142  0.4234948 \n\n\nObserva√ß√µes importantes:\n\nNo aov(), o termo + bloco garante que a varia√ß√£o entre blocos seja considerada.\nNo ExpDes.pt, usamos dbc() no lugar de dic().\nNo easyanova, o argumento design = 2 √© usado para DBC.\n\nTestes de Pressupostos\n\n# Normalidade\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.93854, p-value = 0.4794\n\n# Usando pacote rstatix e fazendo normalidade por grupo\ndados |&gt; group_by(tratamento) |&gt; rstatix::shapiro_test(produtividade)\n\n# A tibble: 3 √ó 4\n  tratamento variable      statistic     p\n  &lt;fct&gt;      &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 T1         produtividade     0.971 0.850\n2 T2         produtividade     0.993 0.972\n3 T3         produtividade     0.993 0.972\n\n# Homogeneidade\n## Teste de Bartlett\nbartlett.test(produtividade ~ tratamento, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  produtividade by tratamento\nBartlett's K-squared = 0.28694, df = 2, p-value = 0.8663\n\n## Teste de Levene\nrstatix::levene_test(produtividade ~ tratamento, data = dados)\n\n# A tibble: 1 √ó 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2     9     0.158 0.856\n\n## Teste de ONeill e Mathews\noneilldbc(trat = dados$tratamento, resp = dados$produtividade, bloco = dados$repeticao)\n\n[1] 0.1530654\n\n\nEm DBC tamb√©m foi realizado Teste de O‚ÄôNeill e Mathews, espec√≠fico para experimentos em blocos casualizados (DBC), sendo recomendado como alternativa robusta para esse delineamento.\n\nEm todos os testes, valores de p &gt; 0,05 indicam que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade das vari√¢ncias, atendendo ao pressuposto da ANOVA.\n\nCompara√ß√µes de M√©dias\n\n# Tukey no R base\nTukeyHSD(modelo)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = produtividade ~ tratamento + repeticao, data = dados)\n\n$tratamento\n       diff        lwr       upr     p adj\nT2-T1  5.25   3.515829  6.984171 0.0002167\nT3-T1 -3.75  -5.484171 -2.015829 0.0013765\nT3-T2 -9.00 -10.734171 -7.265829 0.0000092\n\n$repeticao\n          diff        lwr         upr     p adj\n2-1  1.6666667 -0.5925501  3.92588339 0.1472526\n3-1 -0.6666667 -2.9258834  1.59255006 0.7441939\n4-1  2.0000000 -0.2592167  4.25921672 0.0796674\n3-2 -2.3333333 -4.5925501 -0.07411661 0.0438895\n4-2  0.3333333 -1.9258834  2.59255006 0.9535148\n4-3  2.6666667  0.4074499  4.92588339 0.0248704\n\n# Tukey no rstatix\ndados |&gt; tukey_hsd(produtividade ~ tratamento)\n\n# A tibble: 3 √ó 9\n  term       group1 group2 null.value estimate conf.low conf.high     p.adj\n* &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 tratamento T1     T2              0     5.25     2.40     8.10  0.00158  \n2 tratamento T1     T3              0    -3.75    -6.60    -0.900 0.0128   \n3 tratamento T2     T3              0    -9      -11.8     -6.15  0.0000269\n# ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt;\n\n# M√©dias ajustadas\n# Emmeans\nemm &lt;- emmeans(modelo, ~ tratamento)\ngrupos &lt;- multcomp::cld(emm, Letters = letters, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\nprint(grupos)\n\n tratamento emmean  SE df lower.CL upper.CL .group\n T3           26.5 0.4  6     25.2     27.8  a    \n T1           30.2 0.4  6     28.9     31.6   b   \n T2           35.5 0.4  6     34.2     36.8    c  \n\nResults are averaged over the levels of: repeticao \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\n# Exemplo com dois fatores\ndados2 &lt;- expand.grid(\n  adubacao = c(\"A1\", \"A2\"),\n  cultivar = c(\"C1\", \"C2\", \"C3\"),\n  rep = 1:4\n)\n\nset.seed(123)\n\ndados2$produtividade &lt;- rnorm(24, mean = 30, sd = 3)\ndados2$adubacao &lt;- factor(dados2$adubacao)\ndados2$cultivar &lt;- factor(dados2$cultivar)\ndados2$rep &lt;- factor(dados2$rep)\n\n# ANOVA usando aov()\nmodelo2 &lt;- aov(produtividade ~ adubacao * cultivar, data = dados2)\nsummary(modelo2)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nadubacao           1   2.09   2.089   0.217  0.647\ncultivar           2   1.07   0.536   0.056  0.946\nadubacao:cultivar  2  13.72   6.861   0.712  0.504\nResiduals         18 173.43   9.635               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1          adubacao   1  18 0.217 0.647       0.012\n2          cultivar   2  18 0.056 0.946       0.006\n3 adubacao:cultivar   2  18 0.712 0.504       0.073\n\n# ExpDes.pt\nfat2.dic(\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nF1       1   2.089  3 0.21680 0.64708\nF2       2   1.073  2 0.05566 0.94602\nF1*F2    2  13.723  4 0.71212 0.50391\nResiduo 18 173.435  5                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.36 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6606527 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\neasyanova::ea2(dados2[-3], design = 1, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2168 0.6471\nfactor_2           2      1.0726      0.5363  0.0557  0.946\nfactor_1:factor_2  2     13.7229      6.8614  0.7121 0.5039\nresiduals         18    173.4346      9.6353       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.8961     a   a      a a           a\n2       A2        29.679 3.2191 0.8961     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6471 0.6471    0.6471 0.6471\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.0975     a   a      a a           a\n2       C3       30.0767 3.6356 1.0975     a   a      a a           a\n3       C1       29.6795 1.9564 1.0975     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9982 0.9549    0.9549 0.9549\n2 C2 - C1   0.4862   0.9475 0.9475    0.7709 0.7577\n3 C3 - C1   0.3972   0.9646 0.8009    0.8009 0.8009\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3414 0.3414    0.3414 0.3414\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5146 0.5146    0.5146 0.5146\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6272 0.6272    0.6272 0.6272\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.552     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.552     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.552     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd   sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.552     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.552     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.552     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9980 0.9523    0.9523 0.9523\n2 A1.C1 - A1.C2   1.3158   0.8221 0.8221    0.5783 0.5563\n3 A1.C3 - A1.C2   1.1828   0.8533 0.5966    0.5966 0.5966\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8112 0.5430    0.5430 0.5430\n2 A2.C2 - A2.C1   2.2883   0.5605 0.5605    0.3371 0.3109\n3 A2.C3 - A2.C1   0.9275   0.9068 0.6776    0.6776 0.6776\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6607\np.value Bartlett test (factor_1)    0.5289\np.value Bartlett test (factor_2)    0.1309\np.value Bartlett test (treatments)  0.5464\ncoefficient of variation (%)       10.3600\nfirst value most discrepant         6.0000\nsecond value most discrepant       18.0000\nthird value most discrepant         3.0000\n\n$`Residual analysis`$residuals\n          1           2           3           4           5           6 \n-2.43335287  0.70247809  5.23998198 -0.68381331 -0.23104847  5.61066714 \n          7           8           9          10          11          12 \n 0.63082268 -2.40217314 -1.49670152 -2.23232439  3.05333372  1.54491366 \n         13          14          15          16          17          18 \n 0.45038842  1.72505871 -1.10366637  4.46540093  0.87463976 -5.43437929 \n         19          20          21          22          23          24 \n 1.35214177 -0.02536366 -2.63961408 -1.54926323 -3.69692502 -1.72120151 \n\n$`Residual analysis`$`standardized residuals`\n           1            2            3            4            5            6 \n-0.886137644  0.255816692  1.908208766 -0.249019664 -0.084139356  2.043198673 \n           7            8            9           10           11           12 \n 0.229722427 -0.874783133 -0.545043662 -0.812930463  1.111911873  0.562600750 \n          13           14           15           16           17           18 \n 0.164014901  0.628202953 -0.401914711  1.626134829  0.318511642 -1.979001121 \n          19           20           21           22           23           24 \n 0.492400316 -0.009236513 -0.961250393 -0.564184702 -1.346284159 -0.626798303 \n\n\n\n\n\n\n\n# ANOVA usando aov()\n# Aqui, bloco √© adicionado como efeito de erro\nmodelo_dbc &lt;- aov(produtividade ~ rep + adubacao * cultivar, data = dados2)\nsummary(modelo_dbc)\n\n                  Df Sum Sq Mean Sq F value Pr(&gt;F)\nrep                3  22.94   7.647   0.762  0.533\nadubacao           1   2.09   2.089   0.208  0.655\ncultivar           2   1.07   0.536   0.053  0.948\nadubacao:cultivar  2  13.72   6.861   0.684  0.520\nResiduals         15 150.49  10.033               \n\n# rstatix\ndados2 |&gt; anova_test(produtividade ~ rep + adubacao * cultivar)\n\nANOVA Table (type II tests)\n\n             Effect DFn DFd     F     p p&lt;.05   ges\n1               rep   3  15 0.762 0.533       0.132\n2          adubacao   1  15 0.208 0.655       0.014\n3          cultivar   2  15 0.053 0.948       0.007\n4 adubacao:cultivar   2  15 0.684 0.520       0.084\n\n# ExpDes.pt\n# fat2.dbc √© a fun√ß√£o para fatorial em blocos no pacote ExpDes.pt\nfat2.dbc(\n  bloco = dados2$rep,\n  fator1 = dados2$adubacao,\n  fator2 = dados2$cultivar,\n  resp = dados2$produtividade,\n  quali = c(TRUE, TRUE),\n  mcomp = \"tukey\"\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  F1 \nFATOR 2:  F2 \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n        GL      SQ QM      Fc   Pr&gt;Fc\nBloco    3  22.942  6 0.76223 0.53264\nF1       1   2.089  4 0.20821 0.65471\nF2       2   1.073  2 0.05345 0.94813\nF1*F2    2  13.723  5 0.68390 0.51971\nResiduo 15 150.493  3                \nTotal   23 190.319  1                \n------------------------------------------------------------------------\nCV = 10.57 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.6960048 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nF1\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     A1 30.26899\n2     A2 29.67895\n------------------------------------------------------------------------\nF2\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1     C1 29.67946\n2     C2 30.16574\n3     C3 30.07672\n------------------------------------------------------------------------\n\n# easyanova\n# Em DBC, design = 2 (fatorial em blocos)\neasyanova::ea2(dados2, design = 2, plot = 2)\n\n\n\n\n\n\n\n\n$`Analysis of variance`\n                  df type III SS mean square F value    p&gt;F\nfactor_1           1      2.0889      2.0889  0.2082 0.6547\nfactor_2           2      1.0726      0.5363  0.0535 0.9481\nblocks             3     22.9420      7.6473  0.7622 0.5326\nfactor_1:factor_2  2     13.7229      6.8614  0.6839 0.5197\nresiduals         15    150.4926     10.0328       -      -\n\n$`Adjusted means (factor 1)`\n  factor_1 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       A1        30.269 2.5979 0.9144     a   a      a a           a\n2       A2        29.679 3.2191 0.9144     a   a      a a           a\n\n$`Multiple comparison test (factor 1)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1 - A2     0.59   0.6547 0.6547    0.6547 0.6547\n\n$`Adjusted means (factor 2)`\n  factor_2 adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1       C2       30.1657 3.1608 1.1199     a   a      a a           a\n2       C3       30.0767 3.6356 1.1199     a   a      a a           a\n3       C1       29.6795 1.9564 1.1199     a   a      a a           a\n\n$`Multiple comparison test (factor 2)`\n     pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 C2 - C3   0.0890   0.9983 0.9559    0.9559 0.9559\n2 C2 - C1   0.4862   0.9495 0.9495    0.7754 0.7631\n3 C3 - C1   0.3972   0.9660 0.8054    0.8054 0.8054\n\n$`Adjusted means (factor 1 in levels of factor 2)`\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A2.C1   2.1449   0.3534 0.3534    0.3534 0.3534\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A1.C2   1.4592   0.5246 0.5246    0.5246 0.5246\n\n$`Multiple comparison test (factor 1 in levels of factor 2)`$`factor_1 in  C3`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C3 - A2.C3   1.0844   0.6353 0.6353    0.6353 0.6353\n\n\n$`Adjusted means (factor 2 in levels of factor 1)`\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n1     A1.C1       30.7519 1.6684 1.5837     a   a      a a           a\n5     A1.C3       30.6189 2.8171 1.5837     a   a      a a           a\n3     A1.C2       29.4361 3.5536 1.5837     a   a      a a           a\n\n$`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n  treatment adjusted.mean     sd    sem tukey snk duncan t scott_knott\n4     A2.C2       30.8953 3.0436 1.5837     a   a      a a           a\n6     A2.C3       29.5345 4.7032 1.5837     a   a      a a           a\n2     A2.C1       28.6070 1.7550 1.5837     a   a      a a           a\n\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A1`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A1.C1 - A1.C3   0.1330   0.9981 0.9534    0.9534 0.9534\n2 A1.C1 - A1.C2   1.3158   0.8288 0.8288    0.5862 0.5656\n3 A1.C3 - A1.C2   1.1828   0.8589 0.6051    0.6051 0.6051\n\n$`Multiple comparison test (factor 2 in levels of factor 1)`$`factor_2 in  A2`\n           pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1 A2.C2 - A2.C3   1.3608   0.8182 0.5526    0.5526 0.5526\n2 A2.C2 - A2.C1   2.2883   0.5751 0.5751    0.3481 0.3231\n3 A2.C3 - A2.C1   0.9275   0.9104 0.6846    0.6846 0.6846\n\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                                    values\np.value Shapiro-Wilk test           0.6960\np.value Bartlett test (factor_1)    0.5441\np.value Bartlett test (factor_2)    0.6041\np.value Bartlett test (treatments)  0.8490\ncoefficient of variation (%)       10.5700\nfirst value most discrepant        18.0000\nsecond value most discrepant       16.0000\nthird value most discrepant         6.0000\n\n$`Residual analysis`$residuals\n         1          2          3          4          5          6          7 \n-3.8008383 -0.6650073  3.8724965 -2.0512987 -1.5985339  4.2431817  0.7811775 \n         8          9         10         11         12         13         14 \n-2.2518183 -1.3463467 -2.0819696  3.2036886  1.6952685  0.2874814  1.5621517 \n        15         16         17         18         19         20         21 \n-1.2665734  4.3024939  0.7117327 -5.5972863  2.7321794  1.3546740 -1.2595765 \n        22         23         24 \n-0.1692256 -2.3168874 -0.3411639 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n-1.48588700 -0.25997574  1.51390084 -0.80192786 -0.62492549  1.65881525 \n          7           8           9          10          11          12 \n 0.30539092 -0.88031831 -0.52633627 -0.81391821  1.25243928  0.66274259 \n         13          14          15          16          17          18 \n 0.11238701  0.61070235 -0.49514996  1.68200256  0.27824241 -2.18818437 \n         19          20          21          22          23          24 \n 1.06810906  0.52959170 -0.49241461 -0.06615649 -0.90575620 -0.13337347"
  },
  {
    "objectID": "cursoder/index.html#m√≥dulo-4-regress√£o",
    "href": "cursoder/index.html#m√≥dulo-4-regress√£o",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "dose &lt;- c(0, 50, 100, 150, 200)\nprod &lt;- c(20, 28, 35, 40, 38)\ndados_reg &lt;- data.frame(dose, prod)\n\nmodelo_reg &lt;- lm(prod ~ dose, data = dados_reg)\na &lt;- summary(modelo_reg)\n\n# Coeficientes\ncoeficientes &lt;- coef(modelo_reg)\nintercepto &lt;- round(coeficientes[1], 2) # sem sinal extra\nslope &lt;- formatC(coeficientes[2], format = \"f\", digits = 2, flag = \"+\") # sempre com sinal\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n\n\n\n# Equa√ß√£o no formato correto\nequacao &lt;- paste0(\"y = \", intercepto, slope, \"x\")\n\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", f_value,\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n\n\ndados_reg |&gt;\n  ggplot(aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  annotate(\"text\",\n           x = 100, y = 10,\n           label = legenda,\n           hjust = 0, size = 5) +\n  labs(x = \"Frequ√™ncia de irriga√ß√£o\", y = \"CRA (%)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ajustar modelo de regress√£o quadr√°tica\nmodelo_quad &lt;- lm(prod ~ dose + I(dose^2), data = dados_reg)\na &lt;- summary(modelo_quad)\na\n\n\nCall:\nlm(formula = prod ~ dose + I(dose^2), data = dados_reg)\n\nResiduals:\n      1       2       3       4       5 \n 0.5429 -0.9714 -0.3429  1.4286 -0.6571 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 19.4571429  1.3021176  14.943  0.00445 **\ndose         0.2217143  0.0308492   7.187  0.01882 * \nI(dose^2)   -0.0006286  0.0001479  -4.250  0.05116 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.384 on 2 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9715 \nF-statistic: 69.21 on 2 and 2 DF,  p-value: 0.01424\n\n# Coeficientes da regress√£o quadr√°tica (com mais casas decimais)\ncoef_quad &lt;- coef(modelo_quad)\nintercepto &lt;- formatC(coef_quad[1], format = \"f\", digits = 4)\nlinear     &lt;- formatC(coef_quad[2], format = \"f\", digits = 4, flag = \"+\")\nquadratico &lt;- formatC(coef_quad[3], format = \"f\", digits = 4, flag = \"+\") \n# usei 6 casas para o termo quadr√°tico porque geralmente √© bem pequeno\n\n# Estat√≠sticas do modelo\nr2 &lt;- round(a$r.squared, 4)\nf_value &lt;- a$fstatistic[1]\ndf1 &lt;- a$fstatistic[2]\ndf2 &lt;- a$fstatistic[3]\np_value_anova &lt;- pf(f_value, df1, df2, lower.tail = FALSE)\n\n# Equa√ß√£o para legenda\nequacao &lt;- paste0(\"y = \", intercepto, \" \", linear, \"x \", quadratico, \"x¬≤\")\nlegenda &lt;- paste0(\n  equacao,\n  \"  R¬≤ = \", r2,\n  \"\\nF = \", round(f_value, 2),\n  \"; p = \", format.pval(p_value_anova, digits = 4, eps = 0.001)\n)\n\n# Gr√°fico\nlibrary(ggplot2)\n\nregressao_quad &lt;- ggplot(dados_reg, aes(x = dose, y = prod)) +\n  geom_point(size = 3) +\n  stat_smooth(\n    method = \"lm\",\n    formula = y ~ x + I(x^2),\n    se = FALSE,\n    color = \"black\"\n  ) +\n  annotate(\"text\", x = 50, y = 10, label = legenda, hjust = 0, size = 5) +\n  labs(x = \"Dose\", y = \"Produ√ß√£o\") +\n  theme_bw() +\n  theme(panel.grid = element_blank()) +\n  ylim(0, 50)\n\n# Exibir gr√°fico\nregressao_quad"
  },
  {
    "objectID": "cursoder/index.html#m√≥dulo-5-relat√≥rios-e-projeto-final",
    "href": "cursoder/index.html#m√≥dulo-5-relat√≥rios-e-projeto-final",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Este pr√≥prio arquivo √© um exemplo.\n\nPode ser exportado em HTML, Word ou PDF."
  },
  {
    "objectID": "cursoder/index.html#projeto-final",
    "href": "cursoder/index.html#projeto-final",
    "title": "Curso de Estat√≠stica com R para Experimenta√ß√£o Agr√≠cola",
    "section": "",
    "text": "Analise um conjunto de dados agr√≠colas (real ou fornecido):\n- Estruture os dados no Excel/CSV.\n- Importe para o R.\n- Realize ANOVA (com aov(), ExpDes.pt, easyanova e rstatix).\n- Teste pressupostos.\n- Se necess√°rio, ajuste modelos de regress√£o.\n- Gere gr√°ficos com ggplot2.\n- Organize os resultados em relat√≥rio RMarkdown."
  },
  {
    "objectID": "graficos.html",
    "href": "graficos.html",
    "title": "Construindo gr√°ficos no R",
    "section": "",
    "text": "Construindo gr√°ficos usando o pacote ggplot2\n\nlibrary(ggplot2) #Criar gr√°ficos de v√°rios tipos\nlibrary(dplyr) #Utilizar operadores pipes\nlibrary(rstatix) #Pacote para realizar estat√≠stica descritiva"
  },
  {
    "objectID": "graficos.html#gr√°fico-de-boxplot",
    "href": "graficos.html#gr√°fico-de-boxplot",
    "title": "Construindo gr√°ficos no R",
    "section": "Gr√°fico de boxplot",
    "text": "Gr√°fico de boxplot\n\nVari√°vel dependente: MAP\n\nVari√°veis independentes: FMICO, LIRRIG, DAS\n\n\nModelo 1- Simples com duas vari√°veis\nMassa a√©rea da parte a√©rea da planta (MAP) em fun√ß√£o de n√≠veis de irriga√ß√£o aplicados √†s plantas (LIRIG).\n\ndados |&gt; \n  ggplot(aes(x= LIRRIG, y=MAP))+ #Escolhe que vari√°veis aparecem no eixo X, Y e grupo\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nModelo 2 - Agrupado com tr√™s vari√°veis\n\nMassa a√©rea da parte a√©rea da planta (MAP) em fun√ß√£o de n√≠veis de irriga√ß√£o aplicados √†s plantas (LIRIG) separado por dias ap√≥s a semeadura (DAS).\n\ndados |&gt; \n  ggplot(aes(x=LIRRIG, y=MAP))+ #Escolhe que vari√°veis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gr√°fico de boxplot\n  facet_grid(~DAS) # Agrupa gr√°fico por MICO\n\n\n\n\n\n\n\n\nPodemos trocar e fazer o gr√°fico em fun√ß√£o de DAS e separado por LIRRIG.\n\ndados |&gt; \n  ggplot(aes(x=DAS, y=MAP))+ #Escolhe que vari√°veis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gr√°fico de boxplot\n  facet_grid(~LIRRIG) # Agrupa gr√°fico por LRRIG\n\n\n\n\n\n\n\n\n\n\n\nModelo 3 agrupado com quatro vari√°veis\n\nMassa a√©rea da parte a√©rea da planta (MAP) em fun√ß√£o de n√≠veis de irriga√ß√£o aplicados √†s plantas (LIRIG) separado por dias ap√≥s a semeadura (DAS) e agrupado por FMICO\n\ndados |&gt; \n  ggplot(aes(x=LIRRIG, y=MAP, fill=FMICO))+ #Escolhe que vari√°veis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gr√°fico de boxplot\n  facet_grid(~DAS)+ # Agrupa gr√°fico por DAS \n  theme_bw() #Estilo de gr√°fico\n\n\n\n\n\n\n\n\n\nAlterando t√≠tulos dos eixos\n\n\nModelo 5\n\n\ndados |&gt; \n  ggplot(aes(x=LIRRIG, y=MAP, fill=FMICO))+ #Escolhe que vari√°veis aparecem no eixo X, Y e grupo\n  geom_boxplot()+ #Seleciona tipo de gr√°fico de boxplot\n  facet_grid(~DAS)+ # Agrupa gr√°fico por DAS \n  theme_bw()+ #Estilo de gr√°fico\n  xlab(\"Dias\")+ #Altera o t√≠tulo do eixo X\n  ylab(\"Nome da vari√°vel no eixo y\") #Altera o t√≠tulo do eixo Y"
  },
  {
    "objectID": "graficos.html#gr√°fico-de-linhas-e-barras-de-erros",
    "href": "graficos.html#gr√°fico-de-linhas-e-barras-de-erros",
    "title": "Construindo gr√°ficos no R",
    "section": "Gr√°fico de linhas e barras de erros",
    "text": "Gr√°fico de linhas e barras de erros\nPara fazer gr√°fico de linhas, a vari√°vel no eixo X precisa ser uma vari√°vel num√©rica, como DAS\n\nModelo 1\n\n\n#chama arquivo de dados\ndados |&gt; \n  \n  # Realizar o agrupamento dos dados por FMICO, LIRRIG e DAS\n  group_by(FMICO, LIRRIG,DAS) |&gt; \n  \n  # Calcular as estat√≠sticas resumidas (m√©dia e erro padr√£o) para a coluna MAP dentro de cada grupo\n  get_summary_stats(MAP, type=\"mean_se\") |&gt; \n  \n  # Criar o gr√°fico de linhas\n  ggplot(aes(x = DAS, #Vari√°vel no eixo X\n             y = mean, #Vari√°vel no eixo Y (essa deve ser a var√°vel analisada (dependente))\n             fill = LIRRIG)) + #Vari√°vel na legenda (as linhas ter√£o as cores agrupadas conforme essa vari√°vel)\n  \n  # Adicionar as linhas de dados\n  geom_line(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  # Adicionar pontos nas linhas (opcional)\n  geom_point(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  #Adiciona barras de erros nos pontos\n  geom_errorbar(aes(ymax = mean + se, #Barra de erro para baixo (m√©dia - erro)\n                   ymin = mean - se, #Barra de erro para cima (m√©dia + erro) \n                   width=2, #define a largura da barra de erro \n                   color=LIRRIG #define as cores das linhas de acordo com LIRRIG\n                   ))+\n  \n  #Agrupa os gr√°ficos por FMICO\n  facet_grid(~FMICO)+\n  \n  #Define o estilo do gr√°fico\n  theme_bw()+\n  \n  #Altera t√≠tulo do eixo X\n  xlab(\"Nome da vari√°vel no eixo X (DAS)\")+\n\n  #Altera t√≠tulo do eixo Y\n  ylab(\"Nome da vari√°vel no eixo Y (MAP)\")\n\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\n\n\n\nModelo 2\n\nAdicionando letras nas linhas:\n\n\n#chama arquivo de dados\ndados |&gt; \n  \n  # Realizar o agrupamento dos dados por FMICO, LIRRIG e DAS\n  group_by(FMICO, LIRRIG,DAS) |&gt; \n  \n  # Calcular as estat√≠sticas resumidas (m√©dia e erro padr√£o) para a coluna MAP dentro de cada grupo\n  get_summary_stats(MAP, type=\"mean_se\") |&gt; \n  \n# Criar o gr√°fico de linhas\n  ggplot(aes(x = DAS, #Vari√°vel no eixo X\n             y = mean, #Vari√°vel no eixo Y (essa deve ser a var√°vel analisada (dependente))\n             fill = LIRRIG)) + #Vari√°vel na legenda (as linhas ter√£o as cores agrupadas conforme essa vari√°vel)\n  \n  # Adicionar as linhas de dados\n  geom_line(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  # Adicionar pontos nas linhas (opcional)\n  geom_point(aes(\n    color=LIRRIG) #define as cores das linhas de acordo com LIRRIG\n    )+\n  \n  #Adiciona barras de erros nos pontos\n  geom_errorbar(aes(ymax = mean + se, #Barra de erro para baixo (m√©dia - erro)\n                   ymin = mean - se, #Barra de erro para cima (m√©dia + erro) \n                   width=2, #define a largura da barra de erro \n                   color=LIRRIG #define as cores das linhas de acordo com LIRRIG\n                   ))+\n  \n  #Agrupa os gr√°ficos por FMICO\n  facet_grid(~FMICO)+\n  \n  #Define o estilo do gr√°fico\n  theme_bw()+\n  \n  #Altera t√≠tulo do eixo X\n  xlab(\"Nome da vari√°vel no eixo X (DAS)\")+\n\n  #Altera t√≠tulo do eixo Y\n  ylab(\"Nome da vari√°vel no eixo Y (MAP)\")\n\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n  # Adiocionar letras acima das barras\n  geom_text(aes(label = c(\n    \"a\"#1\n    \n    )),position = position_dodge(1), vjust = -1)\n\nmapping: label = ~c(\"a\") \ngeom_text: parse = FALSE, check_overlap = FALSE, size.unit = mm, na.rm = FALSE\nstat_identity: na.rm = FALSE\nposition_dodge"
  },
  {
    "objectID": "graficos.html#gr√°fico-de-pontos-e-barras-de-erros",
    "href": "graficos.html#gr√°fico-de-pontos-e-barras-de-erros",
    "title": "Construindo gr√°ficos no R",
    "section": "Gr√°fico de pontos e barras de erros",
    "text": "Gr√°fico de pontos e barras de erros\n\nModelo1\n\n\ndados |&gt;\n  group_by(FMICO, LIRRIG, DAS) |&gt;\n  get_summary_stats(MAP, type = \"mean_se\") |&gt;\n  convert_as_factor(DAS) |&gt;\n  \n  ggplot(aes(\n    x = FMICO,\n    y = mean,\n    fill = LIRRIG\n  )) +\n  geom_point(aes(color = LIRRIG), position = position_dodge(width = 0.2)) +\n  geom_errorbar(\n    aes(\n      x = FMICO,\n      ymax = mean + se,\n      ymin = mean - se,\n      width = 0.1,\n      color = LIRRIG\n    ),\n    position = position_dodge(width = 0.2)\n  ) +\n  facet_grid(~DAS) +\n  theme_bw() +\n  xlab(\"Nome da vari√°vel no eixo X (DAS)\") +\n  ylab(\"Nome da vari√°vel no eixo Y (MAP)\")\n\n\n\n\n\n\n\n\n\n\n\nModelo2\n\nAdicionando signific√¢ncia entre tratamentos.\n\n\nteste=\ndados |&gt; \n  group_by(DAS, FMICO) |&gt;\n  pairwise_t_test(MAP ~ LIRRIG, p.adjust.method = \"bonferroni\") |&gt; \n  dplyr::select(-`p`, -`p.signif`) |&gt; \n  add_xy_position(x = \"DAS\") |&gt;  \n  filter(`p.adj`&lt;0.05 ) \n\n\nlibrary(ggpubr)\n\ndados |&gt;\n  group_by(FMICO, LIRRIG, DAS) |&gt;\n  get_summary_stats(MAP, type = \"mean_se\") |&gt;\n  convert_as_factor(DAS) |&gt;\n  \n  ggplot(aes(\n    x = FMICO,\n    y = mean,\n    fill = LIRRIG\n  )) +\n  geom_point(aes(color = LIRRIG), position = position_dodge(width = 0.2)) +\n  geom_errorbar(\n    aes(\n      x = FMICO,\n      ymax = mean + se,\n      ymin = mean - se,\n      width = 0.1,\n      color = LIRRIG\n    ),\n    position = position_dodge(width = 0.2)\n  ) +\n  facet_grid(~DAS) +\n  theme_bw() +\n  xlab(\"Nome da vari√°vel no eixo X (DAS)\") +\n  ylab(\"Nome da vari√°vel no eixo Y (MAP)\")\n\n\n\n\n\n\n\n  # stat_pvalue_manual(teste, tip.length = 0, hide.ns = TRUE)"
  },
  {
    "objectID": "graficos.html#gr√°fico-de-barras-e-erros",
    "href": "graficos.html#gr√°fico-de-barras-e-erros",
    "title": "Construindo gr√°ficos no R",
    "section": "Gr√°fico de barras e erros",
    "text": "Gr√°fico de barras e erros\n\nModelo 1\n\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estat√≠sticas resumidas (m√©dia e erro padr√£o) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, type = \"mean_se\") |&gt; \n  \n  # Criar o gr√°fico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gr√°fico\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nModelo 2\n\nAlterando t√≠tulo dos eixos X e Y e alterando cores das barras:\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estat√≠sticas resumidas (m√©dia e erro padr√£o) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, #Selcionar a vari√°vel\n                    type = \"mean_se\") |&gt; #definir o tipo de estat√≠stica (m√©dia¬±erro-padr√£o)\n  \n  # Criar o gr√°fico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  \n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", #define que a altura das barras seja a m√©dia\n           position = \"dodge\", #define que as barras fiquem lado a lado\n           color = \"black\") + #Adiciona cotorno preto √†s barras\n  \n  # Escolha as cores das barras manualmente (pode usar nome da cor ou c√≥digo hexadecimal)\n    scale_fill_manual(values = c(\"red\", \"#555555\", \"#ffffff\")) +  \n  \n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gr√°fico\n  theme_bw()+\n  \n  #Altera t√≠tulo do eixo X\n  xlab(\"Nome da vari√°vel FMICO\")+\n  \n  #Altera t√≠tulo do eixo Y\n  ylab(\"Nome da vari√°vel CLOA\")\n\n\n\n\n\n\n\n\n\n\n\nModelo 3\n\nAdicionado letras nas barras:\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estat√≠sticas resumidas (m√©dia e erro padr√£o) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, #Selcionar a vari√°vel\n                    type = \"mean_se\") |&gt; #definir o tipo de estat√≠stica (m√©dia¬±erro-padr√£o)\n  \n  # Criar o gr√°fico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  \n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", #define que a altura das barras seja a m√©dia\n           position = \"dodge\", #define que as barras fiquem lado a lado\n           color = \"black\") + #Adiciona cotorno preto √†s barras\n  \n  # Escolha as cores das barras manualmente (pode usar nome da cor ou c√≥digo hexadecimal)\n    scale_fill_manual(values = c(\"red\", \"#555555\", \"#ffffff\")) +  \n  \n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gr√°fico\n  theme_bw()+\n  \n  #Altera t√≠tulo do eixo X\n  xlab(\"Nome da vari√°vel FMICO\")+\n  \n  #Altera t√≠tulo do eixo Y\n  ylab(\"Nome da vari√°vel CLOA\")+\n  \n  ylim(0,50)+ #AUmentando a escala de Y para caber as letras no gr√°fico\n\n  # Adiocionar letras acima das barras\n  geom_text(aes(label = c(\n    \"a\",#1\n    \"b\",#2\n    \"c\",#3\n    \"d\",#4\n    \"e\",#5\n    \"f\",#6\n    \"g\",#7\n    \"h\",#8\n    \"i\" #9\n    \n    )),position = position_dodge(1), vjust = -1)\n\n\n\n\n\n\n\n\n\n\n\nModelo 4\n\nReduzindo a escala do gr√°fica\n\n\ndados |&gt; \n  # Realizar o agrupamento dos dados por FMICO e LIRRIG\n  group_by(FMICO, LIRRIG) |&gt; \n  # Calcular as estat√≠sticas resumidas (m√©dia e erro padr√£o) para a coluna CLOA dentro de cada grupo\n  get_summary_stats(CLOA, #Selcionar a vari√°vel\n                    type = \"mean_se\") |&gt; #definir o tipo de estat√≠stica (m√©dia¬±erro-padr√£o)\n  \n  # Criar o gr√°fico de barras com barras de erro\n  ggplot(aes(x = FMICO, y = mean, fill = LIRRIG)) +\n  \n  # Adicionar as barras de dados\n  geom_bar(stat = \"identity\", #define que a altura das barras seja a m√©dia\n           position = \"dodge\", #define que as barras fiquem lado a lado\n           color = \"black\") + #Adiciona cotorno preto √†s barras\n  \n  # Escolha as cores das barras manualmente (pode usar nome da cor ou c√≥digo hexadecimal)\n    scale_fill_manual(values = c(\"red\", \"#555555\", \"#ffffff\")) +  \n  \n  # Adicionar as barras de erro\n  geom_errorbar(aes(ymax = mean + se, ymin = mean - se), \n                position = position_dodge(0.9), width = 0.2)+\n  # Definir estilo do gr√°fico\n  theme_bw()+\n  \n  #Altera t√≠tulo do eixo X\n  xlab(\"Nome da vari√°vel FMICO\")+\n  \n  #Altera t√≠tulo do eixo Y\n  ylab(\"Nome da vari√°vel CLOA\")+\n  \n  #Aumentando a escala de Y para caber as letras no gr√°fico\n  #Usando coord_cartesian para definir o range e n√£o subir as barras\n  coord_cartesian(ylim = c(20, 50))+ \n\n  # Adiocionar letras acima das barras\n  geom_text(aes(label = c(\n    \"a\",#1\n    \"b\",#2\n    \"c\",#3\n    \"d\",#4\n    \"e\",#5\n    \"f\",#6\n    \"g\",#7\n    \"h\",#8\n    \"i\" #9\n    \n    )),position = position_dodge(1), vjust = -1)"
  }
]